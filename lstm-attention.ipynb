{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "N44EXiZIwpg_"
      },
      "outputs": [],
      "source": [
        "# Importando as bibliotecas necessárias.\n",
        "\n",
        "import os\n",
        "import pathlib\n",
        "import random\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow.data as tf_data\n",
        "import tensorflow.strings as tf_strings\n",
        "import tensorflow_datasets.public_api as tfds\n",
        "\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras import ops\n",
        "from keras.layers import TextVectorization\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define o backend do Keras para o TensorFlow.\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Objetivo do Código: Carregar e Preparar Dados de Tradução a partir de um Arquivo TSV\n",
        "\n",
        "Este código lê um arquivo TSV contendo dados textuais, extrai pares de frases em francês e português, e armazena esses pares em uma lista para uso em tarefas de processamento de linguagem natural ou treinamento de modelos de tradução. Para o texto em português, são adicionados marcadores especiais de início (`[start]`) e fim (`[end]`) para auxiliar na identificação dos limites da sequência.\n",
        "\n",
        "#### Passo a Passo do Código:\n",
        "\n",
        "1. **Inicialização da Lista de Pares**:\n",
        "   - Cria a lista `text_pairs` que armazenará os pares de textos extraídos do arquivo.\n",
        "\n",
        "2. **Abertura e Leitura do Arquivo**:\n",
        "   - O arquivo `\"data.tsv\"` é aberto em modo leitura (`\"r\"`) com codificação `UTF-8` para garantir a correta interpretação dos caracteres.\n",
        "   - O arquivo é processado linha a linha.\n",
        "\n",
        "3. **Processamento de Cada Linha**:\n",
        "   - **Limpeza e Divisão**:\n",
        "     - Cada linha é \"limpa\" com `strip()` para remover espaços em branco extras e, em seguida, dividida em campos usando o separador de tabulação (`\\t`) através de `split(\"\\t\")`.\n",
        "   - **Validação dos Campos**:\n",
        "     - O código verifica se a linha possui pelo menos 4 campos (índices 0 a 3). Se a condição não for atendida, a linha é ignorada (com `continue`).\n",
        "\n",
        "4. **Extração dos Textos**:\n",
        "   - **Texto em Francês**:\n",
        "     - Extraído do segundo campo da linha (`fields[1]`).\n",
        "   - **Texto em Português**:\n",
        "     - Extraído do quarto campo (`fields[3]`).\n",
        "     - Os tokens especiais `[start]` e `[end]` são adicionados, respectivamente, no início e no final do texto, para indicar os limites da sequência.\n",
        "\n",
        "5. **Armazenamento dos Pares**:\n",
        "   - Cada par formado pelo texto em francês e o texto modificado em português é adicionado à lista `text_pairs`.\n",
        "\n",
        "6. **Verificação dos Dados Carregados**:\n",
        "   - O primeiro par da lista é impresso para garantir que a extração e a formatação foram realizadas corretamente.\n",
        "\n",
        "Este procedimento é fundamental para preparar os dados de entrada que serão utilizados posteriormente no treinamento de modelos de tradução automática ou outras tarefas relacionadas a NLP.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "lIEqT_Qew8A-",
        "outputId": "8e518023-e050-4f65-8ff0-c19d42aa8ec5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('Je ne supporte pas ce type.', '[start] Eu não suporto esse tipo. [end]')\n"
          ]
        }
      ],
      "source": [
        "# Inicializa uma lista para armazenar os pares de textos\n",
        "text_pairs = []\n",
        "\n",
        "# Abre o arquivo \"data.tsv\" no modo de leitura com codificação UTF-8\n",
        "with open(\"data.tsv\", \"r\", encoding=\"utf-8\") as f:\n",
        "    # Itera por cada linha do arquivo\n",
        "    for line in f:\n",
        "        # Remove espaços extras e divide a linha utilizando a tabulação como separador\n",
        "        fields = line.strip().split(\"\\t\")\n",
        "        # Garante que a linha possui ao menos 4 campos (índices 0 a 3)\n",
        "        if len(fields) < 4:\n",
        "            continue\n",
        "        french = fields[1]  # Obtém a segunda coluna (texto em francês)\n",
        "        portuguese = \"[start] \" + fields[3] + \" [end]\"  # Obtém a quarta coluna (texto em português) e adiciona os marcadores de início e fim\n",
        "        text_pairs.append((french, portuguese))\n",
        "\n",
        "# Imprime o primeiro par de textos para verificação\n",
        "print(text_pairs[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQZbopkCxjfB",
        "outputId": "d88b5a40-ffb9-4f73-978d-ec3625fc96aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('La couleur blonde est ma couleur de cheveux naturelle.', '[start] O loiro é a minha cor natural de cabelo. [end]')\n",
            "('Si nécessaire, je viendrai à neuf heures demain.', '[start] Se necessário, eu virei amanhã às nove horas. [end]')\n",
            "('Je dois te demander pardon.', '[start] Preciso te pedir perdão. [end]')\n",
            "('Tous sont là.', '[start] Todos estão aqui. [end]')\n",
            "('Les feux tricolores sont utilisés pour réguler le trafic.', '[start] Os semáforos são usados para regular o tráfego. [end]')\n"
          ]
        }
      ],
      "source": [
        "# Itera 5 vezes para imprimir 5 pares de textos escolhidos aleatoriamente\n",
        "for _ in range(5):\n",
        "    # Seleciona um par de textos aleatório da lista 'text_pairs' e o imprime\n",
        "    print(random.choice(text_pairs))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Objetivo do Código: Dividir os Pares de Textos em Conjuntos de Treinamento, Validação e Teste\n",
        "\n",
        "Este trecho de código realiza a divisão dos pares de textos em três conjuntos distintos: treinamento, validação e teste. Essa separação é fundamental para treinar o modelo com um conjunto de dados, ajustar os hiperparâmetros com outro e avaliar o desempenho final utilizando dados nunca vistos durante o treinamento.\n",
        "\n",
        "#### Passo a Passo do Código:\n",
        "\n",
        "1. **Embaralhamento dos Pares de Textos**:\n",
        "   - `random.shuffle(text_pairs)`\n",
        "     - Embaralha aleatoriamente a lista `text_pairs` para garantir que os dados sejam distribuídos de forma aleatória, evitando qualquer viés que possa estar presente na ordem original.\n",
        "\n",
        "2. **Cálculo do Número de Amostras para Validação**:\n",
        "   - `num_val_samples = int(0.15 * len(text_pairs))`\n",
        "     - Calcula 15% do total de pares de textos para compor o conjunto de validação. Essa proporção ajuda a monitorar a performance do modelo em dados não utilizados no treinamento.\n",
        "\n",
        "3. **Determinação do Número de Amostras para Treinamento**:\n",
        "   - `num_train_samples = len(text_pairs) - 2 * num_val_samples`\n",
        "     - Define o número de pares para treinamento reservando duas vezes a quantidade de amostras de validação: uma por conjunto de validação e outra por conjunto de teste. Essa estratégia mantém uma divisão balanceada dos dados.\n",
        "\n",
        "4. **Divisão dos Dados**:\n",
        "   - **Conjunto de Treinamento**:\n",
        "     - `train_pairs = text_pairs[:num_train_samples]`\n",
        "       - Seleciona os primeiros `num_train_samples` pares para formar o conjunto de treinamento.\n",
        "   - **Conjunto de Validação**:\n",
        "     - `val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]`\n",
        "       - Os pares imediatamente após o conjunto de treinamento são alocados para a validação.\n",
        "   - **Conjunto de Teste**:\n",
        "     - `test_pairs = text_pairs[num_train_samples + num_val_samples :]`\n",
        "       - Os pares restantes são destinados ao conjunto de teste.\n",
        "\n",
        "5. **Exibição da Divisão dos Dados**:\n",
        "   - São exibidos os números totais de pares e a quantidade de pares atribuídos a cada conjunto:\n",
        "     - `print(f\"{len(text_pairs)} total pairs\")`\n",
        "     - `print(f\"{len(train_pairs)} training pairs\")`\n",
        "     - `print(f\"{len(val_pairs)} validation pairs\")`\n",
        "     - `print(f\"{len(test_pairs)} test pairs\")`\n",
        "\n",
        "Esta abordagem assegura uma divisão estruturada dos dados, permitindo um treinamento robusto e uma avaliação imparcial do modelo de tradução.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coukIC5OyL1f",
        "outputId": "e1843b6f-2e81-499b-ce36-1743acf920b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "33030 total pairs\n",
            "23122 training pairs\n",
            "4954 validation pairs\n",
            "4954 test pairs\n"
          ]
        }
      ],
      "source": [
        "# Embaralha aleatoriamente os pares de textos\n",
        "random.shuffle(text_pairs)\n",
        "\n",
        "# Calcula o número de amostras para validação como 15% do total de pares\n",
        "num_val_samples = int(0.15 * len(text_pairs))\n",
        "\n",
        "# Define o número de amostras para treinamento, reservando 2 blocos de validação (um para validação e outro para teste)\n",
        "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
        "\n",
        "# Separa os pares para treinamento\n",
        "train_pairs = text_pairs[:num_train_samples]\n",
        "\n",
        "# Separa os pares para validação (logo após os pares de treinamento)\n",
        "val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n",
        "\n",
        "# Separa os pares para teste (os pares restantes após treinamento e validação)\n",
        "test_pairs = text_pairs[num_train_samples + num_val_samples :]\n",
        "\n",
        "# Exibe a quantidade total de pares, bem como a divisão em treinamento, validação e teste\n",
        "print(f\"{len(text_pairs)} total pairs\")\n",
        "print(f\"{len(train_pairs)} training pairs\")\n",
        "print(f\"{len(val_pairs)} validation pairs\")\n",
        "print(f\"{len(test_pairs)} test pairs\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Objetivo do Código: Configurar o Pré-processamento e a Vetorização dos Textos\n",
        "\n",
        "Este trecho de código define os parâmetros e as funções necessárias para a padronização e vetorização dos textos utilizados no treinamento do modelo de tradução. Ele especifica quais caracteres de pontuação devem ser removidos (exceto os colchetes, para preservar tokens especiais), configura os hiperparâmetros para o processamento dos textos e cria camadas de vetorização personalizadas para os idiomas francês e português.\n",
        "\n",
        "#### Passo a Passo do Código:\n",
        "\n",
        "1. **Definição dos Caracteres de Pontuação a Serem Removidos**:\n",
        "   - `strip_chars = string.punctuation + \"«\" + \"»\"`  \n",
        "     Combina os caracteres de pontuação padrão com os caracteres \"«\" e \"»\".\n",
        "   - `strip_chars = strip_chars.replace(\"[\", \"\")`  \n",
        "     Remove o caractere \"[\" da lista, para não afetar tokens especiais como `[start]`.\n",
        "   - `strip_chars = strip_chars.replace(\"]\", \"\")`  \n",
        "     Remove o caractere \"]\" da lista, garantindo que tokens especiais sejam preservados.\n",
        "\n",
        "2. **Configuração dos Parâmetros para o Processamento**:\n",
        "   - `vocab_size = 25000`  \n",
        "     Define o tamanho máximo do vocabulário.\n",
        "   - `sequence_length = 20`  \n",
        "     Define o comprimento máximo das sequências de saída.\n",
        "   - `batch_size = 64`  \n",
        "     Define o tamanho dos lotes (batch size) para o treinamento.\n",
        "   - `latentSpaceDimension = 32`  \n",
        "     Define a dimensão do espaço latente, que pode ser utilizada em modelos de codificação (por exemplo, na camada LSTM).\n",
        "\n",
        "3. **Implementação da Função de Padronização Customizada**:\n",
        "   - **Função `custom_standardization(input_string)`**:\n",
        "     - Converte o texto para minúsculas usando `tf_strings.lower(input_string)`.\n",
        "     - Remove os caracteres indesejados definidos em `strip_chars` utilizando uma expressão regular com `tf_strings.regex_replace` e `re.escape(strip_chars)`.\n",
        "     - Essa padronização garante que o texto seja uniforme, facilitando o aprendizado pelo modelo.\n",
        "\n",
        "4. **Criação das Camadas de Vetorização**:\n",
        "   - **Para o Texto em Francês**:\n",
        "     - `french_vectorization = TextVectorization(...)`:\n",
        "       - `max_tokens=vocab_size`: Limita o número de tokens no vocabulário.\n",
        "       - `output_mode=\"int\"`: Converte os textos em sequências de inteiros (índices dos tokens).\n",
        "       - `output_sequence_length=sequence_length`: Define o comprimento fixo das sequências.\n",
        "   - **Para o Texto em Português**:\n",
        "     - `portuguese_vectorization = TextVectorization(...)`:\n",
        "       - Configurado de forma similar ao francês, porém com `output_sequence_length=sequence_length + 1` para acomodar um token extra (por exemplo, tokens especiais de início ou fim).\n",
        "       - Aplica a padronização customizada definida em `custom_standardization` para limpar e uniformizar os textos.\n",
        "\n",
        "5. **Extração dos Textos dos Pares de Treinamento**:\n",
        "   - `train_french_texts = [pair[0] for pair in train_pairs]`  \n",
        "     Cria uma lista contendo os textos em francês dos pares de treinamento.\n",
        "   - `train_portuguese_texts = [pair[1] for pair in train_pairs]`  \n",
        "     Cria uma lista contendo os textos em português dos pares de treinamento.\n",
        "\n",
        "6. **Adaptação das Camadas de Vetorização**:\n",
        "   - `french_vectorization.adapt(train_french_texts)`  \n",
        "     Ajusta a camada de vetorização para o francês aos dados de treinamento, permitindo que ela aprenda o vocabulário e os padrões dos textos.\n",
        "   - `portuguese_vectorization.adapt(train_portuguese_texts)`  \n",
        "     Ajusta a camada de vetorização para o português aos dados de treinamento, garantindo que os textos sejam convertidos corretamente em sequências numéricas.\n",
        "\n",
        "Esta etapa de pré-processamento é crucial para converter os dados textuais brutos em um formato adequado para o treinamento de modelos de tradução, garantindo consistência e preservação dos tokens especiais durante a vetorização.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "_LmEwdu8yNv0"
      },
      "outputs": [],
      "source": [
        "# Define os caracteres de pontuação que serão removidos durante a padronização,\n",
        "# adicionando os caracteres \"«\" e \"»\".\n",
        "strip_chars = string.punctuation + \"«\" + \"»\"\n",
        "\n",
        "# Remove os colchetes dos caracteres a serem removidos, mantendo-os no texto\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "\n",
        "# Define os parâmetros para o processamento dos textos\n",
        "vocab_size = 25000       # Tamanho máximo do vocabulário\n",
        "sequence_length = 20     # Comprimento máximo das sequências de saída\n",
        "batch_size = 64          # Tamanho do lote (batch)\n",
        "latentSpaceDimension = 32# Dimensão do espaço latente (latent space dimension).\n",
        "\n",
        "def custom_standardization(input_string):\n",
        "    \"\"\"\n",
        "    Função de padronização customizada para os textos.\n",
        "\n",
        "    Converte o texto para minúsculas e remove os caracteres definidos em 'strip_chars'.\n",
        "    \"\"\"\n",
        "    # Converte o texto para letras minúsculas\n",
        "    lowercase = tf_strings.lower(input_string)\n",
        "    # Remove os caracteres indesejados utilizando uma expressão regular\n",
        "    return tf_strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n",
        "\n",
        "# Cria a camada de vetorização para os textos em francês\n",
        "french_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size,           # Número máximo de tokens\n",
        "    output_mode=\"int\",               # Saída como inteiros (índices dos tokens)\n",
        "    output_sequence_length=sequence_length,  # Comprimento fixo das sequências\n",
        ")\n",
        "\n",
        "# Cria a camada de vetorização para os textos em português,\n",
        "# utilizando a função de padronização customizada\n",
        "portuguese_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size,                # Número máximo de tokens\n",
        "    output_mode=\"int\",                    # Saída como inteiros (índices dos tokens)\n",
        "    output_sequence_length=sequence_length + 1,  # Comprimento fixo das sequências (+1 para token especial)\n",
        "    standardize=custom_standardization,   # Função customizada para padronização dos textos\n",
        ")\n",
        "\n",
        "# Extrai os textos em francês e português dos pares de treinamento\n",
        "train_french_texts = [pair[0] for pair in train_pairs]      # Lista de textos em francês\n",
        "train_portuguese_texts = [pair[1] for pair in train_pairs]    # Lista de textos em português\n",
        "\n",
        "# Adapta as camadas de vetorização aos textos de treinamento\n",
        "french_vectorization.adapt(train_french_texts)\n",
        "portuguese_vectorization.adapt(train_portuguese_texts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Objetivo do Código: Formatar e Criar Conjuntos de Dados para Treinamento e Validação\n",
        "\n",
        "Este trecho de código define duas funções que transformam os pares de textos em um formato adequado para o treinamento do modelo de tradução. Ele converte os textos em sequências numéricas utilizando as camadas de vetorização previamente definidas e organiza os dados em um dataset do TensorFlow, otimizando o pipeline com operações de batching, caching, embaralhamento e prefetch.\n",
        "\n",
        "#### Passo a Passo do Código:\n",
        "\n",
        "1. **Função `format_dataset`**:\n",
        "   - **Entrada**:\n",
        "     - Recebe duas entradas: `french` e `portuguese`, que são textos em francês e português, respectivamente.\n",
        "   - **Vetorização**:\n",
        "     - Aplica a camada de vetorização `french_vectorization` aos textos em francês, convertendo-os em sequências numéricas.\n",
        "     - Aplica a camada de vetorização `portuguese_vectorization` aos textos em português.\n",
        "   - **Preparação dos Dados para o Modelo Encoder-Decoder**:\n",
        "     - Cria um dicionário contendo:\n",
        "       - `\"encoder_inputs\"`: as sequências numéricas dos textos em francês.\n",
        "       - `\"decoder_inputs\"`: as sequências dos textos em português, mas excluindo o último token (`portuguese[:, :-1]`), preparando os dados para o *teacher forcing*.\n",
        "     - Retorna os rótulos para o decodificador (`decoder_target`), que são as sequências em português deslocadas uma posição para a direita (`portuguese[:, 1:]`), isto é, sem o primeiro token.\n",
        "     \n",
        "2. **Função `make_dataset`**:\n",
        "   - **Entrada**:\n",
        "     - Recebe `pairs`, uma lista de tuplas contendo pares de textos (francês, português).\n",
        "   - **Separação dos Textos**:\n",
        "     - Utiliza `zip(*pairs)` para descompactar os pares em duas listas: `french_texts` e `portuguese_texts`.\n",
        "   - **Criação do Dataset**:\n",
        "     - Converte as listas de textos em um dataset do TensorFlow usando `tf_data.Dataset.from_tensor_slices`.\n",
        "   - **Batching**:\n",
        "     - Agrupa os dados em lotes (batches) utilizando o parâmetro `batch_size` previamente definido.\n",
        "   - **Mapeamento com a Função de Formatação**:\n",
        "     - Aplica a função `format_dataset` a cada batch do dataset para transformar os textos em suas respectivas sequências numéricas e organizar as entradas para o modelo.\n",
        "   - **Otimização do Pipeline**:\n",
        "     - Utiliza `cache()` para armazenar os dados em cache e acelerar o acesso em épocas subsequentes.\n",
        "     - Embaralha os dados com `shuffle(2048)` para aumentar a aleatoriedade.\n",
        "     - Pré-carrega os batches com `prefetch(16)` para otimizar o desempenho durante o treinamento.\n",
        "   - **Retorno**:\n",
        "     - Retorna o dataset otimizado para uso no treinamento ou validação.\n",
        "\n",
        "3. **Criação dos Conjuntos de Dados de Treinamento e Validação**:\n",
        "   - `train_ds = make_dataset(train_pairs)`:\n",
        "     - Cria o dataset de treinamento a partir dos pares de textos definidos para treinamento.\n",
        "   - `val_ds = make_dataset(val_pairs)`:\n",
        "     - Cria o dataset de validação a partir dos pares de textos reservados para validação.\n",
        "\n",
        "Este pipeline assegura que os dados textuais estejam devidamente processados e organizados em um formato compatível com o modelo de tradução, otimizando a leitura e o pré-processamento durante o treinamento.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "BDCoAkUHyVLf"
      },
      "outputs": [],
      "source": [
        "def format_dataset(french, portuguese):\n",
        "    # Aplica a vetorização nos textos em francês\n",
        "    french = french_vectorization(french)\n",
        "    # Aplica a vetorização nos textos em português\n",
        "    portuguese = portuguese_vectorization(portuguese)\n",
        "    # Retorna um dicionário com as entradas para o codificador e decodificador,\n",
        "    # além dos rótulos para o treinamento do decodificador.\n",
        "    return (\n",
        "        {\n",
        "            \"encoder_inputs\": french,          # Entrada para o codificador\n",
        "            \"decoder_inputs\": portuguese[:, :-1],  # Entrada para o decodificador (exclui o último token)\n",
        "        },\n",
        "        portuguese[:, 1:],  # Rótulos para o decodificador (exclui o primeiro token)\n",
        "    )\n",
        "\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    # Separa os textos em francês e português dos pares fornecidos\n",
        "    french_texts, portuguese_texts = zip(*pairs)\n",
        "    french_texts = list(french_texts)\n",
        "    portuguese_texts = list(portuguese_texts)\n",
        "\n",
        "    # Cria um dataset do TensorFlow a partir dos textos\n",
        "    dataset = tf_data.Dataset.from_tensor_slices((french_texts, portuguese_texts))\n",
        "    # Agrupa os exemplos em lotes (batch)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    # Aplica a formatação dos dados utilizando a função format_dataset\n",
        "    dataset = dataset.map(format_dataset)\n",
        "    # Armazena o dataset em cache, embaralha e pré-carrega os lotes para otimizar o desempenho\n",
        "    return dataset.cache().shuffle(2048).prefetch(16)\n",
        "\n",
        "\n",
        "# Cria os datasets de treinamento e validação a partir dos pares correspondentes\n",
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3ChRmWUyX07",
        "outputId": "f6fe926c-8e34-4148-f833-bf28d26742ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inputs[\"encoder_inputs\"].shape: (64, 20)\n",
            "inputs[\"decoder_inputs\"].shape: (64, 20)\n",
            "targets.shape: (64, 20)\n"
          ]
        }
      ],
      "source": [
        "# Itera sobre o primeiro lote do dataset de treinamento\n",
        "for inputs, targets in train_ds.take(1):\n",
        "    # Imprime a forma do tensor que contém as entradas para o codificador\n",
        "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
        "\n",
        "    # Imprime a forma do tensor que contém as entradas para o decodificador\n",
        "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
        "\n",
        "    # Imprime a forma do tensor que contém os alvos (saídas) para o treinamento do decodificador\n",
        "    print(f\"targets.shape: {targets.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Th_pfGu2yZf_",
        "outputId": "322ed110-0e61-487d-bf04-cc8d3b91b192"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\"C'est un organisme unicellulaire.\", 'Plus nous avons, plus nous voulons.', 'Quelle route emprunter ?', \"Tout ce que je veux, c'est ton chat.\", 'Je ne les déboîte pas.']\n",
            "['[start] Esse é um organismo unicelular. [end]', '[start] Quanto mais nós temos, mais nós queremos ter. [end]', '[start] Que caminho tomar? [end]', '[start] Tudo o que eu quero é o seu gato. [end]', '[start] Eu não os desencaixo. [end]']\n"
          ]
        }
      ],
      "source": [
        "# Imprime os 5 primeiros textos em francês dos dados de treinamento\n",
        "print(train_french_texts[:5])\n",
        "\n",
        "# Imprime os 5 primeiros textos em português dos dados de treinamento\n",
        "print(train_portuguese_texts[:5])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Objetivo do Código: Implementar a Camada de Atenção Bahdanau\n",
        "\n",
        "Esta classe define a camada de atenção Bahdanau, uma técnica fundamental em modelos seq2seq que permite ao decoder focar nas partes mais relevantes das saídas do encoder. A camada calcula um vetor de contexto ponderado e os pesos de atenção correspondentes, contribuindo para melhorar a qualidade da tradução ou geração de texto.\n",
        "\n",
        "#### Passo a Passo do Código:\n",
        "\n",
        "1. **Inicialização da Classe (`__init__`)**:\n",
        "   - **Parâmetros**:\n",
        "     - `units`: Número de unidades para as camadas densas internas, definindo a dimensão do espaço de atenção.\n",
        "     - `verbose`: Nível de detalhamento para debug (padrão é 0).\n",
        "   - **Camadas Internas**:\n",
        "     - `self.W1`: Camada densa que transforma a **query** (por exemplo, o estado atual do decoder).\n",
        "     - `self.W2`: Camada densa que transforma os **valores** (por exemplo, as saídas do encoder).\n",
        "     - `self.V`: Camada densa que gera os scores de atenção, reduzindo a soma das transformações a um único valor por posição.\n",
        "\n",
        "2. **Método `call`**:\n",
        "   - **Entradas**:\n",
        "     - `query` (Tensor): Vetor de consulta com shape `(batch_size, hidden_size)`.\n",
        "     - `values` (Tensor): Valores do encoder com shape `(batch_size, time_steps, hidden_size)`.\n",
        "   - **Processamento**:\n",
        "     - **Expansão da Query**:\n",
        "       - A query é expandida com `tf.expand_dims(query, 1)` para criar uma dimensão temporal, resultando em shape `(batch_size, 1, hidden_size)`. Isso permite a soma com os valores, que possuem uma dimensão temporal.\n",
        "     - **Cálculo dos Scores de Atenção**:\n",
        "       - Aplica-se `self.W1` à query expandida e `self.W2` aos valores.\n",
        "       - A soma dessas transformações é passada pela função `tf.nn.tanh` para introduzir não-linearidade.\n",
        "       - A camada `self.V` é aplicada ao resultado, produzindo os scores com shape `(batch_size, time_steps, 1)`.\n",
        "     - **Normalização com Softmax**:\n",
        "       - Os scores são normalizados com `tf.nn.softmax` ao longo do eixo temporal (axis=1), gerando os **pesos de atenção** que indicam a relevância de cada valor.\n",
        "     - **Cálculo do Vetor de Contexto**:\n",
        "       - Os pesos de atenção são multiplicados pelos valores para ponderar a contribuição de cada posição.\n",
        "       - A soma ao longo do eixo temporal (`tf.reduce_sum`) resulta no **vetor de contexto** com shape `(batch_size, hidden_size)`.\n",
        "   - **Saídas**:\n",
        "     - `context_vector`: Vetor de contexto que agrega a informação dos valores com base nos pesos de atenção.\n",
        "     - `attention_weights`: Pesos de atenção, fornecendo uma medida da importância de cada posição da sequência de entrada.\n",
        "\n",
        "Este mecanismo de atenção permite que o decoder acesse dinamicamente informações relevantes do encoder, melhorando a capacidade do modelo de lidar com sequências longas e complexas, e contribuindo para um desempenho superior em tarefas de tradução e outras aplicações em NLP.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "S9n-1i9pzTH_"
      },
      "outputs": [],
      "source": [
        "# Supondo que a classe de atenção Bahdanau já esteja definida corretamente:\n",
        "class BahdanauAttention(layers.Layer):\n",
        "    def __init__(self, units, verbose=0):\n",
        "        \"\"\"\n",
        "        Inicializa a camada de atenção Bahdanau.\n",
        "\n",
        "        Args:\n",
        "            units (int): Número de unidades para as camadas densas internas.\n",
        "            verbose (int, opcional): Nível de detalhamento para debug. Padrão é 0.\n",
        "        \"\"\"\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        # Camadas densas para transformar a query e os valores\n",
        "        self.W1 = layers.Dense(units)\n",
        "        self.W2 = layers.Dense(units)\n",
        "        # Camada densa para gerar os scores de atenção\n",
        "        self.V = layers.Dense(1)\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def call(self, query, values):\n",
        "        \"\"\"\n",
        "        Executa a atenção Bahdanau.\n",
        "\n",
        "        Args:\n",
        "            query (Tensor): Vetor de consulta com shape (batch_size, hidden_size).\n",
        "            values (Tensor): Valores com shape (batch_size, time_steps, hidden_size).\n",
        "\n",
        "        Returns:\n",
        "            context_vector (Tensor): Vetor de contexto com shape (batch_size, hidden_size).\n",
        "            attention_weights (Tensor): Pesos de atenção com shape (batch_size, time_steps, 1).\n",
        "        \"\"\"\n",
        "        # Adiciona uma dimensão temporal à query para permitir a soma com os valores.\n",
        "        # Novo shape: (batch_size, 1, hidden_size)\n",
        "        query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "        # Calcula os scores de atenção combinando a query e os valores.\n",
        "        # A função tanh é aplicada após as transformações lineares.\n",
        "        # Resultado: (batch_size, time_steps, 1)\n",
        "        score = self.V(tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(values)))\n",
        "\n",
        "        # Normaliza os scores usando softmax para obter os pesos de atenção.\n",
        "        # Shape: (batch_size, time_steps, 1)\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "        # Multiplica os pesos de atenção pelos valores para obter o vetor de contexto.\n",
        "        # Shape intermediário: (batch_size, time_steps, hidden_size)\n",
        "        context_vector = attention_weights * values\n",
        "\n",
        "        # Reduz a soma ao longo do eixo temporal para combinar as informações.\n",
        "        # Shape final: (batch_size, hidden_size)\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "        return context_vector, attention_weights\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Objetivo do Código: Aplicar a Atenção de Forma Distribuída no Tempo aos Outputs do Decodificador\n",
        "\n",
        "Esta classe, `TimeDistributedAttention`, é uma camada customizada que permite aplicar uma camada de atenção (por exemplo, Bahdanau) a cada timestep dos outputs do decodificador de um modelo seq2seq. Isso possibilita que, para cada instante temporal do decodificador, seja calculado um vetor de contexto que reflete a relevância dos estados do encoder naquele instante, contribuindo para uma melhor performance no processo de decodificação.\n",
        "\n",
        "#### Passo a Passo do Código:\n",
        "\n",
        "1. **Inicialização da Camada (`__init__`)**:\n",
        "   - **Parâmetro**:\n",
        "     - `attention_layer`: Uma instância de uma camada de atenção (por exemplo, uma implementação de BahdanauAttention) que será aplicada a cada timestep.\n",
        "   - **Processamento**:\n",
        "     - A classe herda de `layers.Layer` e inicializa a camada pai utilizando `super()`.\n",
        "     - Armazena a camada de atenção fornecida na variável `self.attention_layer`.\n",
        "\n",
        "2. **Método `call`**:\n",
        "   - **Entrada**:\n",
        "     - `inputs`: Uma lista contendo dois tensores:\n",
        "       - `decoder_outputs`: Saídas do decodificador com shape `(batch_size, dec_timesteps, latentSpaceDimension)`.\n",
        "       - `encoder_outputs`: Saídas do encoder com shape `(batch_size, enc_timesteps, latentSpaceDimension)`.\n",
        "   - **Processamento**:\n",
        "     - **Desempacotamento das Entradas**:\n",
        "       - Os tensores de `decoder_outputs` e `encoder_outputs` são extraídos da lista `inputs`.\n",
        "     - **Transposição dos Outputs do Decodificador**:\n",
        "       - Transpõe `decoder_outputs` de modo que o eixo temporal (timestep) fique como primeiro eixo, transformando o shape para `(dec_timesteps, batch_size, latentSpaceDimension)`. Essa transposição facilita a aplicação da atenção para cada timestep individualmente.\n",
        "     - **Definição da Função Interna `apply_attention`**:\n",
        "       - Essa função é aplicada a cada vetor de timestep do decodificador.\n",
        "       - **Entrada**:\n",
        "         - `decoder_timestep`: Vetor referente a um único timestep, com shape `(batch_size, latentSpaceDimension)`.\n",
        "       - **Processamento**:\n",
        "         - Utiliza o vetor do timestep como *query* para a camada de atenção, passando-o juntamente com `encoder_outputs` como *values*.\n",
        "         - Calcula o vetor de contexto (e os pesos de atenção, que não são utilizados posteriormente) para esse timestep.\n",
        "       - **Saída**:\n",
        "         - Retorna o vetor de contexto para o timestep, com shape `(batch_size, latentSpaceDimension)`.\n",
        "     - **Aplicação da Atenção em Cada Timestep**:\n",
        "       - Utiliza `tf.map_fn` para aplicar a função `apply_attention` a cada elemento do tensor transposto `decoder_outputs_transposed`.\n",
        "       - O resultado é um tensor com shape `(dec_timesteps, batch_size, latentSpaceDimension)`.\n",
        "     - **Retorno ao Formato Original**:\n",
        "       - Transpõe o tensor resultante de volta para o formato original, resultando em um tensor `context_sequence` com shape `(batch_size, dec_timesteps, latentSpaceDimension)`.\n",
        "   - **Saída do Método**:\n",
        "     - Retorna `context_sequence`, que é a sequência de vetores de contexto calculados para cada timestep do decodificador.\n",
        "\n",
        "#### Considerações Adicionais:\n",
        "- **Uso de `tf.map_fn`**:\n",
        "  - Essa função permite iterar sobre o eixo temporal, aplicando a função de atenção para cada timestep de forma independente.\n",
        "- **Integração com Modelos Seq2Seq**:\n",
        "  - A camada `TimeDistributedAttention` pode ser integrada ao pipeline do modelo, combinando os outputs do decodificador com os estados do encoder para fornecer informações contextuais em cada passo de decodificação.\n",
        "\n",
        "Este mecanismo de atenção distribuída no tempo melhora a capacidade do modelo de se concentrar dinamicamente nas partes relevantes da entrada durante o processo de decodificação, contribuindo para resultados mais precisos em tarefas como tradução automática e geração de linguagem natural.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "n7gZa9u_7J9Q"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Camada customizada para aplicar a atenção para cada timestep do decodificador\n",
        "class TimeDistributedAttention(layers.Layer):\n",
        "    def __init__(self, attention_layer, **kwargs):\n",
        "        \"\"\"\n",
        "        Inicializa a camada de atenção distribuída no tempo.\n",
        "\n",
        "        Args:\n",
        "            attention_layer (layers.Layer): Instância da camada de atenção a ser aplicada.\n",
        "            **kwargs: Argumentos adicionais para a camada pai.\n",
        "        \"\"\"\n",
        "        super(TimeDistributedAttention, self).__init__(**kwargs)\n",
        "        self.attention_layer = attention_layer\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        Aplica a atenção a cada timestep dos outputs do decodificador.\n",
        "\n",
        "        Args:\n",
        "            inputs (list): Lista contendo [decoder_outputs, encoder_outputs] onde:\n",
        "                - decoder_outputs: (batch_size, dec_timesteps, latentSpaceDimension)\n",
        "                - encoder_outputs: (batch_size, enc_timesteps, latentSpaceDimension)\n",
        "\n",
        "        Returns:\n",
        "            context_sequence (Tensor): Sequência de vetores de contexto para cada timestep do decodificador,\n",
        "                                       com shape (batch_size, dec_timesteps, latentSpaceDimension).\n",
        "        \"\"\"\n",
        "        # Desempacota as entradas: outputs do decodificador e do codificador\n",
        "        decoder_outputs, encoder_outputs = inputs\n",
        "\n",
        "        # Transpõe os outputs do decodificador para iterar sobre o eixo temporal.\n",
        "        # Novo shape: (dec_timesteps, batch_size, latentSpaceDimension)\n",
        "        decoder_outputs_transposed = tf.transpose(decoder_outputs, perm=[1, 0, 2])\n",
        "\n",
        "        # Função que aplica a atenção para um único timestep do decodificador.\n",
        "        def apply_attention(decoder_timestep):\n",
        "            \"\"\"\n",
        "            Aplica a atenção para um timestep específico.\n",
        "\n",
        "            Args:\n",
        "                decoder_timestep (Tensor): Vetor do timestep do decodificador com shape (batch_size, latentSpaceDimension).\n",
        "\n",
        "            Returns:\n",
        "                context (Tensor): Vetor de contexto calculado para o timestep com shape (batch_size, latentSpaceDimension).\n",
        "            \"\"\"\n",
        "            # Utiliza o vetor do timestep como query para calcular a atenção sobre os encoder_outputs.\n",
        "            context, _ = self.attention_layer(decoder_timestep, encoder_outputs)\n",
        "            return context\n",
        "\n",
        "        # Aplica a função de atenção para cada timestep usando tf.map_fn.\n",
        "        # O resultado possui shape: (dec_timesteps, batch_size, latentSpaceDimension)\n",
        "        context_sequence_transposed = tf.map_fn(\n",
        "            apply_attention,\n",
        "            decoder_outputs_transposed,\n",
        "            fn_output_signature=tf.float32\n",
        "        )\n",
        "\n",
        "        # Transpõe de volta para o formato original: (batch_size, dec_timesteps, latentSpaceDimension)\n",
        "        context_sequence = tf.transpose(context_sequence_transposed, perm=[1, 0, 2])\n",
        "        return context_sequence\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Objetivo do Código: Implementar uma Camada de Embedding Posicional\n",
        "\n",
        "Esta classe, `PositionalEmbedding`, define uma camada customizada que combina os embeddings dos tokens com embeddings de posição. Essa técnica é crucial em modelos que processam sequências, pois permite que o modelo incorpore informações sobre a ordem dos tokens, além das suas representações semânticas.\n",
        "\n",
        "#### Passo a Passo do Código:\n",
        "\n",
        "1. **Definição da Classe e Inicialização (`__init__`)**:\n",
        "   - **Parâmetros de Inicialização**:\n",
        "     - `sequence_length`: Comprimento máximo da sequência, determinando o número de posições possíveis.\n",
        "     - `vocab_size`: Tamanho do vocabulário, ou seja, o número total de tokens únicos que serão representados.\n",
        "     - `embed_dim`: Dimensão dos embeddings, que define o tamanho dos vetores que representarão cada token e cada posição.\n",
        "     - `**kwargs`: Permite passar argumentos adicionais para a classe base (`layers.Layer`).\n",
        "   - **Criação das Camadas de Embedding**:\n",
        "     - `self.token_embeddings`: Uma camada `Embedding` que mapeia os índices dos tokens para vetores de dimensão `embed_dim`.\n",
        "     - `self.position_embeddings`: Uma camada `Embedding` que mapeia os índices de posição (de 0 até `sequence_length - 1`) para vetores de dimensão `embed_dim`.\n",
        "   - **Armazenamento de Parâmetros**:\n",
        "     - Os parâmetros `sequence_length`, `vocab_size` e `embed_dim` são armazenados como atributos da classe para referência posterior, inclusive na serialização da camada.\n",
        "\n",
        "2. **Método `call`**:\n",
        "   - **Entrada**:\n",
        "     - `inputs`: Tensor contendo índices dos tokens com shape `(batch_size, sequence_length)`.\n",
        "   - **Processamento**:\n",
        "     - **Embedding dos Tokens**:\n",
        "       - Aplica `self.token_embeddings` ao tensor `inputs` para obter os embeddings dos tokens com shape `(batch_size, sequence_length, embed_dim)`.\n",
        "     - **Criação e Processamento dos Embeddings de Posição**:\n",
        "       - Cria um tensor constante `positions` que contém uma sequência de índices de 0 até `sequence_length - 1` utilizando `tf.range()`.\n",
        "       - Passa os índices de posição pela camada `self.position_embeddings` para obter os embeddings correspondentes, com shape `(sequence_length, embed_dim)`.\n",
        "       - Expande a dimensão dos embeddings de posição para `(1, sequence_length, embed_dim)` com `tf.expand_dims()`, permitindo a soma com os embeddings dos tokens para cada amostra no batch.\n",
        "     - **Soma dos Embeddings**:\n",
        "       - Soma os embeddings dos tokens com os embeddings das posições para incorporar a informação de posição em cada token.\n",
        "   - **Saída**:\n",
        "     - Retorna um tensor com shape `(batch_size, sequence_length, embed_dim)`, onde cada token foi enriquecido com a informação da sua posição na sequência.\n",
        "\n",
        "3. **Método `get_config`**:\n",
        "   - **Objetivo**:\n",
        "     - Permitir a serialização da camada, facilitando a salvaguarda e a reconstrução do modelo.\n",
        "   - **Processamento**:\n",
        "     - Obtém a configuração da camada base com `super().get_config()`.\n",
        "     - Atualiza o dicionário de configuração com os parâmetros `sequence_length`, `vocab_size` e `embed_dim`.\n",
        "   - **Saída**:\n",
        "     - Retorna um dicionário com a configuração completa da camada.\n",
        "\n",
        "Esta camada é frequentemente utilizada em arquiteturas modernas de NLP (como Transformers) para garantir que o modelo não apenas entenda os tokens isoladamente, mas também a ordem e a posição relativa dos tokens dentro da sequência.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "uBJUAf9SyaOr"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model, Input\n",
        "\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    \"\"\"\n",
        "    Camada de embedding posicional que soma os embeddings dos tokens e das posições.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
        "        \"\"\"\n",
        "        Inicializa a camada de embedding posicional.\n",
        "\n",
        "        Args:\n",
        "            sequence_length (int): Comprimento máximo da sequência.\n",
        "            vocab_size (int): Tamanho do vocabulário.\n",
        "            embed_dim (int): Dimensão dos embeddings.\n",
        "            **kwargs: Argumentos adicionais para a classe base.\n",
        "        \"\"\"\n",
        "        super().__init__(**kwargs)\n",
        "        # Embedding para os tokens com dimensão de entrada igual ao tamanho do vocabulário\n",
        "        # e dimensão de saída igual a embed_dim\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=vocab_size, output_dim=embed_dim\n",
        "        )\n",
        "        # Embedding para as posições com dimensão de entrada igual ao comprimento da sequência\n",
        "        # e dimensão de saída igual a embed_dim\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=embed_dim\n",
        "        )\n",
        "        self.sequence_length = sequence_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        Soma os embeddings dos tokens e das posições.\n",
        "\n",
        "        Args:\n",
        "            inputs (Tensor): Tensores contendo índices dos tokens com shape\n",
        "                             (batch_size, sequence_length).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Soma dos embeddings dos tokens e das posições com shape\n",
        "                    (batch_size, sequence_length, embed_dim).\n",
        "        \"\"\"\n",
        "        # Obtém os embeddings dos tokens: shape (batch_size, sequence_length, embed_dim)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "\n",
        "        # Cria um tensor constante com as posições: shape (sequence_length,)\n",
        "        positions = tf.range(start=0, limit=self.sequence_length, delta=1)\n",
        "\n",
        "        # Obtém os embeddings das posições: shape (sequence_length, embed_dim)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "\n",
        "        # Expande a dimensão para que os embeddings das posições possam ser somados\n",
        "        # aos embeddings dos tokens em todas as amostras do batch.\n",
        "        # Novo shape: (1, sequence_length, embed_dim)\n",
        "        embedded_positions = tf.expand_dims(embedded_positions, axis=0)\n",
        "\n",
        "        # Retorna a soma dos embeddings dos tokens com os embeddings das posições\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"\n",
        "        Retorna a configuração da camada para possibilitar a serialização.\n",
        "\n",
        "        Returns:\n",
        "            dict: Dicionário de configuração da camada.\n",
        "        \"\"\"\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"sequence_length\": self.sequence_length,\n",
        "            \"vocab_size\": self.vocab_size,\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "        })\n",
        "        return config\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Objetivo do Código: Implementar uma Célula LSTM com Mecanismo de Atenção Integrada\n",
        "\n",
        "Esta classe, `AttentionLSTMCell`, implementa uma célula LSTM customizada que integra um mecanismo de atenção em cada passo de tempo. Essa abordagem permite que a célula utilize informações contextuais do encoder para influenciar a geração da saída no decoder, combinando a robustez da LSTM com a capacidade de focar em partes relevantes da entrada.\n",
        "\n",
        "#### Passo a Passo do Código:\n",
        "\n",
        "1. **Inicialização da Célula (`__init__`)**:\n",
        "   - **Parâmetros**:\n",
        "     - `units` (int): Número de unidades da LSTM, determinando a dimensionalidade dos estados internos.\n",
        "     - `attention_layer` (layers.Layer): Instância da camada de atenção (por exemplo, BahdanauAttention) que será aplicada para calcular o vetor de contexto.\n",
        "     - `**kwargs`: Argumentos adicionais para a camada base.\n",
        "   - **Processamento**:\n",
        "     - Armazena o número de unidades em `self.units`.\n",
        "     - A camada de atenção é armazenada em `self.attention_layer`.\n",
        "     - Cria uma instância padrão de `layers.LSTMCell` com o número de unidades especificado, armazenada em `self.lstm_cell`.\n",
        "\n",
        "2. **Definição das Propriedades de Estado e Saída**:\n",
        "   - **`state_size`**:\n",
        "     - Retorna uma lista que define os tamanhos dos estados internos da célula:\n",
        "       - **hidden**: Vetor oculto com dimensão `units`.\n",
        "       - **cell**: Vetor da célula com dimensão `units`.\n",
        "       - **prev_attention**: Vetor de atenção do timestep anterior com dimensão `units` (usado para input feeding).\n",
        "       - **encoder_outputs**: Estados do encoder com shape `(None, units)`, onde `None` indica que o número de timesteps pode variar.\n",
        "   - **`output_size`**:\n",
        "     - Define o tamanho da saída da célula como a soma das dimensões do novo estado oculto e do vetor de contexto, resultando em `units + units`.\n",
        "\n",
        "3. **Método `call`**:\n",
        "   - **Entradas**:\n",
        "     - `inputs` (Tensor): Embedding do token atual, com shape `(batch_size, embed_dim)`.\n",
        "     - `states` (lista): Contém os estados anteriores no seguinte formato:\n",
        "       - `hidden`: Estado oculto da LSTM.\n",
        "       - `cell`: Estado da célula da LSTM.\n",
        "       - `prev_attention`: Vetor de atenção do timestep anterior (para input feeding).\n",
        "       - `encoder_outputs`: Saídas do encoder, que permanecem constantes durante a decodificação.\n",
        "   - **Processamento**:\n",
        "     - **Input Feeding**:\n",
        "       - Concatena o embedding do token atual (`inputs`) com o vetor de atenção do timestep anterior (`prev_attention`) usando `tf.concat`. Isso fornece à LSTM um contexto adicional sobre a atenção calculada anteriormente.\n",
        "     - **Passagem pela LSTMCell**:\n",
        "       - O vetor combinado (`input_combined`) é processado pela célula LSTM padrão (`self.lstm_cell`), gerando um novo estado oculto (`new_hidden`) e um novo estado da célula (`new_cell`).\n",
        "     - **Cálculo da Atenção**:\n",
        "       - Utiliza a camada de atenção (`self.attention_layer`) para calcular o vetor de contexto. O `new_hidden` é usado como *query* e `encoder_outputs` como *values*. O mecanismo retorna o vetor de contexto (`context_vector`) e os pesos de atenção (que podem ser utilizados para interpretação, mas não são propagados adiante neste contexto).\n",
        "     - **Formação da Saída**:\n",
        "       - A saída da célula é definida como a concatenação do novo estado oculto (`new_hidden`) com o vetor de contexto (`context_vector`), formando `new_output` com dimensão `units + units`.\n",
        "     - **Atualização dos Estados**:\n",
        "       - Os estados são atualizados para o próximo timestep com a lista:\n",
        "         - `new_hidden`: O novo estado oculto.\n",
        "         - `new_cell`: O novo estado da célula.\n",
        "         - `context_vector`: O vetor de contexto atual, que servirá como `prev_attention` no próximo timestep.\n",
        "         - `encoder_outputs`: Mantido inalterado, pois os outputs do encoder não variam durante a decodificação.\n",
        "   - **Saída**:\n",
        "     - Retorna uma tupla contendo:\n",
        "       - `new_output`: A saída combinada da célula para o timestep atual.\n",
        "       - `new_state`: A lista atualizada dos estados para uso no próximo timestep.\n",
        "\n",
        "Este design permite que o modelo integre de maneira eficaz o mecanismo de atenção dentro do fluxo recursivo da LSTM, melhorando a capacidade do decoder de acessar informações relevantes do encoder em cada passo do processo de geração de sequência.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "RHW-79jt5ZYr"
      },
      "outputs": [],
      "source": [
        "class AttentionLSTMCell(layers.Layer):\n",
        "    \"\"\"\n",
        "    Célula LSTM com mecanismo de atenção integrada.\n",
        "    Esta célula utiliza um mecanismo de atenção (attention_layer)\n",
        "    para calcular um vetor de contexto a cada timestep, que é concatenado\n",
        "    com o novo estado oculto da LSTM para formar a saída.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, units, attention_layer, **kwargs):\n",
        "        \"\"\"\n",
        "        Inicializa a célula LSTM com atenção.\n",
        "\n",
        "        Args:\n",
        "            units (int): Número de unidades da LSTM.\n",
        "            attention_layer (layers.Layer): Camada de atenção a ser utilizada.\n",
        "            **kwargs: Argumentos adicionais.\n",
        "        \"\"\"\n",
        "        super(AttentionLSTMCell, self).__init__(**kwargs)\n",
        "        self.units = units  # Número de unidades para a LSTM\n",
        "        self.attention_layer = attention_layer  # Mecanismo de atenção a ser aplicado\n",
        "        self.lstm_cell = layers.LSTMCell(units)  # Instância da célula LSTM padrão\n",
        "\n",
        "    @property\n",
        "    def state_size(self):\n",
        "        \"\"\"\n",
        "        Define o tamanho dos estados internos da célula.\n",
        "\n",
        "        Retorna uma lista contendo:\n",
        "          - hidden: vetor oculto com dimensão (units)\n",
        "          - cell: vetor de célula com dimensão (units)\n",
        "          - prev_attention: vetor de atenção do timestep anterior com dimensão (units)\n",
        "          - encoder_outputs: estados do encoder com shape (None, units)\n",
        "            (None indica que o número de timesteps do encoder pode variar)\n",
        "        \"\"\"\n",
        "        return [self.units, self.units, self.units, tf.TensorShape([None, self.units])]\n",
        "\n",
        "    @property\n",
        "    def output_size(self):\n",
        "        \"\"\"\n",
        "        Define o tamanho da saída da célula.\n",
        "\n",
        "        A saída é a concatenação do novo estado oculto e do vetor de contexto,\n",
        "        portanto, sua dimensão é a soma das dimensões dos dois vetores.\n",
        "        \"\"\"\n",
        "        return self.units + self.units\n",
        "\n",
        "    def call(self, inputs, states):\n",
        "        \"\"\"\n",
        "        Executa um passo de tempo da célula LSTM com atenção.\n",
        "\n",
        "        Args:\n",
        "            inputs (Tensor): Embedding do token atual com shape (batch_size, embed_dim).\n",
        "            states (list): Lista contendo os estados anteriores:\n",
        "                [hidden, cell, prev_attention, encoder_outputs]\n",
        "\n",
        "        Retorna:\n",
        "            new_output (Tensor): Saída da célula com shape (batch_size, output_size),\n",
        "                                 que é a concatenação do novo estado oculto e do vetor de contexto.\n",
        "            new_state (list): Lista atualizada dos estados, mantendo os valores para:\n",
        "                              [new_hidden, new_cell, context_vector, encoder_outputs].\n",
        "        \"\"\"\n",
        "        # Desempacota os estados: hidden, cell, atenção anterior e outputs do encoder\n",
        "        hidden, cell, prev_attention, encoder_outputs = states\n",
        "\n",
        "        # Concatena o embedding do token atual com o vetor de atenção do timestep anterior (input feeding)\n",
        "        input_combined = tf.concat([inputs, prev_attention], axis=-1)\n",
        "\n",
        "        # Processa o input combinado pela LSTMCell para obter o novo estado oculto e o novo estado da célula\n",
        "        output, [new_hidden, new_cell] = self.lstm_cell(input_combined, [hidden, cell])\n",
        "\n",
        "        # Calcula a atenção utilizando o novo estado oculto como query e os outputs do encoder como values\n",
        "        context_vector, attention_weights = self.attention_layer(new_hidden, encoder_outputs)\n",
        "\n",
        "        # Define a saída da célula como a concatenação do novo estado oculto com o vetor de contexto\n",
        "        new_output = tf.concat([new_hidden, context_vector], axis=-1)\n",
        "\n",
        "        # Atualiza os estados:\n",
        "        # - new_hidden: novo estado oculto da LSTM\n",
        "        # - new_cell: novo estado da célula da LSTM\n",
        "        # - context_vector: vetor de contexto obtido pela atenção (será usado no próximo timestep)\n",
        "        # - encoder_outputs: permanece constante ao longo da decodificação\n",
        "        new_state = [new_hidden, new_cell, context_vector, encoder_outputs]\n",
        "\n",
        "        return new_output, new_state\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Objetivo do Código: Construir o Encoder e o Decoder com Mecanismo de Atenção Integrada\n",
        "\n",
        "Este trecho de código implementa a arquitetura de um modelo seq2seq que utiliza um encoder baseado em LSTM e um decoder customizado com um mecanismo de atenção. O objetivo é mapear uma sequência de entrada (por exemplo, em uma tarefa de tradução) para uma sequência de saída, permitindo que o decoder acesse dinamicamente as informações relevantes dos outputs do encoder por meio de atenção.\n",
        "\n",
        "---\n",
        "\n",
        "#### 1. Adaptação dos Outputs do Encoder para o Espaço Latente\n",
        "\n",
        "- **Camada Densa Adaptadora**:\n",
        "  - `encoder_adapter = layers.Dense(latentSpaceDimension, activation='relu', name='encoder_adapter')`\n",
        "  - Essa camada transforma os outputs do encoder para o espaço latente definido por `latentSpaceDimension`, utilizando a ativação ReLU para introduzir não-linearidade.\n",
        "\n",
        "---\n",
        "\n",
        "#### 2. Construção do Encoder\n",
        "\n",
        "- **Entrada do Encoder**:\n",
        "  - `encoder_inputs = Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")`\n",
        "  - Recebe sequências de índices (tokens) de comprimento variável.\n",
        "\n",
        "- **Embedding Posicional**:\n",
        "  - `encoder_embed = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)`\n",
        "  - Aplica a camada de embedding posicional para incorporar tanto as representações dos tokens quanto as informações de posição.\n",
        "\n",
        "- **LSTM do Encoder**:\n",
        "  - `encoder_lstm = layers.LSTM(latentSpaceDimension, return_sequences=True, return_state=True, name='encoder_lstm')`\n",
        "  - Processa a sequência de embeddings e retorna:\n",
        "    - `encoder_outputs`: Sequência de saídas em cada timestep.\n",
        "    - `state_h` e `state_c`: Estados finais (oculto e célula), que serão utilizados para inicializar o decoder.\n",
        "  - Armazena os estados finais em `encoder_states = [state_h, state_c]`.\n",
        "\n",
        "- **Adaptação dos Outputs do Encoder**:\n",
        "  - `adapted_encoder_outputs = encoder_adapter(encoder_outputs)`\n",
        "  - Os outputs do encoder são transformados para o espaço latente, fornecendo informações contextuais a serem usadas pela camada de atenção no decoder.\n",
        "\n",
        "---\n",
        "\n",
        "#### 3. Construção do Decoder\n",
        "\n",
        "- **Entrada do Decoder**:\n",
        "  - `decoder_inputs = Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")`\n",
        "  - Recebe sequências de índices (tokens) de comprimento variável que representam a entrada do decoder.\n",
        "\n",
        "- **Embedding dos Tokens do Decoder**:\n",
        "  - `decoder_embeddings = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)(decoder_inputs)`\n",
        "  - Converte os tokens do decoder em vetores de embedding.\n",
        "\n",
        "- **Configuração do Decoder com Atenção**:\n",
        "  - **Custom Attention LSTM Cell**:\n",
        "    - `attention_cell = AttentionLSTMCell(latentSpaceDimension, attention_layer)`\n",
        "    - Utiliza uma célula LSTM customizada que integra um mecanismo de atenção (por meio de `attention_layer`) para calcular, a cada timestep, um vetor de contexto que auxilia o decoder.\n",
        "  - **Camada RNN com a Célula Customizada**:\n",
        "    - `decoder_rnn = layers.RNN(attention_cell, return_sequences=True, return_state=True)`\n",
        "    - Cria uma camada RNN que processará os embeddings do decoder utilizando a célula customizada de LSTM com atenção.\n",
        "\n",
        "- **Inicialização do Vetor de Atenção**:\n",
        "  - **Função Auxiliar**:\n",
        "    - ```python\n",
        "      def get_initial_attention(x):\n",
        "          batch_size = tf.shape(x)[0]\n",
        "          return tf.zeros((batch_size, latentSpaceDimension), dtype=tf.float32)\n",
        "      ```\n",
        "    - Essa função gera um vetor de zeros para cada exemplo no batch, servindo como o vetor de atenção inicial.\n",
        "  - **Cálculo do Vetor de Atenção Inicial**:\n",
        "    - `initial_attention = layers.Lambda(get_initial_attention)(state_h)`\n",
        "    - Utiliza o estado oculto do encoder (`state_h`) para determinar o batch size e inicializa o vetor de atenção com zeros.\n",
        "\n",
        "- **Definição do Estado Inicial do Decoder**:\n",
        "  - `initial_state = encoder_states + [initial_attention, adapted_encoder_outputs]`\n",
        "  - O estado inicial do decoder é composto por:\n",
        "    - `state_h` e `state_c`: Estados finais do encoder.\n",
        "    - `initial_attention`: Vetor de atenção inicial (zeros).\n",
        "    - `adapted_encoder_outputs`: Outputs do encoder adaptados para o espaço latente, que servirão como valores para o mecanismo de atenção durante a decodificação.\n",
        "\n",
        "- **Execução da RNN do Decoder**:\n",
        "  - `decoder_rnn_outputs = decoder_rnn(decoder_embeddings, initial_state=initial_state)`\n",
        "  - Processa os embeddings do decoder utilizando o estado inicial definido.\n",
        "  - A camada RNN retorna uma tupla onde o primeiro elemento é a sequência resultante dos outputs processados.\n",
        "\n",
        "- **Extração dos Outputs do Decoder**:\n",
        "  - `decoder_outputs = decoder_rnn_outputs[0]`\n",
        "  - Essa variável contém a sequência de saídas do decoder, que poderá ser posteriormente transformada (por exemplo, via uma camada densa) para predição dos tokens de saída.\n",
        "\n",
        "---\n",
        "\n",
        "#### Resumo do Fluxo do Modelo\n",
        "\n",
        "1. **Encoder**:\n",
        "   - Recebe uma sequência de tokens, aplica embeddings posicionais e processa a sequência com uma LSTM.\n",
        "   - Os outputs do encoder são adaptados para um espaço latente e os estados finais são capturados.\n",
        "\n",
        "2. **Decoder**:\n",
        "   - Recebe uma sequência de tokens de entrada (por exemplo, tokens de início para geração de sequência).\n",
        "   - Converte os tokens em embeddings e os processa por uma camada RNN que utiliza uma célula LSTM com atenção.\n",
        "   - O mecanismo de atenção utiliza os estados do encoder para calcular, a cada timestep, um vetor de contexto que é combinado com o novo estado oculto para formar a saída do decoder.\n",
        "\n",
        "Este design integra de forma robusta o mecanismo de atenção ao fluxo recursivo do decoder, permitindo que o modelo foque em partes relevantes da sequência de entrada a cada passo de decodificação, o que é crucial para tarefas como tradução automática, sumarização e outras aplicações em NLP.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEmxKVc0TUst",
        "outputId": "1c7ff268-4749-49a7-f76b-aa27986138bf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/bruno/Documents/unb/tema/.venv/lib/python3.10/site-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'attention_lstm_cell_3', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Camada densa para adaptar os outputs do encoder para o espaço latente\n",
        "encoder_adapter = layers.Dense(latentSpaceDimension, activation='relu', name='encoder_adapter')\n",
        "\n",
        "# --- Parâmetros e camadas de embedding (assumindo que já estejam definidos) ---\n",
        "# sequence_length: comprimento máximo da sequência\n",
        "# vocab_size: tamanho do vocabulário\n",
        "# embed_dim: dimensão dos embeddings dos tokens\n",
        "# latentSpaceDimension: dimensão do espaço latente\n",
        "\n",
        "# --- Encoder ---\n",
        "# Entrada para o encoder: sequência de índices (tokens) com tamanho variável\n",
        "encoder_inputs = Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "# Aplica o embedding posicional nos tokens do encoder\n",
        "encoder_embed = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "# Camada LSTM do encoder que retorna tanto as sequências quanto os estados finais\n",
        "encoder_lstm = layers.LSTM(latentSpaceDimension,\n",
        "                           return_sequences=True,\n",
        "                           return_state=True,\n",
        "                           name='encoder_lstm')\n",
        "# Processa a sequência de embeddings e obtém os outputs e os estados finais (hidden e cell)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embed)\n",
        "# Armazena os estados finais do encoder para uso posterior no decoder\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Adapta os outputs do encoder para o espaço latente usando a camada densa definida anteriormente\n",
        "adapted_encoder_outputs = encoder_adapter(encoder_outputs)\n",
        "\n",
        "# --- Decoder ---\n",
        "# Entrada para o decoder: sequência de índices (tokens) com tamanho variável\n",
        "decoder_inputs = Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "# Aplica a camada de embedding para os tokens do decoder\n",
        "decoder_embeddings = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)(decoder_inputs)\n",
        "\n",
        "# Cria o cell customizado de LSTM com atenção (input feeding) utilizando a AttentionLSTMCell\n",
        "attention_cell = AttentionLSTMCell(latentSpaceDimension, attention_layer)\n",
        "# Cria uma camada RNN que utiliza a célula customizada, retornando sequências e estados\n",
        "decoder_rnn = layers.RNN(attention_cell, return_sequences=True, return_state=True)\n",
        "\n",
        "# Função auxiliar para inicializar o vetor de atenção com zeros para cada exemplo do batch\n",
        "def get_initial_attention(x):\n",
        "    batch_size = tf.shape(x)[0]\n",
        "    return tf.zeros((batch_size, latentSpaceDimension), dtype=tf.float32)\n",
        "\n",
        "# Inicializa o vetor de atenção com zeros, utilizando o estado hidden do encoder como base para definir o batch size\n",
        "initial_attention = layers.Lambda(get_initial_attention)(state_h)\n",
        "\n",
        "# Define o estado inicial do decoder como a combinação dos estados do encoder e o vetor de atenção inicial:\n",
        "# [hidden, cell, prev_attention, adapted_encoder_outputs]\n",
        "initial_state = encoder_states + [initial_attention, adapted_encoder_outputs]\n",
        "\n",
        "# Executa a RNN do decoder, processando os embeddings do decoder com o estado inicial definido\n",
        "decoder_rnn_outputs = decoder_rnn(decoder_embeddings, initial_state=initial_state)\n",
        "# A saída do decoder é a sequência resultante (primeiro elemento do retorno da RNN)\n",
        "decoder_outputs = decoder_rnn_outputs[0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Objetivo do Código: Construir e Compilar o Modelo Seq2Seq com Mecanismo de Atenção e Input Feeding\n",
        "\n",
        "Este trecho final de código monta o modelo seq2seq, integrando o decoder com o mecanismo de atenção e input feeding. A camada densa final converte os outputs do decoder em predições sobre o vocabulário, e o modelo é compilado com o otimizador Adam e a função de perda de entropia cruzada esparsa.\n",
        "\n",
        "#### Passo a Passo do Código:\n",
        "\n",
        "1. **Camada Densa Final para Geração de Predições**:\n",
        "   - **Definição da Camada**:\n",
        "     - ```python\n",
        "       decoder_dense = layers.Dense(vocab_size, activation='softmax', name='decoder_dense')\n",
        "       ```\n",
        "     - Esta camada transforma os outputs do decoder em uma distribuição de probabilidade sobre o vocabulário, utilizando a ativação `softmax` para garantir que as probabilidades somem 1.\n",
        "\n",
        "   - **Aplicação da Camada aos Outputs do Decoder**:\n",
        "     - ```python\n",
        "       final_outputs = decoder_dense(decoder_outputs)\n",
        "       ```\n",
        "     - Os outputs processados pelo decoder são passados pela camada densa, gerando as predições finais.\n",
        "\n",
        "2. **Definição do Modelo Final**:\n",
        "   - **Construção do Modelo**:\n",
        "     - ```python\n",
        "       model = Model([encoder_inputs, decoder_inputs], final_outputs, name='seq2seq_input_feeding')\n",
        "       ```\n",
        "     - O modelo é definido para receber duas entradas:\n",
        "       - `encoder_inputs`: Sequência de tokens para o encoder.\n",
        "       - `decoder_inputs`: Sequência de tokens para o decoder.\n",
        "     - A saída do modelo são as predições finais (`final_outputs`), que representam a distribuição de probabilidade sobre o vocabulário para cada posição na sequência de saída.\n",
        "\n",
        "3. **Compilação do Modelo**:\n",
        "   - **Configuração da Compilação**:\n",
        "     - ```python\n",
        "       model.compile(optimizer='adam',\n",
        "                     loss='sparse_categorical_crossentropy',\n",
        "                     metrics=['accuracy'])\n",
        "       ```\n",
        "     - O modelo é compilado com:\n",
        "       - **Otimizador**: `adam`, que adapta os parâmetros durante o treinamento.\n",
        "       - **Função de Perda**: `sparse_categorical_crossentropy`, apropriada para classificação multi-classe onde os rótulos são inteiros.\n",
        "       - **Métrica**: `accuracy`, para monitorar a performance do modelo durante o treinamento e a validação.\n",
        "\n",
        "4. **Exibição do Resumo da Arquitetura do Modelo**:\n",
        "   - **Resumo do Modelo**:\n",
        "     - ```python\n",
        "       model.summary()\n",
        "       ```\n",
        "     - Imprime um resumo detalhado da arquitetura do modelo, mostrando as camadas, a forma dos tensores e o número de parâmetros treináveis.\n",
        "\n",
        "---\n",
        "\n",
        "Este modelo seq2seq, que integra mecanismos de atenção com input feeding, está preparado para tarefas de tradução, sumarização ou outras aplicações de processamento de linguagem natural, onde é essencial que o decoder tenha acesso contextual dinâmico às informações processadas pelo encoder.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "H6kTExKzyeId",
        "outputId": "e2482b2c-1b7a-4e6e-ed12-943dd5cf17a5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"seq2seq_input_feeding\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"seq2seq_input_feeding\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ positional_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,202,560</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>),  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">20,608</span> │ positional_embed… │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>),       │            │                   │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)]       │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_30        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,200,000</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_adapter     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ rnn_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RNN</span>)         │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,145</span> │ embedding_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>),  │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>),       │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)]       │            │ lambda_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                     │                   │            │ encoder_adapter[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_dense       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,625,000</span> │ rnn_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ <span style=\"color: #00af00; text-decoration-color: #00af00\">25000</span>)            │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ positional_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │  \u001b[38;5;34m3,202,560\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mPositionalEmbeddi…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m32\u001b[0m),  │     \u001b[38;5;34m20,608\u001b[0m │ positional_embed… │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m),       │            │                   │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)]       │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_30        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │  \u001b[38;5;34m3,200,000\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda_3 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_adapter     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │      \u001b[38;5;34m1,056\u001b[0m │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ rnn_3 (\u001b[38;5;33mRNN\u001b[0m)         │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │      \u001b[38;5;34m2,145\u001b[0m │ embedding_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m),  │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m),       │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)]       │            │ lambda_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                     │                   │            │ encoder_adapter[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_dense       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │  \u001b[38;5;34m1,625,000\u001b[0m │ rnn_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │ \u001b[38;5;34m25000\u001b[0m)            │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,051,369</span> (30.71 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,051,369\u001b[0m (30.71 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,051,369</span> (30.71 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,051,369\u001b[0m (30.71 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Camada densa final para gerar as predições a partir dos outputs do decoder.\n",
        "decoder_dense = layers.Dense(vocab_size, activation='softmax', name='decoder_dense')\n",
        "final_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# --- Modelo Final ---\n",
        "# Define o modelo sequencial que recebe as entradas do encoder e do decoder,\n",
        "# e produz as predições finais.\n",
        "model = Model([encoder_inputs, decoder_inputs], final_outputs, name='seq2seq_input_feeding')\n",
        "\n",
        "# Compila o modelo utilizando o otimizador Adam, a função de perda\n",
        "# de entropia cruzada esparsa e a métrica de acurácia.\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Exibe um resumo da arquitetura do modelo.\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Objetivo do Código: Preparar Dados de Treinamento e Teste, Treinar e Avaliar o Modelo Seq2Seq com Atenção\n",
        "\n",
        "Este trecho de código realiza as seguintes operações:\n",
        "- Converte os textos brutos (tanto de treinamento quanto de teste) em arrays numéricos utilizando as camadas de vetorização.\n",
        "- Prepara as sequências de entrada e as sequências alvo para o decoder, aplicando o conceito de *teacher forcing* (deslocamento das sequências).\n",
        "- Treina o modelo seq2seq com atenção utilizando os dados preparados.\n",
        "- Avalia o desempenho do modelo no conjunto de teste e imprime as métricas de perda e acurácia.\n",
        "\n",
        "---\n",
        "\n",
        "#### 1. Preparação dos Dados de Treinamento\n",
        "\n",
        "- **Encoder Inputs:**\n",
        "  - Os textos em francês de treinamento são convertidos para arrays de inteiros:\n",
        "    ```python\n",
        "    encoder_input_data = french_vectorization(np.array(train_french_texts)).numpy()\n",
        "    ```\n",
        "    - Cada elemento do array representa uma sequência de índices correspondentes aos tokens.\n",
        "\n",
        "- **Decoder Inputs e Targets:**\n",
        "  - Os textos em português de treinamento são convertidos para arrays tokenizados:\n",
        "    ```python\n",
        "    portuguese_tokenized = portuguese_vectorization(np.array(train_portuguese_texts)).numpy()\n",
        "    ```\n",
        "  - **Decoder Input Data:**\n",
        "    - São utilizados todos os tokens, exceto o último, para formar a sequência de entrada do decoder:\n",
        "      ```python\n",
        "      decoder_input_data = portuguese_tokenized[:, :-1]\n",
        "      ```\n",
        "  - **Decoder Target Data:**\n",
        "    - São utilizados todos os tokens, exceto o primeiro, de forma que o modelo aprenda a prever o próximo token:\n",
        "      ```python\n",
        "      decoder_target_data = portuguese_tokenized[:, 1:]\n",
        "      ```\n",
        "\n",
        "---\n",
        "\n",
        "#### 2. Preparação dos Dados de Teste\n",
        "\n",
        "- **Extração dos Textos de Teste:**\n",
        "  - Os textos em francês e português são extraídos dos pares de teste:\n",
        "    ```python\n",
        "    test_french_texts = [pair[0] for pair in test_pairs]\n",
        "    test_portuguese_texts = [pair[1] for pair in test_pairs]\n",
        "    ```\n",
        "- **Conversão para Arrays Numéricos:**\n",
        "  - Os textos em francês e português são convertidos para arrays de inteiros:\n",
        "    ```python\n",
        "    encoder_input_test = french_vectorization(np.array(test_french_texts)).numpy()\n",
        "    portuguese_tokenized_test = portuguese_vectorization(np.array(test_portuguese_texts)).numpy()\n",
        "    ```\n",
        "- **Preparação das Sequências para o Decoder:**\n",
        "  - As entradas e os alvos do decoder são preparados da mesma forma que nos dados de treinamento:\n",
        "    ```python\n",
        "    decoder_input_test = portuguese_tokenized_test[:, :-1]\n",
        "    decoder_target_test = portuguese_tokenized_test[:, 1:]\n",
        "    ```\n",
        "\n",
        "---\n",
        "\n",
        "#### 3. Treinamento do Modelo\n",
        "\n",
        "- O modelo é treinado utilizando os arrays preparados:\n",
        "  ```python\n",
        "  history = model.fit(\n",
        "      x=[encoder_input_data, decoder_input_data],\n",
        "      y=decoder_target_data,\n",
        "      batch_size=64,\n",
        "      epochs=30,\n",
        "      validation_data=([encoder_input_test, decoder_input_test], decoder_target_test)\n",
        "  )\n",
        "  ```\n",
        "  - **Entradas:**\n",
        "    - `[encoder_input_data, decoder_input_data]`: Dados de entrada para o encoder e o decoder.\n",
        "  - **Saída Alvo:**\n",
        "    - `decoder_target_data`: Sequência que o modelo deve aprender a prever.\n",
        "  - **Configuração:**\n",
        "    - Batch size de 64 e 30 épocas.\n",
        "    - Uso de dados de validação para monitorar o desempenho durante o treinamento.\n",
        "  - O histórico de treinamento é armazenado na variável `history`.\n",
        "\n",
        "---\n",
        "\n",
        "#### 4. Avaliação do Modelo\n",
        "\n",
        "- Após o treinamento, o modelo é avaliado utilizando os dados de teste:\n",
        "  ```python\n",
        "  test_loss, test_accuracy = model.evaluate(\n",
        "      x=[encoder_input_test, decoder_input_test],\n",
        "      y=decoder_target_test\n",
        "  )\n",
        "  ```\n",
        "  - O método `evaluate` retorna a perda e a acurácia no conjunto de teste.\n",
        "\n",
        "- **Exibição dos Resultados:**\n",
        "  - Os valores de perda e acurácia são impressos:\n",
        "    ```python\n",
        "    print(\"Test loss:\", test_loss)\n",
        "    print(\"Test accuracy:\", test_accuracy)\n",
        "    ```\n",
        "\n",
        "---\n",
        "\n",
        "### Resumo\n",
        "\n",
        "- **Conversão e Preparação dos Dados:**  \n",
        "  Os textos brutos são convertidos para arrays numéricos utilizando camadas de vetorização, e as sequências de entrada e alvo são ajustadas para o treinamento com *teacher forcing*.\n",
        "\n",
        "- **Treinamento:**  \n",
        "  O modelo é treinado com os dados preparados e validado em um conjunto separado de teste.\n",
        "\n",
        "- **Avaliação:**  \n",
        "  O desempenho do modelo é avaliado e os resultados (perda e acurácia) são exibidos.\n",
        "\n",
        "Este fluxo garante que o modelo esteja pronto para lidar com a tarefa de tradução ou geração de sequências, utilizando a robustez do mecanismo de atenção integrado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfo-sAwWyg03",
        "outputId": "f5dcccfd-2db2-477e-c7e7-cdf19a845fb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 236ms/step - accuracy: 0.6434 - loss: 4.6661 - val_accuracy: 0.7010 - val_loss: 2.1632\n",
            "Epoch 2/30\n",
            "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 245ms/step - accuracy: 0.7041 - loss: 2.0725 - val_accuracy: 0.7101 - val_loss: 2.0720\n",
            "Epoch 3/30\n",
            "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 247ms/step - accuracy: 0.7179 - loss: 1.9415 - val_accuracy: 0.7180 - val_loss: 2.0037\n",
            "Epoch 4/30\n",
            "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 248ms/step - accuracy: 0.7237 - loss: 1.8574 - val_accuracy: 0.7238 - val_loss: 1.9522\n",
            "Epoch 5/30\n",
            "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 243ms/step - accuracy: 0.7334 - loss: 1.7577 - val_accuracy: 0.7309 - val_loss: 1.9025\n",
            "Epoch 6/30\n",
            "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 238ms/step - accuracy: 0.7390 - loss: 1.6830 - val_accuracy: 0.7347 - val_loss: 1.8634\n",
            "Epoch 7/30\n",
            "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 227ms/step - accuracy: 0.7466 - loss: 1.6029 - val_accuracy: 0.7399 - val_loss: 1.8399\n",
            "Epoch 8/30\n",
            "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 228ms/step - accuracy: 0.7535 - loss: 1.5379 - val_accuracy: 0.7474 - val_loss: 1.8092\n",
            "Epoch 9/30\n",
            "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 232ms/step - accuracy: 0.7612 - loss: 1.4674 - val_accuracy: 0.7534 - val_loss: 1.7803\n",
            "Epoch 10/30\n",
            "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 235ms/step - accuracy: 0.7694 - loss: 1.3912 - val_accuracy: 0.7576 - val_loss: 1.7518\n",
            "Epoch 11/30\n",
            "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 239ms/step - accuracy: 0.7774 - loss: 1.3218 - val_accuracy: 0.7640 - val_loss: 1.7220\n",
            "Epoch 12/30\n",
            "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 234ms/step - accuracy: 0.7840 - loss: 1.2574 - val_accuracy: 0.7681 - val_loss: 1.6984\n",
            "Epoch 13/30\n",
            "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 243ms/step - accuracy: 0.7930 - loss: 1.1844 - val_accuracy: 0.7765 - val_loss: 1.6805\n",
            "Epoch 14/30\n",
            "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 246ms/step - accuracy: 0.8031 - loss: 1.1084 - val_accuracy: 0.7824 - val_loss: 1.6544\n",
            "Epoch 15/30\n",
            "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 239ms/step - accuracy: 0.8124 - loss: 1.0373 - val_accuracy: 0.7869 - val_loss: 1.6383\n",
            "Epoch 16/30\n",
            "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 237ms/step - accuracy: 0.8207 - loss: 0.9691 - val_accuracy: 0.7922 - val_loss: 1.6469\n",
            "Epoch 17/30\n",
            "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 230ms/step - accuracy: 0.8298 - loss: 0.9060 - val_accuracy: 0.7965 - val_loss: 1.6237\n",
            "Epoch 18/30\n",
            "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 233ms/step - accuracy: 0.8369 - loss: 0.8523 - val_accuracy: 0.7995 - val_loss: 1.6042\n",
            "Epoch 19/30\n",
            "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 225ms/step - accuracy: 0.8454 - loss: 0.7991 - val_accuracy: 0.8044 - val_loss: 1.6408\n",
            "Epoch 20/30\n",
            "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 230ms/step - accuracy: 0.8526 - loss: 0.7457 - val_accuracy: 0.8063 - val_loss: 1.6062\n",
            "Epoch 21/30\n",
            "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 232ms/step - accuracy: 0.8607 - loss: 0.7009 - val_accuracy: 0.8118 - val_loss: 1.6194\n",
            "Epoch 22/30\n",
            "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 234ms/step - accuracy: 0.8679 - loss: 0.6603 - val_accuracy: 0.8124 - val_loss: 1.6197\n",
            "Epoch 23/30\n",
            "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 232ms/step - accuracy: 0.8764 - loss: 0.6074 - val_accuracy: 0.8146 - val_loss: 1.6298\n",
            "Epoch 24/30\n",
            "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 232ms/step - accuracy: 0.8804 - loss: 0.5842 - val_accuracy: 0.8174 - val_loss: 1.6450\n",
            "Epoch 25/30\n",
            "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 224ms/step - accuracy: 0.8857 - loss: 0.5559 - val_accuracy: 0.8181 - val_loss: 1.6328\n",
            "Epoch 26/30\n",
            "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 221ms/step - accuracy: 0.8935 - loss: 0.5183 - val_accuracy: 0.8205 - val_loss: 1.6554\n",
            "Epoch 27/30\n",
            "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 220ms/step - accuracy: 0.8991 - loss: 0.4871 - val_accuracy: 0.8216 - val_loss: 1.6702\n",
            "Epoch 28/30\n",
            "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 219ms/step - accuracy: 0.9037 - loss: 0.4650 - val_accuracy: 0.8213 - val_loss: 1.6740\n",
            "Epoch 29/30\n",
            "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 219ms/step - accuracy: 0.9070 - loss: 0.4412 - val_accuracy: 0.8205 - val_loss: 1.6936\n",
            "Epoch 30/30\n",
            "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 219ms/step - accuracy: 0.9107 - loss: 0.4252 - val_accuracy: 0.8234 - val_loss: 1.7236\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 69ms/step - accuracy: 0.8231 - loss: 1.7403\n",
            "Test loss: 1.7236313819885254\n",
            "Test accuracy: 0.8233650326728821\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Preparação dos arrays para treinamento e teste a partir dos textos brutos\n",
        "# =============================================================================\n",
        "\n",
        "# --- Dados de Treinamento ---\n",
        "# Converte os textos de treinamento para arrays utilizando as camadas de vetorização.\n",
        "# O resultado é um array de inteiros para o encoder.\n",
        "encoder_input_data = french_vectorization(np.array(train_french_texts)).numpy()\n",
        "\n",
        "# Converte os textos de treinamento do português para arrays tokenizados.\n",
        "# O resultado é um array onde cada linha representa uma sequência tokenizada.\n",
        "portuguese_tokenized = portuguese_vectorization(np.array(train_portuguese_texts)).numpy()\n",
        "\n",
        "# Para o decoder, definimos:\n",
        "# - decoder_input_data: sequência de entrada do decoder (todos os tokens, exceto o último),\n",
        "#   pois o modelo recebe essa sequência para prever o próximo token.\n",
        "# - decoder_target_data: sequência alvo (todos os tokens, exceto o primeiro), que é o que o\n",
        "#   modelo deve prever.\n",
        "decoder_input_data = portuguese_tokenized[:, :-1]\n",
        "decoder_target_data = portuguese_tokenized[:, 1:]\n",
        "\n",
        "# --- Dados de Teste ---\n",
        "# Extrai os textos de teste dos pares e converte utilizando as camadas de vetorização.\n",
        "\n",
        "# Obtém os textos em francês e português dos pares de teste\n",
        "test_french_texts = [pair[0] for pair in test_pairs]\n",
        "test_portuguese_texts = [pair[1] for pair in test_pairs]\n",
        "\n",
        "# Converte os textos de teste para arrays de inteiros\n",
        "encoder_input_test = french_vectorization(np.array(test_french_texts)).numpy()\n",
        "portuguese_tokenized_test = portuguese_vectorization(np.array(test_portuguese_texts)).numpy()\n",
        "\n",
        "# Prepara as sequências para o decoder no teste, seguindo a mesma lógica aplicada aos dados de treinamento.\n",
        "decoder_input_test = portuguese_tokenized_test[:, :-1]\n",
        "decoder_target_test = portuguese_tokenized_test[:, 1:]\n",
        "\n",
        "# =============================================================================\n",
        "# Treinamento e Avaliação do Modelo com a Nova Arquitetura (com atenção)\n",
        "# =============================================================================\n",
        "\n",
        "# Treina o modelo utilizando os arrays preparados para o encoder e decoder.\n",
        "history = model.fit(\n",
        "    x=[encoder_input_data, decoder_input_data],\n",
        "    y=decoder_target_data,\n",
        "    batch_size=64,\n",
        "    epochs=30,\n",
        "    validation_data=([encoder_input_test, decoder_input_test], decoder_target_test)\n",
        ")\n",
        "\n",
        "# Avalia o modelo no conjunto de teste.\n",
        "test_loss, test_accuracy = model.evaluate(\n",
        "    x=[encoder_input_test, decoder_input_test],\n",
        "    y=decoder_target_test\n",
        ")\n",
        "\n",
        "# Exibe os resultados da avaliação no teste.\n",
        "print(\"Test loss:\", test_loss)\n",
        "print(\"Test accuracy:\", test_accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Objetivo do Código: Visualizar o Histórico de Acurácia e Perda Durante o Treinamento\n",
        "\n",
        "Este trecho de código utiliza a biblioteca Matplotlib para plotar gráficos que resumem o desempenho do modelo ao longo das épocas, tanto para o conjunto de treinamento quanto para o de validação. As visualizações ajudam a identificar o comportamento do modelo durante o treinamento, permitindo monitorar a convergência e detectar possíveis problemas como overfitting.\n",
        "\n",
        "#### Passo a Passo:\n",
        "\n",
        "1. **Plotagem da Acurácia**:\n",
        "   - **Dados Utilizados**:\n",
        "     - `history.history['accuracy']`: Lista com os valores de acurácia obtidos durante o treinamento em cada época.\n",
        "     - `history.history['val_accuracy']`: Lista com os valores de acurácia no conjunto de validação em cada época.\n",
        "   - **Configuração do Gráfico**:\n",
        "     - `plt.plot(history.history['accuracy'])`: Plota a acurácia do treinamento.\n",
        "     - `plt.plot(history.history['val_accuracy'])`: Plota a acurácia da validação.\n",
        "     - `plt.title(model.name + ' accuracy')`: Define o título do gráfico, combinando o nome do modelo com a palavra \"accuracy\".\n",
        "     - `plt.ylabel('accuracy')`: Rótulo para o eixo y, representando a acurácia.\n",
        "     - `plt.xlabel('epoch')`: Rótulo para o eixo x, representando as épocas.\n",
        "     - `plt.legend(['train', 'val'], loc='upper left')`: Adiciona uma legenda para distinguir as curvas de treinamento e validação, posicionada no canto superior esquerdo.\n",
        "   - **Exibição**:\n",
        "     - `plt.show()`: Exibe o gráfico de acurácia.\n",
        "\n",
        "2. **Plotagem da Perda (Loss)**:\n",
        "   - **Dados Utilizados**:\n",
        "     - `history.history['loss']`: Lista com os valores de perda durante o treinamento.\n",
        "     - `history.history['val_loss']`: Lista com os valores de perda durante a validação.\n",
        "   - **Configuração do Gráfico**:\n",
        "     - `plt.plot(history.history['loss'])`: Plota a perda do treinamento.\n",
        "     - `plt.plot(history.history['val_loss'])`: Plota a perda da validação.\n",
        "     - `plt.title(model.name + ' loss')`: Define o título do gráfico, combinando o nome do modelo com a palavra \"loss\".\n",
        "     - `plt.ylabel('loss')`: Rótulo para o eixo y, representando a perda.\n",
        "     - `plt.xlabel('epoch')`: Rótulo para o eixo x, representando as épocas.\n",
        "     - `plt.legend(['train', 'val'], loc='upper left')`: Adiciona uma legenda para identificar as curvas de treinamento e validação.\n",
        "   - **Exibição**:\n",
        "     - `plt.show()`: Exibe o gráfico de perda.\n",
        "\n",
        "---\n",
        "\n",
        "Esses gráficos permitem monitorar visualmente o desempenho do modelo, facilitando a identificação de melhorias necessárias no treinamento ou ajustes na arquitetura.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "yfMUdro2yo9A"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Resume o histórico de acurácia: plota a acurácia para os conjuntos de treinamento e validação\n",
        "plt.plot(history.history['accuracy'])       # Acurácia durante o treinamento\n",
        "plt.plot(history.history['val_accuracy'])     # Acurácia durante a validação\n",
        "plt.title(model.name + ' accuracy')           # Define o título do gráfico (nome do modelo + 'accuracy')\n",
        "plt.ylabel('accuracy')                        # Rótulo do eixo y\n",
        "plt.xlabel('epoch')                           # Rótulo do eixo x\n",
        "plt.legend(['train', 'val'], loc='upper left')  # Adiciona a legenda indicando os conjuntos\n",
        "plt.show()                                    # Exibe o gráfico de acurácia\n",
        "\n",
        "# Resume o histórico de perda: plota a perda para os conjuntos de treinamento e validação\n",
        "plt.plot(history.history['loss'])             # Perda durante o treinamento\n",
        "plt.plot(history.history['val_loss'])           # Perda durante a validação\n",
        "plt.title(model.name + ' loss')                # Define o título do gráfico (nome do modelo + 'loss')\n",
        "plt.ylabel('loss')                            # Rótulo do eixo y\n",
        "plt.xlabel('epoch')                           # Rótulo do eixo x\n",
        "plt.legend(['train', 'val'], loc='upper left')  # Adiciona a legenda indicando os conjuntos\n",
        "plt.show()                                    # Exibe o gráfico de perda\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
