{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set the backend to TensorFlow. The code works with\n",
    "# both `tensorflow` and `torch`. It does not work with JAX\n",
    "# due to the behavior of `jax.numpy.tile` in a jit scope\n",
    "# (used in `TransformerDecoder.get_causal_attention_mask()`:\n",
    "# `tile` in JAX does not support a dynamic `reps` argument.\n",
    "# You can make the code work in JAX by wrapping the\n",
    "# inside of the `get_causal_attention_mask` method in\n",
    "# a decorator to prevent jit compilation:\n",
    "# `with jax.ensure_compile_time_eval():`.\n",
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "\n",
    "import pathlib\n",
    "import random\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow.data as tf_data\n",
    "import tensorflow.strings as tf_strings\n",
    "import tensorflow_datasets.public_api as tfds\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import ops\n",
    "from keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Je ne supporte pas ce type.', '[start] Eu não suporto esse tipo. [end]')\n"
     ]
    }
   ],
   "source": [
    "text_pairs = []\n",
    "\n",
    "with open(\"data.tsv\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        # Strip any extra whitespace and split the line by tabs\n",
    "        fields = line.strip().split(\"\\t\")\n",
    "        # Ensure the line has at least 4 fields (indexes 0 to 3)\n",
    "        if len(fields) < 4:\n",
    "            continue\n",
    "        french = fields[1]  # second column\n",
    "        portuguese = \"[start] \" + fields[3] + \" [end]\"  # fourth column\n",
    "        text_pairs.append((french, portuguese))\n",
    "\n",
    "# Print the first pair to verify\n",
    "print(text_pairs[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Je veux perdre quelques kilos.', '[start] Eu quero perder alguns quilos. [end]')\n",
      "(\"Nourrissez votre esprit d'informations importantes.\", '[start] Alimente a sua mente com informações importantes. [end]')\n",
      "('Les personnes fortes transpirent généralement beaucoup.', '[start] Pessoas gordas, geralmente, suam bastante. [end]')\n",
      "(\"C'est un ouvrage traitant de l'Angleterre.\", '[start] Essa é uma obra que trata da Inglaterra. [end]')\n",
      "(\"Vous n'avez pas pu ouvrir la porte parce qu'elle était verrouillée de l'intérieur.\", '[start] Você não conseguiu abrir a porta porque ela estava trancada por dentro. [end]')\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    print(random.choice(text_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33030 total pairs\n",
      "23122 training pairs\n",
      "4954 validation pairs\n",
      "4954 test pairs\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(text_pairs)\n",
    "num_val_samples = int(0.15 * len(text_pairs))\n",
    "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
    "train_pairs = text_pairs[:num_train_samples]\n",
    "val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n",
    "test_pairs = text_pairs[num_train_samples + num_val_samples :]\n",
    "\n",
    "print(f\"{len(text_pairs)} total pairs\")\n",
    "print(f\"{len(train_pairs)} training pairs\")\n",
    "print(f\"{len(val_pairs)} validation pairs\")\n",
    "print(f\"{len(test_pairs)} test pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "strip_chars = string.punctuation + \"«\" + \"»\"\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")\n",
    "\n",
    "vocab_size = 25000\n",
    "sequence_length = 20\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "def custom_standardization(input_string):\n",
    "    lowercase = tf_strings.lower(input_string)\n",
    "    return tf_strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n",
    "\n",
    "\n",
    "french_vectorization = TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "portuguese_vectorization = TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length + 1,\n",
    "    standardize=custom_standardization,\n",
    ")\n",
    "train_french_texts = [pair[0] for pair in train_pairs]\n",
    "train_portuguese_texts = [pair[1] for pair in train_pairs]\n",
    "french_vectorization.adapt(train_french_texts)\n",
    "portuguese_vectorization.adapt(train_portuguese_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dataset(french, portuguese):\n",
    "    french = french_vectorization(french)\n",
    "    portuguese = portuguese_vectorization(portuguese)\n",
    "    return (\n",
    "        {\n",
    "            \"encoder_inputs\": french,\n",
    "            \"decoder_inputs\": portuguese[:, :-1],\n",
    "        },\n",
    "        portuguese[:, 1:],\n",
    "    )\n",
    "\n",
    "\n",
    "def make_dataset(pairs):\n",
    "    french_texts, portuguese_texts = zip(*pairs)\n",
    "    french_texts = list(french_texts)\n",
    "    portuguese_texts = list(portuguese_texts)\n",
    "    dataset = tf_data.Dataset.from_tensor_slices((french_texts, portuguese_texts))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(format_dataset)\n",
    "    return dataset.cache().shuffle(2048).prefetch(16)\n",
    "\n",
    "\n",
    "train_ds = make_dataset(train_pairs)\n",
    "val_ds = make_dataset(val_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs[\"encoder_inputs\"].shape: (64, 20)\n",
      "inputs[\"decoder_inputs\"].shape: (64, 20)\n",
      "targets.shape: (64, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-08 01:16:49.352537: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_ds.take(1):\n",
    "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
    "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
    "    print(f\"targets.shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"C'est une information intéressante.\", \"Peu importe si c'est bon, faisons le quand même.\", 'Interlingua a cinq sœurs plus âgées.', \"J'ai confessé mon péché.\", \"Ne te fais pas de souci, je vais t'aider.\"]\n",
      "['[start] É uma informação interessante. [end]', '[start] Pouco importa se é bom, façamos mesmo assim. [end]', '[start] Interlíngua tem cinco irmãs mais velhas. [end]', '[start] Eu confessei o meu pecado. [end]', '[start] Não se preocupe, eu vou te ajudar. [end]']\n"
     ]
    }
   ],
   "source": [
    "print(train_french_texts[:5])\n",
    "print(train_portuguese_texts[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "\n",
    "# Parameters\n",
    "sequence_length = 20  # Maximum number of tokens per sequence\n",
    "vocab_size = 15000    # Total number of tokens in your vocabulary\n",
    "embed_dim = 128       # Dimension of each token embedding\n",
    "\n",
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.token_embeddings = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.position_embeddings = layers.Embedding(input_dim=sequence_length, output_dim=embed_dim)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Get token embeddings: shape (batch_size, sequence_length, embed_dim)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        # Create a constant tensor for positions: shape (sequence_length,)\n",
    "        positions = tf.range(start=0, limit=self.sequence_length, delta=1)\n",
    "        # Get positional embeddings: shape (sequence_length, embed_dim)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        # Expand dims to (1, sequence_length, embed_dim) so that it broadcasts over the batch\n",
    "        embedded_positions = tf.expand_dims(embedded_positions, axis=0)\n",
    "        # Return the sum of token and positional embeddings\n",
    "        return embedded_tokens + embedded_positions\n",
    "\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"sequence_length\": self.sequence_length,\n",
    "            \"vocab_size\": self.vocab_size,\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "# Build the encoder using the custom embedding layer and an LSTM\n",
    "encoder_inputs = Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
    "# Use our custom PositionalEmbedding layer\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
    "# Pass the embeddings to an LSTM layer\n",
    "encoder_lstm = layers.LSTM(32, return_state=True, name='encoder_lstm')\n",
    "lstm_outputs, state_h, state_c = encoder_lstm(x)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Define a simple decoder\n",
    "decoder_inputs = Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
    "decoder_embeddings = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
    "decoder_lstm = layers.LSTM(32, return_sequences=True, return_state=True, name='decoder_lstm')\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embeddings, initial_state=encoder_states)\n",
    "decoder_dense = layers.Dense(vocab_size, activation='softmax', name='decoder_dense')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Build the final model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs, name='seq2seq_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"seq2seq_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"seq2seq_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,922,560</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,922,560</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>),      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">20,608</span> │ positional_embed… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>),       │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)]       │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>),  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">20,608</span> │ positional_embed… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>),       │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)]       │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_dense       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15000</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">495,000</span> │ decoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │  \u001b[38;5;34m1,922,560\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mPositionalEmbeddi…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │  \u001b[38;5;34m1,922,560\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mPositionalEmbeddi…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m),      │     \u001b[38;5;34m20,608\u001b[0m │ positional_embed… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m),       │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)]       │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m32\u001b[0m),  │     \u001b[38;5;34m20,608\u001b[0m │ positional_embed… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m),       │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)]       │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_dense       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m15000\u001b[0m) │    \u001b[38;5;34m495,000\u001b[0m │ decoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,381,336</span> (16.71 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,381,336\u001b[0m (16.71 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,381,336</span> (16.71 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,381,336\u001b[0m (16.71 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ktrain_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 24\u001b[0m\n\u001b[1;32m     17\u001b[0m decoder_target_test \u001b[38;5;241m=\u001b[39m portuguese_tokenized_test[:, \u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Finally, call the training/testing function with the updated variables.\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# (Assuming that ktrain_test is a function you have defined or imported\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#  that takes the model and these data arrays.)\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[43mktrain_test\u001b[49m(model,\n\u001b[1;32m     25\u001b[0m             [encoder_input_data, decoder_input_data],\n\u001b[1;32m     26\u001b[0m             decoder_target_data,\n\u001b[1;32m     27\u001b[0m             [encoder_input_test, decoder_input_test],\n\u001b[1;32m     28\u001b[0m             decoder_target_test,\n\u001b[1;32m     29\u001b[0m             epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m     30\u001b[0m             batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,\n\u001b[1;32m     31\u001b[0m             patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m     32\u001b[0m             verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ktrain_test' is not defined"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Prepare arrays for training and testing from the raw texts\n",
    "# =============================================================================\n",
    "# --- For training data ---\n",
    "# Convert training texts into arrays using the vectorization layers\n",
    "encoder_input_data = french_vectorization(np.array(train_french_texts)).numpy()\n",
    "portuguese_tokenized = portuguese_vectorization(np.array(train_portuguese_texts)).numpy()\n",
    "decoder_input_data = portuguese_tokenized[:, :-1]\n",
    "decoder_target_data = portuguese_tokenized[:, 1:]\n",
    "\n",
    "# --- For test data ---\n",
    "test_french_texts = [pair[0] for pair in test_pairs]\n",
    "test_portuguese_texts = [pair[1] for pair in test_pairs]\n",
    "encoder_input_test = french_vectorization(np.array(test_french_texts)).numpy()\n",
    "portuguese_tokenized_test = portuguese_vectorization(np.array(test_portuguese_texts)).numpy()\n",
    "decoder_input_test = portuguese_tokenized_test[:, :-1]\n",
    "decoder_target_test = portuguese_tokenized_test[:, 1:]\n",
    "\n",
    "# =============================================================================\n",
    "# Finally, call the training/testing function with the updated variables.\n",
    "# =============================================================================\n",
    "# (Assuming that ktrain_test is a function you have defined or imported\n",
    "#  that takes the model and these data arrays.)\n",
    "train_test(model,\n",
    "            [encoder_input_data, decoder_input_data],\n",
    "            decoder_target_data,\n",
    "            [encoder_input_test, decoder_input_test],\n",
    "            decoder_target_test,\n",
    "            epochs=5,\n",
    "            batch_size=64,\n",
    "            patience=3,\n",
    "            verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
