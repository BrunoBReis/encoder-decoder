{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define o backend do Keras como TensorFlow\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "# Importações de bibliotecas padrão e de terceiros\n",
    "import pathlib\n",
    "import random\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.data as tf_data\n",
    "import tensorflow.strings as tf_strings\n",
    "import tensorflow_datasets.public_api as tfds\n",
    "from tensorflow import keras\n",
    "from keras import layers, Model, Input\n",
    "from keras.layers import TextVectorization\n",
    "from keras import ops\n",
    "from keras import backend as K  # Importa o backend do Keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivo do Código: Carregar e Pré-processar Dados para Tradução\n",
    "\n",
    "Este código realiza o carregamento e pré-processamento de dados a partir de um arquivo `data.tsv` contendo pares de textos em francês e português. A ideia é extrair os pares de textos, adicionar tokens especiais nos textos em português para indicar início e fim das sequências, e em seguida dividir os dados em conjuntos de treinamento, validação e teste para uso posterior no treinamento de modelos de tradução (seq2seq).\n",
    "\n",
    "#### Passo a Passo do Código:\n",
    "\n",
    "1. **Carregamento dos Dados**:\n",
    "   - **Inicialização**:\n",
    "     - Cria uma lista vazia `text_pairs` para armazenar os pares (francês, português).\n",
    "   - **Leitura do Arquivo**:\n",
    "     - Abre o arquivo `data.tsv` em modo leitura com codificação UTF-8.\n",
    "     - Para cada linha do arquivo:\n",
    "       - Remove espaços extras com `strip()` e divide a linha em campos usando a tabulação (`\\t`) como separador.\n",
    "       - Verifica se a linha possui pelo menos 4 colunas. Se não, ignora a linha (`continue`).\n",
    "       - Extrai o texto em francês da segunda coluna (`fields[1]`).\n",
    "       - Extrai o texto em português da quarta coluna (`fields[3]`) e adiciona tokens especiais `[start]` e `[end]` no início e no final da sequência, respectivamente.\n",
    "       - Adiciona o par `(french, portuguese)` à lista `text_pairs`.\n",
    "   - **Verificação Inicial**:\n",
    "     - Imprime o primeiro par de textos para confirmar que os dados foram carregados corretamente.\n",
    "\n",
    "2. **Embaralhamento e Divisão dos Dados**:\n",
    "   - **Embaralhamento**:\n",
    "     - Embaralha os pares de textos usando `random.shuffle(text_pairs)` para garantir que a divisão subsequente dos conjuntos seja aleatória.\n",
    "   - **Divisão dos Dados**:\n",
    "     - Calcula o número de amostras para validação como 15% do total de pares:\n",
    "       ```python\n",
    "       num_val_samples = int(0.15 * len(text_pairs))\n",
    "       ```\n",
    "     - Define o número de amostras para treinamento como o total menos duas vezes o número de amostras de validação (uma parte para validação e outra para teste):\n",
    "       ```python\n",
    "       num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
    "       ```\n",
    "     - Separa os pares de textos em:\n",
    "       - **Conjunto de Treinamento**: os primeiros `num_train_samples` pares.\n",
    "       - **Conjunto de Validação**: os próximos `num_val_samples` pares.\n",
    "       - **Conjunto de Teste**: os pares restantes.\n",
    "   - **Exibição da Distribuição**:\n",
    "     - Imprime o número total de pares e a quantidade de pares para cada conjunto (treinamento, validação e teste).\n",
    "\n",
    "---\n",
    "\n",
    "Esse fluxo garante que os dados estejam bem organizados e distribuídos de maneira aleatória, o que é fundamental para o treinamento robusto de modelos de tradução ou outras tarefas de Processamento de Linguagem Natural.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Je ne supporte pas ce type.', '[start] Eu não suporto esse tipo. [end]')\n",
      "33030 total pairs\n",
      "23122 training pairs\n",
      "4954 validation pairs\n",
      "4954 test pairs\n"
     ]
    }
   ],
   "source": [
    "# ------------------------\n",
    "# Carregamento e Pré-processamento dos Dados\n",
    "# ------------------------\n",
    "\n",
    "# Inicializa uma lista para armazenar os pares de textos (francês e português)\n",
    "text_pairs = []\n",
    "\n",
    "# Abre o arquivo 'data.tsv' para leitura, utilizando codificação UTF-8\n",
    "with open(\"data.tsv\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        # Remove espaços extras e divide a linha usando tabulação como separador\n",
    "        fields = line.strip().split(\"\\t\")\n",
    "        \n",
    "        # Garante que a linha tenha pelo menos 4 colunas antes de processar\n",
    "        if len(fields) < 4:\n",
    "            continue\n",
    "        \n",
    "        # Extrai o texto em francês (segunda coluna)\n",
    "        french = fields[1]\n",
    "        \n",
    "        # Extrai o texto em português (quarta coluna) e adiciona tokens de início e fim\n",
    "        portuguese = \"[start] \" + fields[3] + \" [end]\"\n",
    "        \n",
    "        # Adiciona o par (francês, português) à lista\n",
    "        text_pairs.append((french, portuguese))\n",
    "\n",
    "# Exibe o primeiro par para verificação\n",
    "print(text_pairs[0])\n",
    "\n",
    "# Embaralha os pares de textos para garantir aleatoriedade na divisão dos conjuntos\n",
    "random.shuffle(text_pairs)\n",
    "\n",
    "# Define o número de amostras para validação (15% do total)\n",
    "num_val_samples = int(0.15 * len(text_pairs))\n",
    "\n",
    "# Define o número de amostras para treinamento (o restante após a divisão para validação e teste)\n",
    "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
    "\n",
    "# Divide os pares em conjuntos de treinamento, validação e teste\n",
    "train_pairs = text_pairs[:num_train_samples]\n",
    "val_pairs = text_pairs[num_train_samples:num_train_samples + num_val_samples]\n",
    "test_pairs = text_pairs[num_train_samples + num_val_samples:]\n",
    "\n",
    "# Exibe o número total de pares e a distribuição entre treinamento, validação e teste\n",
    "print(f\"{len(text_pairs)} total pairs\")\n",
    "print(f\"{len(train_pairs)} training pairs\")\n",
    "print(f\"{len(val_pairs)} validation pairs\")\n",
    "print(f\"{len(test_pairs)} test pairs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivo do Código: Configurar a Padronização e Vetorização dos Textos\n",
    "\n",
    "Este trecho de código prepara a transformação dos textos brutos para um formato numérico, adequado para o treinamento do modelo. São definidos os caracteres a serem removidos, os parâmetros de vetorização e uma função de padronização customizada, que é aplicada durante o processo de vetorização. Em seguida, as camadas de vetorização para os textos em francês e português são criadas e ajustadas aos dados de treinamento.\n",
    "\n",
    "#### Passo a Passo do Código:\n",
    "\n",
    "1. **Definição dos Caracteres a Serem Removidos**:\n",
    "   - Combina os caracteres de pontuação padrão com os caracteres \"«\" e \"»\":\n",
    "     ```python\n",
    "     strip_chars = string.punctuation + \"«\" + \"»\"\n",
    "     ```\n",
    "   - Remove os colchetes `[` e `]` da lista de caracteres a serem removidos, para preservar os tokens especiais (por exemplo, `[start]` e `[end]`):\n",
    "     ```python\n",
    "     strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "     strip_chars = strip_chars.replace(\"]\", \"\")\n",
    "     ```\n",
    "\n",
    "2. **Configuração dos Parâmetros de Vetorização e Treinamento**:\n",
    "   - `vocab_size = 25000`: Define o tamanho máximo do vocabulário, ou seja, o número máximo de tokens únicos que serão considerados.\n",
    "   - `sequence_length = 20`: Define o comprimento máximo das sequências de entrada para o modelo.\n",
    "   - `batch_size = 64`: Define o tamanho do lote (batch) durante o treinamento.\n",
    "\n",
    "3. **Definição da Função de Padronização Customizada**:\n",
    "   - A função `custom_standardization` recebe um texto de entrada e:\n",
    "     - Converte o texto para letras minúsculas com `tf_strings.lower()`.\n",
    "     - Remove os caracteres definidos em `strip_chars` utilizando uma expressão regular com `tf_strings.regex_replace()`.\n",
    "\n",
    "\n",
    "4. **Criação das Camadas de Vetorização**:\n",
    "   - **Vetorização para o Francês**:\n",
    "     - Configurada para transformar os textos em sequências de inteiros (índices dos tokens), com um tamanho máximo de sequência definido por `sequence_length`.\n",
    "     ```python\n",
    "     french_vectorization = TextVectorization(\n",
    "         max_tokens=vocab_size,                # Número máximo de tokens no vocabulário\n",
    "         output_mode=\"int\",                    # Saída como inteiros (índices dos tokens)\n",
    "         output_sequence_length=sequence_length  # Comprimento fixo da sequência\n",
    "     )\n",
    "     ```\n",
    "   - **Vetorização para o Português**:\n",
    "     - Configurada de maneira similar à vetorização do francês, porém com `output_sequence_length` definido como `sequence_length + 1`. Esse incremento acomoda o token especial de final de sequência.\n",
    "     - Utiliza a função de padronização customizada para limpar os textos antes da vetorização.\n",
    "     ```python\n",
    "     portuguese_vectorization = TextVectorization(\n",
    "         max_tokens=vocab_size,                  # Número máximo de tokens no vocabulário\n",
    "         output_mode=\"int\",                      # Saída como inteiros (índices dos tokens)\n",
    "         output_sequence_length=sequence_length + 1,  # Comprimento fixo (com 1 extra para o token final)\n",
    "         standardize=custom_standardization      # Função de padronização personalizada\n",
    "     )\n",
    "     ```\n",
    "\n",
    "5. **Extração dos Textos dos Pares de Treinamento**:\n",
    "   - Os textos em francês e português são extraídos dos pares de treinamento (`train_pairs`):\n",
    "     ```python\n",
    "     train_french_texts = [pair[0] for pair in train_pairs]\n",
    "     train_portuguese_texts = [pair[1] for pair in train_pairs]\n",
    "     ```\n",
    "\n",
    "6. **Adaptação das Camadas de Vetorização aos Dados de Treinamento**:\n",
    "   - As camadas de vetorização são \"adaptadas\" aos textos de treinamento. Esse processo faz com que as camadas aprendam o vocabulário e as frequências dos tokens, mapeando cada palavra para um índice inteiro:\n",
    "     ```python\n",
    "     french_vectorization.adapt(train_french_texts)\n",
    "     portuguese_vectorization.adapt(train_portuguese_texts)\n",
    "     ```\n",
    "\n",
    "---\n",
    "\n",
    "Este processo é crucial para transformar os dados textuais brutos em um formato numérico consistente, preparando-os para o treinamento de modelos de tradução ou outras aplicações de NLP.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define os caracteres que serão removidos durante a padronização dos textos\n",
    "strip_chars = string.punctuation + \"«\" + \"»\"\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")  # Remove colchete de abertura da lista de caracteres\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")  # Remove colchete de fechamento da lista de caracteres\n",
    "\n",
    "# Parâmetros para a vetorização dos textos e treinamento do modelo\n",
    "vocab_size = 25000          # Tamanho máximo do vocabulário para vetorização\n",
    "sequence_length = 20        # Comprimento máximo das sequências de entrada\n",
    "batch_size = 64             # Tamanho do lote (batch) durante o treinamento\n",
    "\n",
    "def custom_standardization(input_string):\n",
    "    \"\"\"\n",
    "    Padroniza o texto convertendo para minúsculas e removendo caracteres indesejados.\n",
    "\n",
    "    Args:\n",
    "        input_string (Tensor): Texto de entrada a ser padronizado.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Texto padronizado com caracteres removidos.\n",
    "    \"\"\"\n",
    "    lowercase = tf_strings.lower(input_string)  # Converte o texto para minúsculas\n",
    "    return tf_strings.regex_replace(\n",
    "        lowercase, \n",
    "        \"[%s]\" % re.escape(strip_chars),  # Remove os caracteres definidos em 'strip_chars'\n",
    "        \"\"\n",
    "    )\n",
    "\n",
    "# Vetorização dos textos em francês\n",
    "french_vectorization = TextVectorization(\n",
    "    max_tokens=vocab_size,                # Número máximo de tokens no vocabulário\n",
    "    output_mode=\"int\",                    # Saída como inteiros (índices dos tokens)\n",
    "    output_sequence_length=sequence_length  # Comprimento fixo da sequência\n",
    ")\n",
    "\n",
    "# Vetorização dos textos em português com padronização personalizada\n",
    "portuguese_vectorization = TextVectorization(\n",
    "    max_tokens=vocab_size,                  # Número máximo de tokens no vocabulário\n",
    "    output_mode=\"int\",                      # Saída como inteiros (índices dos tokens)\n",
    "    output_sequence_length=sequence_length + 1,  # Comprimento fixo (com 1 extra para o token final)\n",
    "    standardize=custom_standardization      # Função de padronização personalizada\n",
    ")\n",
    "\n",
    "# Extrai os textos em francês e português dos pares de treinamento\n",
    "train_french_texts = [pair[0] for pair in train_pairs]\n",
    "train_portuguese_texts = [pair[1] for pair in train_pairs]\n",
    "\n",
    "# Ajusta (adapta) as camadas de vetorização aos textos de treinamento\n",
    "french_vectorization.adapt(train_french_texts)\n",
    "portuguese_vectorization.adapt(train_portuguese_texts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivo do Código: Formatar e Criar o Dataset para Treinamento e Validação de um Modelo Seq2Seq\n",
    "\n",
    "Este trecho de código define duas funções para preparar os dados textuais em um formato adequado para o treinamento de um modelo seq2seq. Os dados são compostos por pares de textos em francês e português, e o processo de formatação envolve a vetorização dos textos e o ajuste das sequências para o funcionamento do modelo encoder-decoder.\n",
    "\n",
    "---\n",
    "\n",
    "#### Função `format_dataset`\n",
    "\n",
    "**Descrição:**  \n",
    "Converte os textos brutos em sequências numéricas utilizando as camadas de vetorização pré-definidas e organiza os dados em entradas para o encoder e decoder, bem como os alvos para o treinamento do decoder.\n",
    "\n",
    "**Entradas:**\n",
    "- `french` (Tensor): Textos em francês, que serão utilizados como entrada do encoder.\n",
    "- `portuguese` (Tensor): Textos em português, que serão utilizados tanto como entrada quanto como alvo do decoder.\n",
    "\n",
    "**Processamento:**\n",
    "1. **Vetoriza o Texto em Francês:**  \n",
    "   - Converte o texto em francês em sequências numéricas usando `french_vectorization`.\n",
    "2. **Vetoriza o Texto em Português:**  \n",
    "   - Converte o texto em português em sequências numéricas usando `portuguese_vectorization`.\n",
    "3. **Organiza os Dados para o Decoder:**\n",
    "   - **`decoder_inputs`:** São obtidos removendo o último token da sequência vetorizada em português. Essa sequência serve de entrada para o decoder durante o treinamento (input feeding).\n",
    "   - **Alvo do Decoder (`decoder_target`):** É obtido removendo o primeiro token da sequência vetorizada em português. Essa sequência é a que o modelo deve aprender a prever.\n",
    "\n",
    "**Saída:**\n",
    "- Retorna uma tupla contendo:\n",
    "  - Um dicionário com:\n",
    "    - `\"encoder_inputs\"`: Sequência vetorizada em francês.\n",
    "    - `\"decoder_inputs\"`: Sequência vetorizada em português sem o último token.\n",
    "  - A sequência de rótulos para o decoder (texto em português sem o primeiro token).\n",
    "\n",
    "---\n",
    "\n",
    "#### Função `make_dataset`\n",
    "\n",
    "**Descrição:**  \n",
    "Cria um `tf.data.Dataset` formatado a partir dos pares de textos, aplicando as etapas de batching, mapeamento, cache, shuffle e prefetch para otimizar o pipeline de dados durante o treinamento e a validação.\n",
    "\n",
    "**Entradas:**\n",
    "- `pairs` (list): Lista de tuplas, onde cada tupla contém um par de textos (francês, português).\n",
    "\n",
    "**Processamento:**\n",
    "1. **Separação dos Textos:**  \n",
    "   - Utiliza `zip(*pairs)` para descompactar os pares em duas listas: uma para os textos em francês e outra para os textos em português.\n",
    "2. **Criação do Dataset:**  \n",
    "   - Converte as listas em um dataset TensorFlow utilizando `tf_data.Dataset.from_tensor_slices`.\n",
    "3. **Batching:**  \n",
    "   - Agrupa os dados em lotes com o tamanho definido por `batch_size`.\n",
    "4. **Mapeamento:**  \n",
    "   - Aplica a função `format_dataset` para converter cada lote de textos brutos em um formato compatível com o modelo.\n",
    "5. **Otimização do Pipeline:**  \n",
    "   - Utiliza `cache()` para armazenar em cache o dataset.\n",
    "   - Embaralha os dados com `shuffle(2048)` para garantir aleatoriedade.\n",
    "   - Pré-carrega os dados com `prefetch(16)` para melhorar a performance durante o treinamento.\n",
    "\n",
    "**Saída:**\n",
    "- Retorna um `tf.data.Dataset` pronto para ser usado nos processos de treinamento ou validação.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### Uso dos Datasets\n",
    "\n",
    "Os datasets de treinamento e validação são criados utilizando as funções definidas:\n",
    "\n",
    "```python\n",
    "# Cria os datasets de treinamento e validação utilizando os pares correspondentes\n",
    "train_ds = make_dataset(train_pairs)\n",
    "val_ds = make_dataset(val_pairs)\n",
    "```\n",
    "\n",
    "Esses datasets serão usados para treinar e validar o modelo seq2seq, garantindo que os dados estejam no formato correto e que o pipeline de entrada seja eficiente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dataset(french, portuguese):\n",
    "    \"\"\"\n",
    "    Formata os pares de textos em francês e português para o modelo seq2seq.\n",
    "\n",
    "    Args:\n",
    "        french (Tensor): Textos em francês.\n",
    "        portuguese (Tensor): Textos em português.\n",
    "\n",
    "    Returns:\n",
    "        Tuple: Um dicionário com as entradas do encoder e do decoder, \n",
    "               e o alvo do decoder para o treinamento.\n",
    "    \"\"\"\n",
    "    # Vetoriza o texto em francês (entrada do encoder)\n",
    "    french = french_vectorization(french)\n",
    "    \n",
    "    # Vetoriza o texto em português (entrada e alvo do decoder)\n",
    "    portuguese = portuguese_vectorization(portuguese)\n",
    "    \n",
    "    return (\n",
    "        {\n",
    "            \"encoder_inputs\": french,  # Entrada do encoder\n",
    "            \"decoder_inputs\": portuguese[:, :-1],  # Entrada do decoder (sem o último token)\n",
    "        },\n",
    "        portuguese[:, 1:]  # Alvo do decoder (sem o primeiro token)\n",
    "    )\n",
    "\n",
    "\n",
    "def make_dataset(pairs):\n",
    "    \"\"\"\n",
    "    Cria um dataset formatado a partir dos pares de texto.\n",
    "\n",
    "    Args:\n",
    "        pairs (list): Lista de tuplas contendo os textos em francês e português.\n",
    "\n",
    "    Returns:\n",
    "        tf.data.Dataset: Dataset formatado para o treinamento e validação.\n",
    "    \"\"\"\n",
    "    # Separa os textos em francês e português dos pares\n",
    "    french_texts, portuguese_texts = zip(*pairs)\n",
    "    \n",
    "    # Cria um dataset TensorFlow a partir dos textos\n",
    "    dataset = tf_data.Dataset.from_tensor_slices(\n",
    "        (list(french_texts), list(portuguese_texts))\n",
    "    )\n",
    "    \n",
    "    # Agrupa os dados em lotes (batch)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    \n",
    "    # Aplica a função de formatação para preparar as entradas e alvos\n",
    "    dataset = dataset.map(format_dataset)\n",
    "    \n",
    "    # Armazena em cache, embaralha e pré-carrega os dados para otimização\n",
    "    return dataset.cache().shuffle(2048).prefetch(16)\n",
    "\n",
    "\n",
    "# Cria os datasets de treinamento e validação utilizando os pares correspondentes\n",
    "train_ds = make_dataset(train_pairs)\n",
    "val_ds = make_dataset(val_pairs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivo do Código: Implementar uma Camada de Embedding Posicional com Regularização Aprimorada\n",
    "\n",
    "Esta classe, `PositionalEmbedding`, é uma camada customizada do Keras que combina os embeddings dos tokens com embeddings posicionais. Essa combinação permite que o modelo capture não apenas a representação semântica dos tokens, mas também a informação sobre sua posição relativa na sequência, o que é essencial para muitas tarefas de Processamento de Linguagem Natural (NLP).\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. Inicialização da Camada (`__init__`)\n",
    "\n",
    "- **Parâmetros:**\n",
    "  - `sequence_length` (int): Comprimento máximo da sequência. Define quantas posições a camada pode representar.\n",
    "  - `vocab_size` (int): Tamanho do vocabulário, ou seja, o número máximo de tokens únicos.\n",
    "  - `embed_dim` (int): Dimensão do vetor de embedding para cada token e para cada posição.\n",
    "  - `**kwargs`: Argumentos adicionais para a classe base `Layer`.\n",
    "\n",
    "- **Componentes Internos:**\n",
    "  - `self.token_embeddings`: Camada de embedding que mapeia cada token para um vetor de dimensão `embed_dim`.\n",
    "  - `self.position_embeddings`: Camada de embedding que mapeia cada posição na sequência para um vetor de dimensão `embed_dim`.\n",
    "\n",
    "- **Armazenamento de Parâmetros:**\n",
    "  - Os parâmetros `sequence_length`, `vocab_size` e `embed_dim` são armazenados como atributos da classe para uso posterior e para possibilitar a serialização da camada.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Método `call`\n",
    "\n",
    "- **Objetivo:**\n",
    "  - Combinar os embeddings dos tokens com os embeddings das posições correspondentes, enriquecendo as representações dos tokens com a informação posicional.\n",
    "\n",
    "- **Processo:**\n",
    "  1. **Determinar o Comprimento da Sequência:**\n",
    "     - `length = ops.shape(inputs)[-1]`\n",
    "       - Obtém o comprimento da sequência a partir do shape do tensor de entrada.\n",
    "  2. **Gerar Índices de Posição:**\n",
    "     - `positions = ops.arange(0, length, 1)`\n",
    "       - Cria um tensor que representa as posições de 0 até `length - 1`.\n",
    "  3. **Aplicar Embeddings:**\n",
    "     - `embedded_tokens = self.token_embeddings(inputs)`\n",
    "       - Converte os tokens de entrada em seus respectivos vetores de embedding.\n",
    "     - `embedded_positions = self.position_embeddings(positions)`\n",
    "       - Converte os índices de posição em vetores de embedding.\n",
    "  4. **Combinar os Embeddings:**\n",
    "     - Retorna a soma dos embeddings dos tokens com os embeddings das posições:\n",
    "       ```python\n",
    "       return embedded_tokens + embedded_positions\n",
    "       ```\n",
    "       \n",
    "- **Saída:**\n",
    "  - Um tensor de shape `(batch_size, sequence_length, embed_dim)` contendo os embeddings enriquecidos com a informação de posição.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Método `compute_mask`\n",
    "\n",
    "- **Objetivo:**\n",
    "  - Gerar uma máscara para ignorar os tokens de padding (por exemplo, tokens com valor 0) durante o processamento.\n",
    "\n",
    "- **Processo:**\n",
    "  - Utiliza `ops.not_equal(inputs, 0)` para criar uma máscara booleana onde:\n",
    "    - `True` indica que o token é válido (diferente de 0).\n",
    "    - `False` indica que o token é padding.\n",
    "\n",
    "- **Saída:**\n",
    "  - Um tensor de máscara que pode ser usado pelas camadas subsequentes para ignorar os tokens de padding.\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. Método `get_config`\n",
    "\n",
    "- **Objetivo:**\n",
    "  - Permitir a serialização e reconstrução da camada, retornando sua configuração em forma de dicionário.\n",
    "\n",
    "- **Processo:**\n",
    "  - Chama `super().get_config()` para obter as configurações da camada base e atualiza esse dicionário com os parâmetros:\n",
    "    - `sequence_length`\n",
    "    - `vocab_size`\n",
    "    - `embed_dim`\n",
    "\n",
    "- **Saída:**\n",
    "  - Um dicionário com a configuração completa da camada, garantindo que ela possa ser salva e carregada corretamente.\n",
    "\n",
    "---\n",
    "\n",
    "#### Resumo\n",
    "\n",
    "A camada `PositionalEmbedding` é fundamental para modelos que precisam entender a ordem dos tokens. Ao combinar embeddings de tokens com embeddings posicionais, ela fornece ao modelo informações estruturais essenciais para capturar relações sequenciais, melhorando a performance em tarefas como tradução, sumarização e outras aplicações de NLP.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# Componentes do Modelo com Regularização Aprimorada\n",
    "# ------------------------\n",
    "\n",
    "class PositionalEmbedding(layers.Layer):\n",
    "    \"\"\"\n",
    "    Camada personalizada para aplicar embeddings de tokens combinados com embeddings posicionais.\n",
    "    Isso permite que o modelo entenda a ordem dos tokens na sequência.\n",
    "    \"\"\"\n",
    "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
    "        \"\"\"\n",
    "        Inicializa a camada de embeddings posicionais.\n",
    "\n",
    "        Args:\n",
    "            sequence_length (int): Comprimento máximo da sequência.\n",
    "            vocab_size (int): Tamanho do vocabulário (número máximo de tokens).\n",
    "            embed_dim (int): Dimensão do vetor de embedding.\n",
    "            **kwargs: Argumentos adicionais para a classe base `Layer`.\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        # Embedding para os tokens (representação vetorial de cada palavra/token)\n",
    "        self.token_embeddings = layers.Embedding(\n",
    "            input_dim=vocab_size, \n",
    "            output_dim=embed_dim\n",
    "        )\n",
    "        \n",
    "        # Embedding para a posição de cada token na sequência\n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim=sequence_length, \n",
    "            output_dim=embed_dim\n",
    "        )\n",
    "        \n",
    "        # Armazena os parâmetros para reutilização e configuração\n",
    "        self.sequence_length = sequence_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        Combina embeddings dos tokens com seus respectivos embeddings posicionais.\n",
    "\n",
    "        Args:\n",
    "            inputs (Tensor): Sequência de tokens (shape: batch_size, sequence_length).\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Embedding combinado de tokens e posições (shape: batch_size, sequence_length, embed_dim).\n",
    "        \"\"\"\n",
    "        # Obtém o comprimento da sequência (última dimensão da entrada)\n",
    "        length = ops.shape(inputs)[-1]\n",
    "        \n",
    "        # Cria um tensor representando as posições (0, 1, 2, ..., length - 1)\n",
    "        positions = ops.arange(0, length, 1)\n",
    "        \n",
    "        # Aplica o embedding nos tokens\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        \n",
    "        # Aplica o embedding nas posições\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        \n",
    "        # Combina o embedding dos tokens com o embedding das posições\n",
    "        return embedded_tokens + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        \"\"\"\n",
    "        Gera uma máscara para ignorar o padding (valores iguais a 0).\n",
    "\n",
    "        Args:\n",
    "            inputs (Tensor): Sequência de entrada.\n",
    "            mask (Tensor, opcional): Máscara existente.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Máscara onde valores diferentes de zero são marcados como válidos.\n",
    "        \"\"\"\n",
    "        # Cria a máscara usando `ops.not_equal` para detectar tokens válidos (diferentes de 0)\n",
    "        return ops.not_equal(inputs, 0)\n",
    "\n",
    "    def get_config(self):\n",
    "        \"\"\"\n",
    "        Retorna a configuração da camada para permitir a serialização do modelo.\n",
    "\n",
    "        Returns:\n",
    "            dict: Configurações da camada, incluindo comprimento da sequência, \n",
    "                  tamanho do vocabulário e dimensão do embedding.\n",
    "        \"\"\"\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"sequence_length\": self.sequence_length,\n",
    "            \"vocab_size\": self.vocab_size,\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "        })\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivo do Código: Implementar um Encoder Transformer com Dropout e Regularização Aprimorada\n",
    "\n",
    "Esta classe define um encoder baseado na arquitetura Transformer, que incorpora atenção multi-cabeça, redes feedforward e normalização em camadas, além de aplicar regularização via dropout em pontos críticos do fluxo. Essa implementação é essencial para construir modelos que lidam com sequências de forma eficiente e robusta, mitigando o overfitting e melhorando a generalização.\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. Inicialização da Camada (`__init__`)\n",
    "\n",
    "- **Parâmetros de Entrada:**\n",
    "  - `embed_dim` (int): Dimensão dos embeddings de entrada.\n",
    "  - `dense_dim` (int): Dimensão interna da rede feedforward.\n",
    "  - `num_heads` (int): Número de cabeças de atenção na camada multi-head.\n",
    "  - `dropout_rate` (float): Taxa de dropout aplicada após a atenção e a rede feedforward.\n",
    "  - `**kwargs`: Argumentos adicionais passados para a classe base `Layer`.\n",
    "\n",
    "- **Componentes Críticos:**\n",
    "  - **Atenção Multi-Cabeça:**  \n",
    "    Utiliza `layers.MultiHeadAttention` para permitir que o modelo foque em diferentes partes da sequência simultaneamente.  \n",
    "    ```python\n",
    "    self.attention = layers.MultiHeadAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=embed_dim\n",
    "    )\n",
    "    ```\n",
    "  - **Dropout após a Atenção:**  \n",
    "    Aplica regularização ao output da camada de atenção para reduzir o overfitting.  \n",
    "    ```python\n",
    "    self.dropout_att = layers.Dropout(dropout_rate)\n",
    "    ```\n",
    "  - **Rede Feedforward:**  \n",
    "    Uma sequência de duas camadas densas que processa a saída da camada de atenção:  \n",
    "    - Primeira camada: Projeção para uma dimensão `dense_dim` com ativação ReLU.\n",
    "    - Segunda camada: Projeção de volta para `embed_dim`.\n",
    "    ```python\n",
    "    self.dense_proj = keras.Sequential([\n",
    "        layers.Dense(dense_dim, activation=\"relu\"),\n",
    "        layers.Dense(embed_dim),\n",
    "    ])\n",
    "    ```\n",
    "  - **Dropout após o Feedforward:**  \n",
    "    Aplica dropout ao output da rede feedforward para regularização adicional.  \n",
    "    ```python\n",
    "    self.dropout_ffn = layers.Dropout(dropout_rate)\n",
    "    ```\n",
    "  - **Normalização em Camadas:**  \n",
    "    Duas camadas de `LayerNormalization` são utilizadas para estabilizar a aprendizagem e melhorar a convergência:\n",
    "    - `self.layernorm_1`: Após a soma residual com a atenção.\n",
    "    - `self.layernorm_2`: Após a soma residual com o feedforward.\n",
    "  - **Suporte a Máscaras:**  \n",
    "    Define `self.supports_masking = True` para permitir que a camada ignore tokens de padding durante o processamento.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Método `call`\n",
    "\n",
    "- **Entradas:**\n",
    "  - `inputs` (Tensor): Tensor de entrada com shape `(batch_size, sequence_length, embed_dim)`.\n",
    "  - `mask` (Tensor, opcional): Máscara para ignorar posições de padding.\n",
    "  - `training` (bool, opcional): Flag que indica se a camada está em modo de treinamento, para controlar a aplicação do dropout.\n",
    "\n",
    "- **Processamento Passo a Passo:**\n",
    "\n",
    "  1. **Preparação da Máscara:**  \n",
    "     Se uma máscara for fornecida, ela é ajustada para compatibilidade com a atenção, expandindo a dimensão do eixo das cabeças:\n",
    "     ```python\n",
    "     if mask is not None:\n",
    "         padding_mask = tf.cast(mask[:, None, :], dtype=\"int32\")\n",
    "     else:\n",
    "         padding_mask = None\n",
    "     ```\n",
    "  \n",
    "  2. **Atenção Multi-Cabeça:**  \n",
    "     A camada de atenção é aplicada com os mesmos `inputs` como query, key e value, utilizando a máscara (se houver):\n",
    "     ```python\n",
    "     attention_output = self.attention(\n",
    "         query=inputs,\n",
    "         value=inputs,\n",
    "         key=inputs,\n",
    "         attention_mask=padding_mask\n",
    "     )\n",
    "     ```\n",
    "  \n",
    "  3. **Dropout na Atenção:**  \n",
    "     Aplica dropout ao resultado da atenção, somente durante o treinamento:\n",
    "     ```python\n",
    "     attention_output = self.dropout_att(attention_output, training=training)\n",
    "     ```\n",
    "  \n",
    "  4. **Soma Residual e Normalização (Atenção):**  \n",
    "     Soma o output da atenção com o input original e normaliza o resultado:\n",
    "     ```python\n",
    "     proj_input = self.layernorm_1(inputs + attention_output)\n",
    "     ```\n",
    "  \n",
    "  5. **Rede Feedforward:**  \n",
    "     Processa a saída normalizada por meio da rede feedforward:\n",
    "     ```python\n",
    "     proj_output = self.dense_proj(proj_input)\n",
    "     ```\n",
    "  \n",
    "  6. **Dropout na Rede Feedforward:**  \n",
    "     Aplica dropout ao resultado da rede feedforward durante o treinamento:\n",
    "     ```python\n",
    "     proj_output = self.dropout_ffn(proj_output, training=training)\n",
    "     ```\n",
    "  \n",
    "  7. **Soma Residual e Normalização (Feedforward):**  \n",
    "     Soma a entrada normalizada (após atenção) com o output do feedforward e aplica normalização final:\n",
    "     ```python\n",
    "     return self.layernorm_2(proj_input + proj_output)\n",
    "     ```\n",
    "\n",
    "- **Saída:**\n",
    "  - Um tensor de saída com a mesma forma que o input, enriquecido com as operações de atenção, feedforward e normalização.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Método `get_config`\n",
    "\n",
    "- **Objetivo:**\n",
    "  - Permitir a serialização e a reconstrução da camada, retornando suas configurações essenciais.\n",
    "\n",
    "- **Processo:**\n",
    "  - Recupera a configuração base da camada e a atualiza com os parâmetros `embed_dim`, `dense_dim` e `num_heads`.\n",
    "  - Retorna o dicionário de configuração.\n",
    "\n",
    "```python\n",
    "def get_config(self):\n",
    "    config = super().get_config()\n",
    "    config.update({\n",
    "        \"embed_dim\": self.embed_dim,\n",
    "        \"dense_dim\": self.dense_dim,\n",
    "        \"num_heads\": self.num_heads,\n",
    "    })\n",
    "    return config\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Resumo\n",
    "\n",
    "A classe `TransformerEncoder` implementa um encoder Transformer completo com:\n",
    "- **Atenção Multi-Cabeça:** Para capturar diferentes relacionamentos entre tokens.\n",
    "- **Redes Feedforward:** Para transformar as representações obtidas pela atenção.\n",
    "- **Dropout:** Aplicado após a atenção e a rede feedforward, visando regularização.\n",
    "- **Normalização em Camadas:** Para estabilizar e acelerar o treinamento.\n",
    "- **Suporte a Máscaras:** Permite o tratamento de tokens de padding.\n",
    "\n",
    "Essa implementação é essencial para construir modelos Transformer robustos e eficientes em tarefas como tradução, classificação de texto, e outras aplicações em NLP.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer Encoder com Dropout adicionado nas camadas de atenção e feedforward\n",
    "class TransformerEncoder(layers.Layer):\n",
    "    \"\"\"\n",
    "    Encoder do Transformer que aplica atenção multi-cabeça, normalização em camadas\n",
    "    e redes feedforward, com regularização por Dropout.\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, dropout_rate=0.1, **kwargs):\n",
    "        \"\"\"\n",
    "        Inicializa o Transformer Encoder.\n",
    "\n",
    "        Args:\n",
    "            embed_dim (int): Dimensão dos embeddings de entrada.\n",
    "            dense_dim (int): Dimensão da rede feedforward interna.\n",
    "            num_heads (int): Número de cabeças de atenção.\n",
    "            dropout_rate (float): Taxa de dropout para regularização.\n",
    "            **kwargs: Argumentos adicionais para a classe base `Layer`.\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Parâmetros da camada\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        # Camada de Atenção Multi-Cabeça\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=embed_dim\n",
    "        )\n",
    "\n",
    "        # Dropout aplicado após a camada de atenção\n",
    "        self.dropout_att = layers.Dropout(dropout_rate)\n",
    "\n",
    "        # Rede feedforward composta por duas camadas densas\n",
    "        self.dense_proj = keras.Sequential([\n",
    "            layers.Dense(dense_dim, activation=\"relu\"),\n",
    "            layers.Dense(embed_dim),\n",
    "        ])\n",
    "\n",
    "        # Dropout aplicado após a rede feedforward\n",
    "        self.dropout_ffn = layers.Dropout(dropout_rate)\n",
    "\n",
    "        # Normalização em camadas aplicada após a atenção e o feedforward\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "\n",
    "        # Indica que a camada suporta mascaramento (útil para lidar com padding)\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, mask=None, training=False):\n",
    "        \"\"\"\n",
    "        Executa a passagem dos dados pela camada Transformer Encoder.\n",
    "\n",
    "        Args:\n",
    "            inputs (Tensor): Tensor de entrada (batch_size, sequence_length, embed_dim).\n",
    "            mask (Tensor, opcional): Máscara para ignorar posições de padding.\n",
    "            training (bool, opcional): Indica se a camada está em modo de treinamento.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Saída do encoder após atenção, feedforward e normalização.\n",
    "        \"\"\"\n",
    "        # Se uma máscara for fornecida, ajusta o formato para ser compatível com a atenção\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(mask[:, None, :], dtype=\"int32\")\n",
    "        else:\n",
    "            padding_mask = None\n",
    "\n",
    "        # Aplica a atenção multi-cabeça com a máscara de padding (se existir)\n",
    "        attention_output = self.attention(\n",
    "            query=inputs,\n",
    "            value=inputs,\n",
    "            key=inputs,\n",
    "            attention_mask=padding_mask\n",
    "        )\n",
    "\n",
    "        # Aplica Dropout após a atenção (apenas durante o treinamento)\n",
    "        attention_output = self.dropout_att(attention_output, training=training)\n",
    "\n",
    "        # Normaliza a soma residual entre a entrada e a saída da atenção\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "\n",
    "        # Passa pela rede feedforward\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "\n",
    "        # Aplica Dropout após o feedforward (apenas durante o treinamento)\n",
    "        proj_output = self.dropout_ffn(proj_output, training=training)\n",
    "\n",
    "        # Normaliza a soma residual entre o input normalizado e a saída do feedforward\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "\n",
    "    def get_config(self):\n",
    "        \"\"\"\n",
    "        Retorna a configuração da camada para permitir a serialização do modelo.\n",
    "\n",
    "        Returns:\n",
    "            dict: Configurações da camada, incluindo embed_dim, dense_dim e num_heads.\n",
    "        \"\"\"\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "        })\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivo do Código: Implementar um Transformer Decoder com Dropout e Regularização Aprimorada\n",
    "\n",
    "Esta classe, `TransformerDecoder`, define um decoder do Transformer que incorpora duas subcamadas de atenção (self-attention e cross-attention), uma rede feedforward e várias operações de regularização, como dropout e normalização em camadas. O decoder também utiliza uma máscara causal para garantir que a previsão de cada token não dependa de tokens futuros, mantendo a propriedade autoregressiva durante a geração de sequência.\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. Inicialização da Camada (`__init__`)\n",
    "\n",
    "- **Parâmetros de Entrada:**\n",
    "  - `embed_dim` (int): Dimensão dos embeddings de entrada.\n",
    "  - `latent_dim` (int): Dimensão interna da rede feedforward.\n",
    "  - `num_heads` (int): Número de cabeças de atenção multi-head.\n",
    "  - `dropout_rate` (float): Taxa de dropout aplicada após cada subcamada, com valor padrão de 0.1.\n",
    "  - `**kwargs`: Argumentos adicionais para a classe base `Layer`.\n",
    "\n",
    "- **Componentes Criados:**\n",
    "  - **Primeira Atenção Multi-Cabeça (Self-Attention):**\n",
    "    - `self.attention_1`: Camada de self-attention para processar os inputs do decoder.\n",
    "    - `self.dropout_att1`: Dropout aplicado ao output da self-attention.\n",
    "    \n",
    "  - **Segunda Atenção Multi-Cabeça (Cross-Attention):**\n",
    "    - `self.attention_2`: Camada de cross-attention que utiliza a saída do encoder para refinar as representações do decoder.\n",
    "    - `self.dropout_att2`: Dropout aplicado após a cross-attention.\n",
    "    \n",
    "  - **Rede Feedforward:**\n",
    "    - `self.dense_proj`: Uma rede feedforward composta por duas camadas densas:\n",
    "      - A primeira camada projeta para uma dimensão `latent_dim` com ativação ReLU.\n",
    "      - A segunda camada retorna ao espaço de `embed_dim`.\n",
    "    - `self.dropout_ffn`: Dropout aplicado à saída da rede feedforward.\n",
    "    \n",
    "  - **Normalizações em Camadas:**\n",
    "    - `self.layernorm_1`: Normaliza a soma residual após a self-attention.\n",
    "    - `self.layernorm_2`: Normaliza a soma residual após a cross-attention.\n",
    "    - `self.layernorm_3`: Normaliza a soma residual após a rede feedforward.\n",
    "    \n",
    "  - **Suporte a Máscaras:**\n",
    "    - `self.supports_masking = True` indica que a camada pode processar inputs com máscaras (útil para ignorar padding).\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Método `call`\n",
    "\n",
    "- **Entradas:**\n",
    "  - `inputs` (tuple): Contém uma tupla `(decoder_inputs, encoder_outputs)`:\n",
    "    - `decoder_inputs`: Representa a sequência de entrada do decoder (normalmente já embutida).\n",
    "    - `encoder_outputs`: Saída do encoder, que será utilizada na cross-attention.\n",
    "  - `mask` (tuple, opcional): Contém duas máscaras:\n",
    "    - `decoder_padding_mask`: Para ignorar tokens de padding no decoder.\n",
    "    - `encoder_padding_mask`: Para ignorar tokens de padding no encoder.\n",
    "  - `training` (bool, opcional): Indica se a camada está em modo de treinamento para ativar o dropout.\n",
    "\n",
    "- **Fluxo de Processamento:**\n",
    "\n",
    "  1. **Geração da Máscara Causal:**\n",
    "     - Chama `self.get_causal_attention_mask(decoder_inputs)` para criar uma máscara que impede o acesso a tokens futuros, garantindo a propriedade autoregressiva.\n",
    "  \n",
    "  2. **Processamento da Self-Attention (Primeira Atenção Multi-Cabeça):**\n",
    "     - Aplica `self.attention_1` aos `decoder_inputs` usando a máscara causal (e opcionalmente uma máscara de padding para o decoder).\n",
    "     - O resultado passa pelo dropout `self.dropout_att1`.\n",
    "     - Realiza uma soma residual entre o input original e o output da atenção, seguido de normalização com `self.layernorm_1`, produzindo `out_1`.\n",
    "  \n",
    "  3. **Processamento da Cross-Attention (Segunda Atenção Multi-Cabeça):**\n",
    "     - Aplica `self.attention_2` utilizando `out_1` como query e os `encoder_outputs` como key e value. As máscaras para o decoder e o encoder são aplicadas, se fornecidas.\n",
    "     - O output é submetido ao dropout `self.dropout_att2`.\n",
    "     - Realiza a soma residual de `out_1` e o output da cross-attention, seguido de normalização com `self.layernorm_2`, resultando em `out_2`.\n",
    "  \n",
    "  4. **Rede Feedforward:**\n",
    "     - Processa `out_2` através da rede feedforward `self.dense_proj`.\n",
    "     - Aplica dropout à saída com `self.dropout_ffn`.\n",
    "     - Realiza a soma residual de `out_2` com o output do feedforward e aplica uma última normalização com `self.layernorm_3`.\n",
    "  \n",
    "  5. **Saída:**\n",
    "     - Retorna o tensor resultante que integra as operações de atenção (self e cross), feedforward e normalização, pronto para ser passado para as camadas subsequentes ou para gerar predições.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Método `get_causal_attention_mask`\n",
    "\n",
    "- **Objetivo:**\n",
    "  - Gerar uma máscara causal que impede que cada posição do decoder acesse tokens futuros.\n",
    "  \n",
    "- **Processo:**\n",
    "  - Calcula o comprimento da sequência (`seq_length`) a partir do tensor `inputs`.\n",
    "  - Cria uma matriz lower-triangular (usando `tf.range` e comparações) onde cada posição `i` só pode ver posições `j` onde `j ≤ i`.\n",
    "  - Ajusta a forma da máscara para compatibilidade com a atenção multi-cabeça e a replica para o tamanho do batch.\n",
    "\n",
    "- **Saída:**\n",
    "  - Um tensor de máscara com shape `(batch_size, seq_length, seq_length)`.\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. Método `get_config`\n",
    "\n",
    "- **Objetivo:**\n",
    "  - Permitir a serialização da camada retornando um dicionário com as configurações principais.\n",
    "  \n",
    "- **Processo:**\n",
    "  - Chama `super().get_config()` para obter a configuração base e atualiza o dicionário com os parâmetros:\n",
    "    - `embed_dim`\n",
    "    - `latent_dim`\n",
    "    - `num_heads`\n",
    "  \n",
    "- **Saída:**\n",
    "  - Um dicionário contendo as configurações da camada, facilitando sua serialização e posterior reconstrução.\n",
    "\n",
    "```python\n",
    "def get_config(self):\n",
    "    config = super().get_config()\n",
    "    config.update({\n",
    "        \"embed_dim\": self.embed_dim,\n",
    "        \"latent_dim\": self.latent_dim,\n",
    "        \"num_heads\": self.num_heads,\n",
    "    })\n",
    "    return config\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Resumo\n",
    "\n",
    "A classe `TransformerDecoder` implementa um decoder Transformer robusto com:\n",
    "- **Self-Attention Causal:** Garante que cada token não possa ver o futuro, mantendo o caráter autoregressivo.\n",
    "- **Cross-Attention:** Permite ao decoder integrar informações relevantes do encoder.\n",
    "- **Rede Feedforward:** Processa as representações combinadas para obter features mais refinadas.\n",
    "- **Dropout e Normalização:** Aplicados após cada subcamada para regularização e estabilidade durante o treinamento.\n",
    "- **Suporte a Máscaras:** Trata adequadamente o padding em ambas as entradas do decoder e do encoder.\n",
    "\n",
    "Essa estrutura é fundamental para tarefas como tradução automática, geração de texto e outras aplicações que utilizam a arquitetura Transformer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer Decoder com Dropout adicionado nas subcamadas de atenção e na rede feedforward\n",
    "class TransformerDecoder(layers.Layer):\n",
    "    \"\"\"\n",
    "    Decoder do Transformer que aplica atenção causal, cross-attention com a saída do encoder,\n",
    "    normalização em camadas e redes feedforward, com regularização por Dropout.\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim, latent_dim, num_heads, dropout_rate=0.1, **kwargs):\n",
    "        \"\"\"\n",
    "        Inicializa o Transformer Decoder.\n",
    "\n",
    "        Args:\n",
    "            embed_dim (int): Dimensão dos embeddings de entrada.\n",
    "            latent_dim (int): Dimensão da rede feedforward interna.\n",
    "            num_heads (int): Número de cabeças de atenção.\n",
    "            dropout_rate (float): Taxa de dropout para regularização.\n",
    "            **kwargs: Argumentos adicionais para a classe base `Layer`.\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Parâmetros do decoder\n",
    "        self.embed_dim = embed_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        # Primeira camada de Atenção Multi-Cabeça (Self-Attention com máscara causal)\n",
    "        self.attention_1 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=embed_dim\n",
    "        )\n",
    "        self.dropout_att1 = layers.Dropout(dropout_rate)\n",
    "\n",
    "        # Segunda camada de Atenção Multi-Cabeça (Cross-Attention com saída do encoder)\n",
    "        self.attention_2 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=embed_dim\n",
    "        )\n",
    "        self.dropout_att2 = layers.Dropout(dropout_rate)\n",
    "\n",
    "        # Rede feedforward com ativação ReLU\n",
    "        self.dense_proj = keras.Sequential([\n",
    "            layers.Dense(latent_dim, activation=\"relu\"),\n",
    "            layers.Dense(embed_dim),\n",
    "        ])\n",
    "        self.dropout_ffn = layers.Dropout(dropout_rate)\n",
    "\n",
    "        # Normalização em camadas após cada subcamada do decoder\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.layernorm_3 = layers.LayerNormalization()\n",
    "\n",
    "        # Indica que a camada suporta mascaramento (útil para lidar com padding)\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, mask=None, training=False):\n",
    "        \"\"\"\n",
    "        Executa a passagem dos dados pela camada Transformer Decoder.\n",
    "\n",
    "        Args:\n",
    "            inputs (tuple): Tupla contendo (decoder_inputs, encoder_outputs).\n",
    "            mask (tuple, opcional): Máscaras para o decoder e o encoder.\n",
    "            training (bool, opcional): Indica se a camada está em modo de treinamento.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Saída do decoder após atenção, feedforward e normalização.\n",
    "        \"\"\"\n",
    "        decoder_inputs, encoder_outputs = inputs\n",
    "\n",
    "        # Cria a máscara causal para evitar que o decoder veja tokens futuros\n",
    "        causal_mask = self.get_causal_attention_mask(decoder_inputs)\n",
    "\n",
    "        # Se uma máscara for fornecida, separa as máscaras do decoder e do encoder\n",
    "        if mask is None:\n",
    "            decoder_padding_mask, encoder_padding_mask = None, None\n",
    "        else:\n",
    "            decoder_padding_mask, encoder_padding_mask = mask\n",
    "\n",
    "        # Primeira Atenção Multi-Cabeça (Self-Attention com máscara causal)\n",
    "        attention_output_1 = self.attention_1(\n",
    "            query=decoder_inputs,\n",
    "            value=decoder_inputs,\n",
    "            key=decoder_inputs,\n",
    "            attention_mask=causal_mask,\n",
    "            query_mask=decoder_padding_mask,\n",
    "        )\n",
    "        attention_output_1 = self.dropout_att1(attention_output_1, training=training)\n",
    "\n",
    "        # Soma residual e normalização após a primeira atenção\n",
    "        out_1 = self.layernorm_1(decoder_inputs + attention_output_1)\n",
    "\n",
    "        # Segunda Atenção Multi-Cabeça (Cross-Attention com saída do encoder)\n",
    "        attention_output_2 = self.attention_2(\n",
    "            query=out_1,\n",
    "            value=encoder_outputs,\n",
    "            key=encoder_outputs,\n",
    "            query_mask=decoder_padding_mask,\n",
    "            key_mask=encoder_padding_mask,\n",
    "        )\n",
    "        attention_output_2 = self.dropout_att2(attention_output_2, training=training)\n",
    "\n",
    "        # Soma residual e normalização após a cross-attention\n",
    "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
    "\n",
    "        # Passagem pela rede feedforward\n",
    "        proj_output = self.dense_proj(out_2)\n",
    "        proj_output = self.dropout_ffn(proj_output, training=training)\n",
    "\n",
    "        # Soma residual e normalização após a rede feedforward\n",
    "        return self.layernorm_3(out_2 + proj_output)\n",
    "\n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        \"\"\"\n",
    "        Gera uma máscara causal para a atenção, impedindo o acesso a tokens futuros.\n",
    "\n",
    "        Args:\n",
    "            inputs (Tensor): Sequência de entrada do decoder.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Máscara causal com shape (batch_size, seq_length, seq_length).\n",
    "        \"\"\"\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, seq_length = input_shape[0], input_shape[1]\n",
    "\n",
    "        # Cria uma matriz onde cada posição i só pode ver até a posição j (i >= j)\n",
    "        i = tf.range(seq_length)[:, None]\n",
    "        j = tf.range(seq_length)\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "\n",
    "        # Ajusta o formato da máscara para ser compatível com a atenção multi-cabeça\n",
    "        mask = tf.reshape(mask, (1, seq_length, seq_length))\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1), tf.convert_to_tensor([1, 1])], axis=0\n",
    "        )\n",
    "        return tf.tile(mask, mult)\n",
    "\n",
    "    def get_config(self):\n",
    "        \"\"\"\n",
    "        Retorna a configuração da camada para permitir a serialização do modelo.\n",
    "\n",
    "        Returns:\n",
    "            dict: Configurações da camada, incluindo embed_dim, latent_dim e num_heads.\n",
    "        \"\"\"\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"latent_dim\": self.latent_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "        })\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivo do Código: Construir um Modelo Transformer Completo\n",
    "\n",
    "Este trecho de código monta um modelo Transformer composto por um encoder e um decoder, utilizando técnicas de embedding posicional, atenção multi-cabeça, redes feedforward e regularização via dropout. O modelo é configurado para tarefas de geração de sequência, como tradução automática, onde o decoder é treinado utilizando o método de *teacher forcing*.\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. Definição dos Hiperparâmetros\n",
    "\n",
    "- **`embed_dim = 128`**  \n",
    "  Define a dimensão dos embeddings que serão gerados para cada token.\n",
    "  \n",
    "- **`latent_dim = 1024`**  \n",
    "  Especifica a dimensão interna da rede feedforward dentro dos blocos do Transformer. Essa dimensão é geralmente maior que `embed_dim` para permitir transformações mais complexas.\n",
    "  \n",
    "- **`num_heads = 6`**  \n",
    "  Número de cabeças utilizadas na camada de atenção multi-cabeça, permitindo que o modelo foque em diferentes subespaços das representações.\n",
    "  \n",
    "- **`sequence_length = 20`**  \n",
    "  Comprimento máximo das sequências de entrada. Essa definição é usada tanto para o encoder quanto para o decoder.\n",
    "  \n",
    "- **`vocab_size_model = 15000`**  \n",
    "  Tamanho do vocabulário que o modelo utiliza, ou seja, o número total de tokens únicos que podem ser processados.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Construção do Encoder\n",
    "\n",
    "- **Entrada do Encoder:**\n",
    "  ```python\n",
    "  encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
    "  ```\n",
    "  - Define a entrada do encoder, que é uma sequência de tokens inteiros com comprimento variável (o `None` permite sequências de diferentes tamanhos).\n",
    "\n",
    "- **Embedding Posicional:**\n",
    "  ```python\n",
    "  x = PositionalEmbedding(sequence_length, vocab_size_model, embed_dim)(encoder_inputs)\n",
    "  ```\n",
    "  - Aplica a camada `PositionalEmbedding` para combinar embeddings dos tokens com informações posicionais, permitindo ao modelo capturar a ordem dos tokens.\n",
    "\n",
    "- **Passagem pelo Transformer Encoder:**\n",
    "  ```python\n",
    "  encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
    "  ```\n",
    "  - Processa os embeddings enriquecidos pelo encoder, utilizando atenção multi-cabeça, redes feedforward e normalização, com dropout para regularização.\n",
    "\n",
    "- **Definição do Modelo Encoder:**\n",
    "  ```python\n",
    "  encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
    "  ```\n",
    "  - Cria um modelo Keras que mapeia as entradas do encoder para suas saídas processadas. Esse modelo poderá ser usado para gerar representações contextuais da sequência de entrada.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Construção do Decoder (usando Teacher Forcing)\n",
    "\n",
    "- **Entrada do Decoder:**\n",
    "  ```python\n",
    "  decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
    "  ```\n",
    "  - Define a entrada do decoder, que consiste em uma sequência de tokens de destino (normalmente iniciada com um token especial de início).\n",
    "\n",
    "- **Embedding Posicional para o Decoder:**\n",
    "  ```python\n",
    "  x = PositionalEmbedding(sequence_length, vocab_size_model, embed_dim)(decoder_inputs)\n",
    "  ```\n",
    "  - Aplica a camada de embedding posicional aos tokens do decoder para incorporar informações de posição.\n",
    "\n",
    "- **Passagem pelo Transformer Decoder:**\n",
    "  ```python\n",
    "  x = TransformerDecoder(embed_dim, latent_dim, num_heads)([x, encoder_outputs])\n",
    "  ```\n",
    "  - Processa os embeddings do decoder utilizando:\n",
    "    - **Self-Attention Causal:** Para que o decoder não \"veja\" tokens futuros.\n",
    "    - **Cross-Attention:** Que utiliza as saídas do encoder para melhorar a geração da sequência.\n",
    "  - As operações de dropout e normalização em cada subcamada ajudam a estabilizar e regularizar o treinamento.\n",
    "\n",
    "- **Camada Densa Final para Previsão:**\n",
    "  ```python\n",
    "  decoder_outputs = layers.Dense(vocab_size_model, activation=\"softmax\")(x)\n",
    "  ```\n",
    "  - Uma camada densa com ativação `softmax` converte as saídas do decoder em uma distribuição de probabilidade sobre o vocabulário, permitindo a predição do token em cada posição da sequência de saída.\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. Definição do Modelo Final Transformer\n",
    "\n",
    "- **Criação do Modelo Completo:**\n",
    "  ```python\n",
    "  transformer = keras.Model(\n",
    "      {\"encoder_inputs\": encoder_inputs, \"decoder_inputs\": decoder_inputs},\n",
    "      decoder_outputs,\n",
    "      name=\"transformer\",\n",
    "  )\n",
    "  ```\n",
    "  - Combina o encoder e o decoder em um único modelo Transformer que recebe duas entradas:\n",
    "    - `\"encoder_inputs\"`: Para o encoder processar a sequência de entrada.\n",
    "    - `\"decoder_inputs\"`: Para o decoder, utilizado com *teacher forcing* durante o treinamento.\n",
    "  - A saída do modelo é a predição final do decoder, que é uma sequência de distribuições de probabilidade sobre o vocabulário.\n",
    "\n",
    "- **Exibição do Resumo do Modelo:**\n",
    "  ```python\n",
    "  transformer.summary()\n",
    "  ```\n",
    "  - Exibe um resumo da arquitetura do modelo, listando as camadas, shapes dos tensores e o número de parâmetros treináveis.\n",
    "\n",
    "---\n",
    "\n",
    "### Resumo Geral\n",
    "\n",
    "- **Encoder:**  \n",
    "  Converte a sequência de entrada em embeddings enriquecidos com informações posicionais e processa esses embeddings através de um bloco Transformer que utiliza atenção multi-cabeça, redes feedforward e normalização.\n",
    "\n",
    "- **Decoder:**  \n",
    "  Recebe uma sequência de tokens de destino, aplica embeddings posicionais e passa esses embeddings por um bloco Transformer Decoder. O decoder utiliza self-attention (com máscara causal) e cross-attention para integrar informações do encoder, e a saída final é convertida em predições de tokens através de uma camada densa com softmax.\n",
    "\n",
    "- **Modelo Transformer Completo:**  \n",
    "  O modelo resultante integra o encoder e o decoder, estando preparado para tarefas de geração de sequência, como tradução automática, onde o modelo aprende a mapear uma sequência de entrada para uma sequência de saída.\n",
    "\n",
    "Este design modular e regularizado é fundamental para a performance e robustez dos modelos Transformer em diversas aplicações de NLP.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"transformer\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,922,560</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_4         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,922,560</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_encode… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">659,456</span> │ positional_embed… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │ not_equal_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_5         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_decode… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,055,360</span> │ positional_embed… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ transformer_enco… │\n",
       "│                     │                   │            │ not_equal_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ not_equal_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,935,000</span> │ transformer_deco… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">15000</span>)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │  \u001b[38;5;34m1,922,560\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mPositionalEmbeddi…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_4         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │  \u001b[38;5;34m1,922,560\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mPositionalEmbeddi…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_encode… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │    \u001b[38;5;34m659,456\u001b[0m │ positional_embed… │\n",
       "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │ not_equal_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_5         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_decode… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │  \u001b[38;5;34m1,055,360\u001b[0m │ positional_embed… │\n",
       "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ transformer_enco… │\n",
       "│                     │                   │            │ not_equal_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ not_equal_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │  \u001b[38;5;34m1,935,000\u001b[0m │ transformer_deco… │\n",
       "│                     │ \u001b[38;5;34m15000\u001b[0m)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,494,936</span> (28.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,494,936\u001b[0m (28.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,494,936</span> (28.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,494,936\u001b[0m (28.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ------------------------\n",
    "# Construção do Modelo Transformer\n",
    "# ------------------------\n",
    "\n",
    "# Definição dos hiperparâmetros do modelo\n",
    "embed_dim = 128           # Dimensão do embedding para os tokens\n",
    "latent_dim = 1024         # Dimensão da rede feed-forward dentro dos blocos do Transformer\n",
    "num_heads = 6             # Número de cabeças de atenção na Multi-Head Attention\n",
    "sequence_length = 20      # Comprimento máximo da sequência de entrada\n",
    "vocab_size_model = 15000  # Tamanho do vocabulário usado no modelo\n",
    "\n",
    "# ------------------------\n",
    "# Construção do Encoder\n",
    "# ------------------------\n",
    "\n",
    "# Entrada do encoder: sequência de tokens inteiros (shape: batch_size, sequence_length)\n",
    "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
    "\n",
    "# Aplica a camada de embedding posicional para adicionar informações sobre a ordem dos tokens\n",
    "x = PositionalEmbedding(sequence_length, vocab_size_model, embed_dim)(encoder_inputs)\n",
    "\n",
    "# Passa os embeddings pelo Transformer Encoder\n",
    "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
    "\n",
    "# Define o modelo do encoder, mapeando as entradas para as saídas processadas\n",
    "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
    "\n",
    "# ------------------------\n",
    "# Construção do Decoder (usando Teacher Forcing)\n",
    "# ------------------------\n",
    "\n",
    "# Entrada do decoder: sequência de tokens de destino (shape: batch_size, sequence_length)\n",
    "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
    "\n",
    "# Aplica a camada de embedding posicional nos inputs do decoder\n",
    "x = PositionalEmbedding(sequence_length, vocab_size_model, embed_dim)(decoder_inputs)\n",
    "\n",
    "# Passa os embeddings pelo Transformer Decoder, utilizando as saídas do encoder\n",
    "x = TransformerDecoder(embed_dim, latent_dim, num_heads)([x, encoder_outputs])\n",
    "\n",
    "# Camada densa final para gerar as previsões de tokens (com ativação softmax)\n",
    "decoder_outputs = layers.Dense(vocab_size_model, activation=\"softmax\")(x)\n",
    "\n",
    "# ------------------------\n",
    "# Definição do Modelo Final Transformer\n",
    "# ------------------------\n",
    "\n",
    "# Cria o modelo Transformer completo, com entradas para o encoder e decoder\n",
    "transformer = keras.Model(\n",
    "    {\"encoder_inputs\": encoder_inputs, \"decoder_inputs\": decoder_inputs},\n",
    "    decoder_outputs,\n",
    "    name=\"transformer\",\n",
    ")\n",
    "\n",
    "# Exibe o resumo da arquitetura do modelo, mostrando as camadas e parâmetros\n",
    "transformer.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivo do Código: Compilar o Modelo Transformer com Otimizador Adam e Scheduler de Aprendizado\n",
    "\n",
    "Este trecho de código configura a estratégia de otimização do modelo Transformer, utilizando um scheduler para a taxa de aprendizado e o otimizador Adam. A função de perda escolhida é a `SparseCategoricalCrossentropy`, que é adequada para problemas de classificação com múltiplas classes, e ignora o índice 0 (usado para padding). A métrica de acurácia é utilizada para monitorar o desempenho durante o treinamento.\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. Scheduler para Taxa de Aprendizado Adaptativa\n",
    "\n",
    "- **Exponential Decay Scheduler:**\n",
    "  - Define um scheduler que diminui a taxa de aprendizado de forma exponencial ao longo do tempo.\n",
    "  - Parâmetros:\n",
    "    - `initial_learning_rate=1e-3`: Taxa de aprendizado inicial.\n",
    "    - `decay_steps=10000`: Número de passos (batches ou iterações) antes de aplicar o decaimento.\n",
    "    - `decay_rate=0.9`: Fator pelo qual a taxa de aprendizado é multiplicada a cada `decay_steps`.\n",
    "    - `staircase=True`: Se `True`, o decaimento ocorre em \"degraus\", ou seja, a taxa é reduzida de forma discreta a cada `decay_steps` (em vez de ser contínua).\n",
    "    \n",
    "```python\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-3,  # Taxa de aprendizado inicial\n",
    "    decay_steps=10000,           # Número de passos antes de aplicar o decaimento\n",
    "    decay_rate=0.9,              # Fator de decaimento exponencial\n",
    "    staircase=True               # O decaimento ocorre em \"degraus\" (não contínuo)\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Otimizador Adam com Scheduler\n",
    "\n",
    "- **Adam Optimizer:**\n",
    "  - Utiliza o otimizador Adam, que é amplamente utilizado devido à sua capacidade de lidar com problemas de otimização de forma eficiente.\n",
    "  - A taxa de aprendizado do Adam é controlada pelo scheduler definido anteriormente (`lr_schedule`).\n",
    "\n",
    "```python\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Compilação do Modelo Transformer\n",
    "\n",
    "- **Configuração da Compilação:**\n",
    "  - **Otimizador:** Utiliza o otimizador Adam configurado com a taxa de aprendizado adaptativa.\n",
    "  - **Função de Perda:**  \n",
    "    - `SparseCategoricalCrossentropy(ignore_class=0)` é usada para problemas de classificação multi-classe, onde os rótulos são inteiros.\n",
    "    - O parâmetro `ignore_class=0` indica que o índice 0, geralmente utilizado para tokens de padding, será ignorado no cálculo da perda.\n",
    "  - **Métricas:**  \n",
    "    - `[\"accuracy\"]` é definida para monitorar a acurácia durante o treinamento e validação.\n",
    "\n",
    "```python\n",
    "transformer.compile(\n",
    "    optimizer=optimizer,  # Otimizador Adam com taxa de aprendizado adaptativa\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(ignore_class=0),  \n",
    "    # Função de perda com entropia cruzada esparsa (ignora o índice 0, usado para padding)\n",
    "    metrics=[\"accuracy\"]  # Métrica de acurácia para avaliar o desempenho durante o treinamento\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Resumo\n",
    "\n",
    "- **Scheduler:**  \n",
    "  Ajusta dinamicamente a taxa de aprendizado de forma exponencial, ajudando na convergência do modelo.\n",
    "  \n",
    "- **Otimizador Adam:**  \n",
    "  Utiliza o scheduler para adaptar a taxa de aprendizado e otimizar os parâmetros do modelo de maneira eficiente.\n",
    "  \n",
    "- **Função de Perda e Métricas:**  \n",
    "  A função de perda `SparseCategoricalCrossentropy` ignora tokens de padding, e a acurácia é monitorada para avaliar a performance do modelo.\n",
    "\n",
    "Este conjunto de configurações garante que o modelo Transformer seja treinado de maneira robusta e eficiente, adaptando a taxa de aprendizado ao longo do tempo e considerando corretamente os tokens de padding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# Compilação do Modelo com Otimizador Adam e Scheduler de Aprendizado\n",
    "# ------------------------\n",
    "\n",
    "# Definição de um scheduler para a taxa de aprendizado adaptativa\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-3,  # Taxa de aprendizado inicial\n",
    "    decay_steps=10000,           # Número de passos antes de aplicar o decaimento\n",
    "    decay_rate=0.9,              # Fator de decaimento exponencial\n",
    "    staircase=True               # O decaimento ocorre em \"degraus\" (não contínuo)\n",
    ")\n",
    "\n",
    "# Otimizador Adam com a taxa de aprendizado controlada pelo scheduler\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "# Compilação do modelo Transformer\n",
    "transformer.compile(\n",
    "    optimizer=optimizer,  # Otimizador Adam com taxa de aprendizado adaptativa\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(ignore_class=0),  \n",
    "    # Função de perda com entropia cruzada esparsa (ignora o índice 0, usado para padding)\n",
    "    metrics=[\"accuracy\"]  # Métrica de acurácia para avaliar o desempenho durante o treinamento\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivo do Código: Treinar o Modelo Transformer\n",
    "\n",
    "Este trecho de código inicia o processo de treinamento do modelo Transformer previamente definido, utilizando os datasets de treinamento e validação. O número de épocas é especificado para controlar quantas vezes o modelo passará por todo o conjunto de treinamento.\n",
    "\n",
    "#### Passo a Passo do Código:\n",
    "\n",
    "1. **Definição do Número de Épocas:**\n",
    "   - `epochs = 30`  \n",
    "     Define o número de épocas para o treinamento. Esse valor pode ser ajustado conforme necessário, e estratégias como *early stopping* podem ser empregadas para evitar overfitting.\n",
    "\n",
    "2. **Treinamento do Modelo:**\n",
    "   - Utiliza o método `fit` do modelo Transformer para iniciar o treinamento:\n",
    "     - **Dataset de Treinamento (`train_ds`):** Os dados de treinamento são passados para o modelo.\n",
    "     - **Número de Épocas (`epochs`):** O modelo será treinado por 30 épocas.\n",
    "     - **Dataset de Validação (`val_ds`):** Durante o treinamento, o modelo é avaliado periodicamente com esses dados para monitorar o desempenho e ajustar os hiperparâmetros se necessário.\n",
    "   - O histórico do treinamento, que inclui métricas de perda e acurácia ao longo das épocas, é armazenado na variável `history`.\n",
    "\n",
    "---\n",
    "\n",
    "Este processo de treinamento ajusta os pesos do modelo Transformer com base nos dados fornecidos, e o uso de um dataset de validação permite monitorar a performance do modelo ao longo do tempo, facilitando ajustes futuros e a prevenção de overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 338ms/step - accuracy: 0.0682 - loss: 6.4049 - val_accuracy: 0.1331 - val_loss: 4.2081\n",
      "Epoch 2/30\n",
      "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 347ms/step - accuracy: 0.1543 - loss: 3.6151 - val_accuracy: 0.1799 - val_loss: 3.2776\n",
      "Epoch 3/30\n",
      "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 342ms/step - accuracy: 0.2084 - loss: 2.3730 - val_accuracy: 0.2005 - val_loss: 2.8716\n",
      "Epoch 4/30\n",
      "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 334ms/step - accuracy: 0.2484 - loss: 1.5322 - val_accuracy: 0.2081 - val_loss: 2.7865\n",
      "Epoch 5/30\n",
      "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 340ms/step - accuracy: 0.2746 - loss: 1.0139 - val_accuracy: 0.2117 - val_loss: 2.8350\n",
      "Epoch 6/30\n",
      "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 354ms/step - accuracy: 0.2933 - loss: 0.6924 - val_accuracy: 0.2131 - val_loss: 2.8744\n",
      "Epoch 7/30\n",
      "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 352ms/step - accuracy: 0.3081 - loss: 0.5056 - val_accuracy: 0.2126 - val_loss: 2.9688\n",
      "Epoch 8/30\n",
      "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 345ms/step - accuracy: 0.3161 - loss: 0.4047 - val_accuracy: 0.2121 - val_loss: 3.0325\n",
      "Epoch 9/30\n",
      "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 341ms/step - accuracy: 0.3187 - loss: 0.3501 - val_accuracy: 0.2137 - val_loss: 3.0930\n",
      "Epoch 10/30\n",
      "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 341ms/step - accuracy: 0.3230 - loss: 0.2933 - val_accuracy: 0.2118 - val_loss: 3.1678\n",
      "Epoch 11/30\n",
      "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 335ms/step - accuracy: 0.3254 - loss: 0.2734 - val_accuracy: 0.2129 - val_loss: 3.2279\n",
      "Epoch 12/30\n",
      "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 341ms/step - accuracy: 0.3288 - loss: 0.2395 - val_accuracy: 0.2118 - val_loss: 3.2898\n",
      "Epoch 13/30\n",
      "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 346ms/step - accuracy: 0.3301 - loss: 0.2180 - val_accuracy: 0.2108 - val_loss: 3.3422\n",
      "Epoch 14/30\n",
      "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 339ms/step - accuracy: 0.3332 - loss: 0.2047 - val_accuracy: 0.2111 - val_loss: 3.3526\n",
      "Epoch 15/30\n",
      "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 342ms/step - accuracy: 0.3323 - loss: 0.2008 - val_accuracy: 0.2120 - val_loss: 3.3685\n",
      "Epoch 16/30\n",
      "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 341ms/step - accuracy: 0.3356 - loss: 0.1768 - val_accuracy: 0.2098 - val_loss: 3.4567\n",
      "Epoch 17/30\n",
      "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 339ms/step - accuracy: 0.3352 - loss: 0.1811 - val_accuracy: 0.2121 - val_loss: 3.4432\n",
      "Epoch 18/30\n",
      "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 341ms/step - accuracy: 0.3366 - loss: 0.1671 - val_accuracy: 0.2117 - val_loss: 3.5071\n",
      "Epoch 19/30\n",
      "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 340ms/step - accuracy: 0.3361 - loss: 0.1597 - val_accuracy: 0.2119 - val_loss: 3.4910\n",
      "Epoch 20/30\n",
      "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 343ms/step - accuracy: 0.3359 - loss: 0.1626 - val_accuracy: 0.2109 - val_loss: 3.4920\n",
      "Epoch 21/30\n",
      "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 342ms/step - accuracy: 0.3364 - loss: 0.1546 - val_accuracy: 0.2113 - val_loss: 3.5234\n",
      "Epoch 22/30\n",
      "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 339ms/step - accuracy: 0.3380 - loss: 0.1484 - val_accuracy: 0.2120 - val_loss: 3.5566\n",
      "Epoch 23/30\n",
      "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1514s\u001b[0m 4s/step - accuracy: 0.3382 - loss: 0.1394 - val_accuracy: 0.2104 - val_loss: 3.5493\n",
      "Epoch 24/30\n",
      "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 349ms/step - accuracy: 0.3378 - loss: 0.1377 - val_accuracy: 0.2123 - val_loss: 3.5966\n",
      "Epoch 25/30\n",
      "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 343ms/step - accuracy: 0.3389 - loss: 0.1405 - val_accuracy: 0.2125 - val_loss: 3.5642\n",
      "Epoch 26/30\n",
      "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 342ms/step - accuracy: 0.3412 - loss: 0.1365 - val_accuracy: 0.2112 - val_loss: 3.5877\n",
      "Epoch 27/30\n",
      "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 341ms/step - accuracy: 0.3393 - loss: 0.1323 - val_accuracy: 0.2105 - val_loss: 3.6498\n",
      "Epoch 28/30\n",
      "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 346ms/step - accuracy: 0.3431 - loss: 0.1246 - val_accuracy: 0.2127 - val_loss: 3.5857\n",
      "Epoch 29/30\n",
      "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 342ms/step - accuracy: 0.3431 - loss: 0.1018 - val_accuracy: 0.2120 - val_loss: 3.5983\n",
      "Epoch 30/30\n",
      "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 338ms/step - accuracy: 0.3431 - loss: 0.0987 - val_accuracy: 0.2107 - val_loss: 3.6370\n"
     ]
    }
   ],
   "source": [
    "# ------------------------\n",
    "# Treinamento do Modelo Transformer\n",
    "# ------------------------\n",
    "\n",
    "# Define o número de épocas para o treinamento do modelo\n",
    "epochs = 30  # Considere aumentar este valor ou usar early stopping para evitar overfitting\n",
    "\n",
    "# Inicia o processo de treinamento do modelo\n",
    "history = transformer.fit(\n",
    "    train_ds,              # Dataset de treinamento\n",
    "    epochs=epochs,         # Número de épocas para o treinamento\n",
    "    validation_data=val_ds  # Dataset de validação para monitorar o desempenho\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivo do Código: Visualizar o Desempenho do Modelo Durante o Treinamento\n",
    "\n",
    "Este trecho de código utiliza o Matplotlib para plotar gráficos que demonstram a evolução da acurácia e da perda (loss) ao longo das épocas durante o treinamento do modelo. Essas visualizações ajudam a identificar se o modelo está aprendendo de forma adequada e a monitorar possíveis problemas, como overfitting.\n",
    "\n",
    "#### Passo a Passo do Código:\n",
    "\n",
    "1. **Importação do Matplotlib**:\n",
    "   - `import matplotlib.pyplot as plt`  \n",
    "     Importa a biblioteca Matplotlib, que é utilizada para criar visualizações gráficas.\n",
    "\n",
    "2. **Plotagem da Acurácia**:\n",
    "   - `plt.plot(history.history['accuracy'])`  \n",
    "     Plota a acurácia obtida durante o treinamento em cada época.\n",
    "   - `plt.plot(history.history['val_accuracy'])`  \n",
    "     Plota a acurácia obtida no conjunto de validação em cada época.\n",
    "   - `plt.title(model.name+' accuracy')`  \n",
    "     Define o título do gráfico, que inclui o nome do modelo seguido da palavra \"accuracy\".\n",
    "   - `plt.ylabel('accuracy')` e `plt.xlabel('epoch')`  \n",
    "     Rotulam os eixos y (acurácia) e x (épocas).\n",
    "   - `plt.legend(['train', 'val'], loc='upper left')`  \n",
    "     Adiciona uma legenda para diferenciar os dados de treinamento e validação, posicionada no canto superior esquerdo.\n",
    "   - `plt.show()`  \n",
    "     Exibe o gráfico de acurácia.\n",
    "\n",
    "3. **Plotagem da Perda (Loss)**:\n",
    "   - `plt.plot(history.history['loss'])`  \n",
    "     Plota a perda (loss) do treinamento em cada época.\n",
    "   - `plt.plot(history.history['val_loss'])`  \n",
    "     Plota a perda do conjunto de validação em cada época.\n",
    "   - `plt.title(model.name+' loss')`  \n",
    "     Define o título do gráfico, que inclui o nome do modelo seguido da palavra \"loss\".\n",
    "   - `plt.ylabel('loss')` e `plt.xlabel('epoch')`  \n",
    "     Rotulam os eixos y (loss) e x (épocas).\n",
    "   - `plt.legend(['train', 'val'], loc='upper left')`  \n",
    "     Adiciona uma legenda para diferenciar os dados de treinamento e validação.\n",
    "   - `plt.show()`  \n",
    "     Exibe o gráfico de perda.\n",
    "\n",
    "Esses gráficos fornecem insights visuais sobre como a acurácia e a perda evoluem ao longo do treinamento, permitindo ajustes e melhorias na arquitetura ou no processo de treinamento do modelo, se necessário.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Visualização do Histórico de Treinamento: Acurácia e Perda\n",
    "# =============================================================================\n",
    "\n",
    "# --- Resumo do histórico de acurácia ---\n",
    "plt.figure(figsize=(8, 5))  # Define o tamanho da figura\n",
    "plt.plot(history.history['accuracy'], label='Treinamento')         # Acurácia no treinamento\n",
    "plt.plot(history.history['val_accuracy'], label='Validação')       # Acurácia na validação\n",
    "plt.title(f'{transformer.name} - Acurácia')                              # Título do gráfico com o nome do modelo\n",
    "plt.ylabel('Acurácia')                                            # Rótulo do eixo Y\n",
    "plt.xlabel('Época')                                               # Rótulo do eixo X\n",
    "plt.legend(loc='upper left')                                      # Legenda posicionada no canto superior esquerdo\n",
    "plt.grid(True)                                                    # Adiciona uma grade ao gráfico\n",
    "plt.show()                                                        # Exibe o gráfico\n",
    "\n",
    "# --- Resumo do histórico de perda ---\n",
    "plt.figure(figsize=(8, 5))  # Define o tamanho da figura\n",
    "plt.plot(history.history['loss'], label='Treinamento')            # Perda no treinamento\n",
    "plt.plot(history.history['val_loss'], label='Validação')          # Perda na validação\n",
    "plt.title(f'{transformer.name} - Perda')                                # Título do gráfico com o nome do modelo\n",
    "plt.ylabel('Perda')                                              # Rótulo do eixo Y\n",
    "plt.xlabel('Época')                                              # Rótulo do eixo X\n",
    "plt.legend(loc='upper left')                                     # Legenda posicionada no canto superior esquerdo\n",
    "plt.grid(True)                                                   # Adiciona uma grade ao gráfico\n",
    "plt.show()                                                       # Exibe o gráfico\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
