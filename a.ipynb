{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define o backend do Keras como TensorFlow\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "# Importações de bibliotecas padrão e de terceiros\n",
    "import pathlib\n",
    "import random\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.data as tf_data\n",
    "import tensorflow.strings as tf_strings\n",
    "import tensorflow_datasets.public_api as tfds\n",
    "from tensorflow import keras\n",
    "from keras import layers, Model, Input\n",
    "from keras.layers import TextVectorization\n",
    "from keras import ops\n",
    "from keras import backend as K  # Importa o backend do Keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# Carregamento e Pré-processamento dos Dados\n",
    "# ------------------------\n",
    "\n",
    "# Inicializa uma lista para armazenar os pares de textos (francês e português)\n",
    "text_pairs = []\n",
    "\n",
    "# Abre o arquivo 'data.tsv' para leitura, utilizando codificação UTF-8\n",
    "with open(\"data.tsv\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        # Remove espaços extras e divide a linha usando tabulação como separador\n",
    "        fields = line.strip().split(\"\\t\")\n",
    "        \n",
    "        # Garante que a linha tenha pelo menos 4 colunas antes de processar\n",
    "        if len(fields) < 4:\n",
    "            continue\n",
    "        \n",
    "        # Extrai o texto em francês (segunda coluna)\n",
    "        french = fields[1]\n",
    "        \n",
    "        # Extrai o texto em português (quarta coluna) e adiciona tokens de início e fim\n",
    "        portuguese = \"[start] \" + fields[3] + \" [end]\"\n",
    "        \n",
    "        # Adiciona o par (francês, português) à lista\n",
    "        text_pairs.append((french, portuguese))\n",
    "\n",
    "# Exibe o primeiro par para verificação\n",
    "print(text_pairs[0])\n",
    "\n",
    "# Embaralha os pares de textos para garantir aleatoriedade na divisão dos conjuntos\n",
    "random.shuffle(text_pairs)\n",
    "\n",
    "# Define o número de amostras para validação (15% do total)\n",
    "num_val_samples = int(0.15 * len(text_pairs))\n",
    "\n",
    "# Define o número de amostras para treinamento (o restante após a divisão para validação e teste)\n",
    "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
    "\n",
    "# Divide os pares em conjuntos de treinamento, validação e teste\n",
    "train_pairs = text_pairs[:num_train_samples]\n",
    "val_pairs = text_pairs[num_train_samples:num_train_samples + num_val_samples]\n",
    "test_pairs = text_pairs[num_train_samples + num_val_samples:]\n",
    "\n",
    "# Exibe o número total de pares e a distribuição entre treinamento, validação e teste\n",
    "print(f\"{len(text_pairs)} total pairs\")\n",
    "print(f\"{len(train_pairs)} training pairs\")\n",
    "print(f\"{len(val_pairs)} validation pairs\")\n",
    "print(f\"{len(test_pairs)} test pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define os caracteres que serão removidos durante a padronização dos textos\n",
    "strip_chars = string.punctuation + \"«\" + \"»\"\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")  # Remove colchete de abertura da lista de caracteres\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")  # Remove colchete de fechamento da lista de caracteres\n",
    "\n",
    "# Parâmetros para a vetorização dos textos e treinamento do modelo\n",
    "vocab_size = 25000          # Tamanho máximo do vocabulário para vetorização\n",
    "sequence_length = 20        # Comprimento máximo das sequências de entrada\n",
    "batch_size = 64             # Tamanho do lote (batch) durante o treinamento\n",
    "\n",
    "def custom_standardization(input_string):\n",
    "    \"\"\"\n",
    "    Padroniza o texto convertendo para minúsculas e removendo caracteres indesejados.\n",
    "\n",
    "    Args:\n",
    "        input_string (Tensor): Texto de entrada a ser padronizado.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Texto padronizado com caracteres removidos.\n",
    "    \"\"\"\n",
    "    lowercase = tf_strings.lower(input_string)  # Converte o texto para minúsculas\n",
    "    return tf_strings.regex_replace(\n",
    "        lowercase, \n",
    "        \"[%s]\" % re.escape(strip_chars),  # Remove os caracteres definidos em 'strip_chars'\n",
    "        \"\"\n",
    "    )\n",
    "\n",
    "# Vetorização dos textos em francês\n",
    "french_vectorization = TextVectorization(\n",
    "    max_tokens=vocab_size,                # Número máximo de tokens no vocabulário\n",
    "    output_mode=\"int\",                    # Saída como inteiros (índices dos tokens)\n",
    "    output_sequence_length=sequence_length  # Comprimento fixo da sequência\n",
    ")\n",
    "\n",
    "# Vetorização dos textos em português com padronização personalizada\n",
    "portuguese_vectorization = TextVectorization(\n",
    "    max_tokens=vocab_size,                  # Número máximo de tokens no vocabulário\n",
    "    output_mode=\"int\",                      # Saída como inteiros (índices dos tokens)\n",
    "    output_sequence_length=sequence_length + 1,  # Comprimento fixo (com 1 extra para o token final)\n",
    "    standardize=custom_standardization      # Função de padronização personalizada\n",
    ")\n",
    "\n",
    "# Extrai os textos em francês e português dos pares de treinamento\n",
    "train_french_texts = [pair[0] for pair in train_pairs]\n",
    "train_portuguese_texts = [pair[1] for pair in train_pairs]\n",
    "\n",
    "# Ajusta (adapta) as camadas de vetorização aos textos de treinamento\n",
    "french_vectorization.adapt(train_french_texts)\n",
    "portuguese_vectorization.adapt(train_portuguese_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dataset(french, portuguese):\n",
    "    \"\"\"\n",
    "    Formata os pares de textos em francês e português para o modelo seq2seq.\n",
    "\n",
    "    Args:\n",
    "        french (Tensor): Textos em francês.\n",
    "        portuguese (Tensor): Textos em português.\n",
    "\n",
    "    Returns:\n",
    "        Tuple: Um dicionário com as entradas do encoder e do decoder, \n",
    "               e o alvo do decoder para o treinamento.\n",
    "    \"\"\"\n",
    "    # Vetoriza o texto em francês (entrada do encoder)\n",
    "    french = french_vectorization(french)\n",
    "    \n",
    "    # Vetoriza o texto em português (entrada e alvo do decoder)\n",
    "    portuguese = portuguese_vectorization(portuguese)\n",
    "    \n",
    "    return (\n",
    "        {\n",
    "            \"encoder_inputs\": french,  # Entrada do encoder\n",
    "            \"decoder_inputs\": portuguese[:, :-1],  # Entrada do decoder (sem o último token)\n",
    "        },\n",
    "        portuguese[:, 1:]  # Alvo do decoder (sem o primeiro token)\n",
    "    )\n",
    "\n",
    "\n",
    "def make_dataset(pairs):\n",
    "    \"\"\"\n",
    "    Cria um dataset formatado a partir dos pares de texto.\n",
    "\n",
    "    Args:\n",
    "        pairs (list): Lista de tuplas contendo os textos em francês e português.\n",
    "\n",
    "    Returns:\n",
    "        tf.data.Dataset: Dataset formatado para o treinamento e validação.\n",
    "    \"\"\"\n",
    "    # Separa os textos em francês e português dos pares\n",
    "    french_texts, portuguese_texts = zip(*pairs)\n",
    "    \n",
    "    # Cria um dataset TensorFlow a partir dos textos\n",
    "    dataset = tf_data.Dataset.from_tensor_slices(\n",
    "        (list(french_texts), list(portuguese_texts))\n",
    "    )\n",
    "    \n",
    "    # Agrupa os dados em lotes (batch)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    \n",
    "    # Aplica a função de formatação para preparar as entradas e alvos\n",
    "    dataset = dataset.map(format_dataset)\n",
    "    \n",
    "    # Armazena em cache, embaralha e pré-carrega os dados para otimização\n",
    "    return dataset.cache().shuffle(2048).prefetch(16)\n",
    "\n",
    "\n",
    "# Cria os datasets de treinamento e validação utilizando os pares correspondentes\n",
    "train_ds = make_dataset(train_pairs)\n",
    "val_ds = make_dataset(val_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# Componentes do Modelo com Regularização Aprimorada\n",
    "# ------------------------\n",
    "\n",
    "class PositionalEmbedding(layers.Layer):\n",
    "    \"\"\"\n",
    "    Camada personalizada para aplicar embeddings de tokens combinados com embeddings posicionais.\n",
    "    Isso permite que o modelo entenda a ordem dos tokens na sequência.\n",
    "    \"\"\"\n",
    "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
    "        \"\"\"\n",
    "        Inicializa a camada de embeddings posicionais.\n",
    "\n",
    "        Args:\n",
    "            sequence_length (int): Comprimento máximo da sequência.\n",
    "            vocab_size (int): Tamanho do vocabulário (número máximo de tokens).\n",
    "            embed_dim (int): Dimensão do vetor de embedding.\n",
    "            **kwargs: Argumentos adicionais para a classe base `Layer`.\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        # Embedding para os tokens (representação vetorial de cada palavra/token)\n",
    "        self.token_embeddings = layers.Embedding(\n",
    "            input_dim=vocab_size, \n",
    "            output_dim=embed_dim\n",
    "        )\n",
    "        \n",
    "        # Embedding para a posição de cada token na sequência\n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim=sequence_length, \n",
    "            output_dim=embed_dim\n",
    "        )\n",
    "        \n",
    "        # Armazena os parâmetros para reutilização e configuração\n",
    "        self.sequence_length = sequence_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        Combina embeddings dos tokens com seus respectivos embeddings posicionais.\n",
    "\n",
    "        Args:\n",
    "            inputs (Tensor): Sequência de tokens (shape: batch_size, sequence_length).\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Embedding combinado de tokens e posições (shape: batch_size, sequence_length, embed_dim).\n",
    "        \"\"\"\n",
    "        # Obtém o comprimento da sequência (última dimensão da entrada)\n",
    "        length = ops.shape(inputs)[-1]\n",
    "        \n",
    "        # Cria um tensor representando as posições (0, 1, 2, ..., length - 1)\n",
    "        positions = ops.arange(0, length, 1)\n",
    "        \n",
    "        # Aplica o embedding nos tokens\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        \n",
    "        # Aplica o embedding nas posições\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        \n",
    "        # Combina o embedding dos tokens com o embedding das posições\n",
    "        return embedded_tokens + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        \"\"\"\n",
    "        Gera uma máscara para ignorar o padding (valores iguais a 0).\n",
    "\n",
    "        Args:\n",
    "            inputs (Tensor): Sequência de entrada.\n",
    "            mask (Tensor, opcional): Máscara existente.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Máscara onde valores diferentes de zero são marcados como válidos.\n",
    "        \"\"\"\n",
    "        # Cria a máscara usando `ops.not_equal` para detectar tokens válidos (diferentes de 0)\n",
    "        return ops.not_equal(inputs, 0)\n",
    "\n",
    "    def get_config(self):\n",
    "        \"\"\"\n",
    "        Retorna a configuração da camada para permitir a serialização do modelo.\n",
    "\n",
    "        Returns:\n",
    "            dict: Configurações da camada, incluindo comprimento da sequência, \n",
    "                  tamanho do vocabulário e dimensão do embedding.\n",
    "        \"\"\"\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"sequence_length\": self.sequence_length,\n",
    "            \"vocab_size\": self.vocab_size,\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "        })\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer Encoder com Dropout adicionado nas camadas de atenção e feedforward\n",
    "class TransformerEncoder(layers.Layer):\n",
    "    \"\"\"\n",
    "    Encoder do Transformer que aplica atenção multi-cabeça, normalização em camadas\n",
    "    e redes feedforward, com regularização por Dropout.\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, dropout_rate=0.1, **kwargs):\n",
    "        \"\"\"\n",
    "        Inicializa o Transformer Encoder.\n",
    "\n",
    "        Args:\n",
    "            embed_dim (int): Dimensão dos embeddings de entrada.\n",
    "            dense_dim (int): Dimensão da rede feedforward interna.\n",
    "            num_heads (int): Número de cabeças de atenção.\n",
    "            dropout_rate (float): Taxa de dropout para regularização.\n",
    "            **kwargs: Argumentos adicionais para a classe base `Layer`.\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Parâmetros da camada\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        # Camada de Atenção Multi-Cabeça\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=embed_dim\n",
    "        )\n",
    "\n",
    "        # Dropout aplicado após a camada de atenção\n",
    "        self.dropout_att = layers.Dropout(dropout_rate)\n",
    "\n",
    "        # Rede feedforward composta por duas camadas densas\n",
    "        self.dense_proj = keras.Sequential([\n",
    "            layers.Dense(dense_dim, activation=\"relu\"),\n",
    "            layers.Dense(embed_dim),\n",
    "        ])\n",
    "\n",
    "        # Dropout aplicado após a rede feedforward\n",
    "        self.dropout_ffn = layers.Dropout(dropout_rate)\n",
    "\n",
    "        # Normalização em camadas aplicada após a atenção e o feedforward\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "\n",
    "        # Indica que a camada suporta mascaramento (útil para lidar com padding)\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, mask=None, training=False):\n",
    "        \"\"\"\n",
    "        Executa a passagem dos dados pela camada Transformer Encoder.\n",
    "\n",
    "        Args:\n",
    "            inputs (Tensor): Tensor de entrada (batch_size, sequence_length, embed_dim).\n",
    "            mask (Tensor, opcional): Máscara para ignorar posições de padding.\n",
    "            training (bool, opcional): Indica se a camada está em modo de treinamento.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Saída do encoder após atenção, feedforward e normalização.\n",
    "        \"\"\"\n",
    "        # Se uma máscara for fornecida, ajusta o formato para ser compatível com a atenção\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(mask[:, None, :], dtype=\"int32\")\n",
    "        else:\n",
    "            padding_mask = None\n",
    "\n",
    "        # Aplica a atenção multi-cabeça com a máscara de padding (se existir)\n",
    "        attention_output = self.attention(\n",
    "            query=inputs,\n",
    "            value=inputs,\n",
    "            key=inputs,\n",
    "            attention_mask=padding_mask\n",
    "        )\n",
    "\n",
    "        # Aplica Dropout após a atenção (apenas durante o treinamento)\n",
    "        attention_output = self.dropout_att(attention_output, training=training)\n",
    "\n",
    "        # Normaliza a soma residual entre a entrada e a saída da atenção\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "\n",
    "        # Passa pela rede feedforward\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "\n",
    "        # Aplica Dropout após o feedforward (apenas durante o treinamento)\n",
    "        proj_output = self.dropout_ffn(proj_output, training=training)\n",
    "\n",
    "        # Normaliza a soma residual entre o input normalizado e a saída do feedforward\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "\n",
    "    def get_config(self):\n",
    "        \"\"\"\n",
    "        Retorna a configuração da camada para permitir a serialização do modelo.\n",
    "\n",
    "        Returns:\n",
    "            dict: Configurações da camada, incluindo embed_dim, dense_dim e num_heads.\n",
    "        \"\"\"\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "        })\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer Decoder com Dropout adicionado nas subcamadas de atenção e na rede feedforward\n",
    "class TransformerDecoder(layers.Layer):\n",
    "    \"\"\"\n",
    "    Decoder do Transformer que aplica atenção causal, cross-attention com a saída do encoder,\n",
    "    normalização em camadas e redes feedforward, com regularização por Dropout.\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim, latent_dim, num_heads, dropout_rate=0.1, **kwargs):\n",
    "        \"\"\"\n",
    "        Inicializa o Transformer Decoder.\n",
    "\n",
    "        Args:\n",
    "            embed_dim (int): Dimensão dos embeddings de entrada.\n",
    "            latent_dim (int): Dimensão da rede feedforward interna.\n",
    "            num_heads (int): Número de cabeças de atenção.\n",
    "            dropout_rate (float): Taxa de dropout para regularização.\n",
    "            **kwargs: Argumentos adicionais para a classe base `Layer`.\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Parâmetros do decoder\n",
    "        self.embed_dim = embed_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        # Primeira camada de Atenção Multi-Cabeça (Self-Attention com máscara causal)\n",
    "        self.attention_1 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=embed_dim\n",
    "        )\n",
    "        self.dropout_att1 = layers.Dropout(dropout_rate)\n",
    "\n",
    "        # Segunda camada de Atenção Multi-Cabeça (Cross-Attention com saída do encoder)\n",
    "        self.attention_2 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=embed_dim\n",
    "        )\n",
    "        self.dropout_att2 = layers.Dropout(dropout_rate)\n",
    "\n",
    "        # Rede feedforward com ativação ReLU\n",
    "        self.dense_proj = keras.Sequential([\n",
    "            layers.Dense(latent_dim, activation=\"relu\"),\n",
    "            layers.Dense(embed_dim),\n",
    "        ])\n",
    "        self.dropout_ffn = layers.Dropout(dropout_rate)\n",
    "\n",
    "        # Normalização em camadas após cada subcamada do decoder\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.layernorm_3 = layers.LayerNormalization()\n",
    "\n",
    "        # Indica que a camada suporta mascaramento (útil para lidar com padding)\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, mask=None, training=False):\n",
    "        \"\"\"\n",
    "        Executa a passagem dos dados pela camada Transformer Decoder.\n",
    "\n",
    "        Args:\n",
    "            inputs (tuple): Tupla contendo (decoder_inputs, encoder_outputs).\n",
    "            mask (tuple, opcional): Máscaras para o decoder e o encoder.\n",
    "            training (bool, opcional): Indica se a camada está em modo de treinamento.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Saída do decoder após atenção, feedforward e normalização.\n",
    "        \"\"\"\n",
    "        decoder_inputs, encoder_outputs = inputs\n",
    "\n",
    "        # Cria a máscara causal para evitar que o decoder veja tokens futuros\n",
    "        causal_mask = self.get_causal_attention_mask(decoder_inputs)\n",
    "\n",
    "        # Se uma máscara for fornecida, separa as máscaras do decoder e do encoder\n",
    "        if mask is None:\n",
    "            decoder_padding_mask, encoder_padding_mask = None, None\n",
    "        else:\n",
    "            decoder_padding_mask, encoder_padding_mask = mask\n",
    "\n",
    "        # Primeira Atenção Multi-Cabeça (Self-Attention com máscara causal)\n",
    "        attention_output_1 = self.attention_1(\n",
    "            query=decoder_inputs,\n",
    "            value=decoder_inputs,\n",
    "            key=decoder_inputs,\n",
    "            attention_mask=causal_mask,\n",
    "            query_mask=decoder_padding_mask,\n",
    "        )\n",
    "        attention_output_1 = self.dropout_att1(attention_output_1, training=training)\n",
    "\n",
    "        # Soma residual e normalização após a primeira atenção\n",
    "        out_1 = self.layernorm_1(decoder_inputs + attention_output_1)\n",
    "\n",
    "        # Segunda Atenção Multi-Cabeça (Cross-Attention com saída do encoder)\n",
    "        attention_output_2 = self.attention_2(\n",
    "            query=out_1,\n",
    "            value=encoder_outputs,\n",
    "            key=encoder_outputs,\n",
    "            query_mask=decoder_padding_mask,\n",
    "            key_mask=encoder_padding_mask,\n",
    "        )\n",
    "        attention_output_2 = self.dropout_att2(attention_output_2, training=training)\n",
    "\n",
    "        # Soma residual e normalização após a cross-attention\n",
    "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
    "\n",
    "        # Passagem pela rede feedforward\n",
    "        proj_output = self.dense_proj(out_2)\n",
    "        proj_output = self.dropout_ffn(proj_output, training=training)\n",
    "\n",
    "        # Soma residual e normalização após a rede feedforward\n",
    "        return self.layernorm_3(out_2 + proj_output)\n",
    "\n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        \"\"\"\n",
    "        Gera uma máscara causal para a atenção, impedindo o acesso a tokens futuros.\n",
    "\n",
    "        Args:\n",
    "            inputs (Tensor): Sequência de entrada do decoder.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Máscara causal com shape (batch_size, seq_length, seq_length).\n",
    "        \"\"\"\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, seq_length = input_shape[0], input_shape[1]\n",
    "\n",
    "        # Cria uma matriz onde cada posição i só pode ver até a posição j (i >= j)\n",
    "        i = tf.range(seq_length)[:, None]\n",
    "        j = tf.range(seq_length)\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "\n",
    "        # Ajusta o formato da máscara para ser compatível com a atenção multi-cabeça\n",
    "        mask = tf.reshape(mask, (1, seq_length, seq_length))\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1), tf.convert_to_tensor([1, 1])], axis=0\n",
    "        )\n",
    "        return tf.tile(mask, mult)\n",
    "\n",
    "    def get_config(self):\n",
    "        \"\"\"\n",
    "        Retorna a configuração da camada para permitir a serialização do modelo.\n",
    "\n",
    "        Returns:\n",
    "            dict: Configurações da camada, incluindo embed_dim, latent_dim e num_heads.\n",
    "        \"\"\"\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"latent_dim\": self.latent_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "        })\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# Construção do Modelo Transformer\n",
    "# ------------------------\n",
    "\n",
    "# Definição dos hiperparâmetros do modelo\n",
    "embed_dim = 128           # Dimensão do embedding para os tokens\n",
    "latent_dim = 1024         # Dimensão da rede feed-forward dentro dos blocos do Transformer\n",
    "num_heads = 6             # Número de cabeças de atenção na Multi-Head Attention\n",
    "sequence_length = 20      # Comprimento máximo da sequência de entrada\n",
    "vocab_size_model = 15000  # Tamanho do vocabulário usado no modelo\n",
    "\n",
    "# ------------------------\n",
    "# Construção do Encoder\n",
    "# ------------------------\n",
    "\n",
    "# Entrada do encoder: sequência de tokens inteiros (shape: batch_size, sequence_length)\n",
    "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
    "\n",
    "# Aplica a camada de embedding posicional para adicionar informações sobre a ordem dos tokens\n",
    "x = PositionalEmbedding(sequence_length, vocab_size_model, embed_dim)(encoder_inputs)\n",
    "\n",
    "# Passa os embeddings pelo Transformer Encoder\n",
    "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
    "\n",
    "# Define o modelo do encoder, mapeando as entradas para as saídas processadas\n",
    "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
    "\n",
    "# ------------------------\n",
    "# Construção do Decoder (usando Teacher Forcing)\n",
    "# ------------------------\n",
    "\n",
    "# Entrada do decoder: sequência de tokens de destino (shape: batch_size, sequence_length)\n",
    "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
    "\n",
    "# Aplica a camada de embedding posicional nos inputs do decoder\n",
    "x = PositionalEmbedding(sequence_length, vocab_size_model, embed_dim)(decoder_inputs)\n",
    "\n",
    "# Passa os embeddings pelo Transformer Decoder, utilizando as saídas do encoder\n",
    "x = TransformerDecoder(embed_dim, latent_dim, num_heads)([x, encoder_outputs])\n",
    "\n",
    "# Camada densa final para gerar as previsões de tokens (com ativação softmax)\n",
    "decoder_outputs = layers.Dense(vocab_size_model, activation=\"softmax\")(x)\n",
    "\n",
    "# ------------------------\n",
    "# Definição do Modelo Final Transformer\n",
    "# ------------------------\n",
    "\n",
    "# Cria o modelo Transformer completo, com entradas para o encoder e decoder\n",
    "transformer = keras.Model(\n",
    "    {\"encoder_inputs\": encoder_inputs, \"decoder_inputs\": decoder_inputs},\n",
    "    decoder_outputs,\n",
    "    name=\"transformer\",\n",
    ")\n",
    "\n",
    "# Exibe o resumo da arquitetura do modelo, mostrando as camadas e parâmetros\n",
    "transformer.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# Compilação do Modelo com Otimizador Adam e Scheduler de Aprendizado\n",
    "# ------------------------\n",
    "\n",
    "# Definição de um scheduler para a taxa de aprendizado adaptativa\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-3,  # Taxa de aprendizado inicial\n",
    "    decay_steps=10000,           # Número de passos antes de aplicar o decaimento\n",
    "    decay_rate=0.9,              # Fator de decaimento exponencial\n",
    "    staircase=True               # O decaimento ocorre em \"degraus\" (não contínuo)\n",
    ")\n",
    "\n",
    "# Otimizador Adam com a taxa de aprendizado controlada pelo scheduler\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "# Compilação do modelo Transformer\n",
    "transformer.compile(\n",
    "    optimizer=optimizer,  # Otimizador Adam com taxa de aprendizado adaptativa\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(ignore_class=0),  \n",
    "    # Função de perda com entropia cruzada esparsa (ignora o índice 0, usado para padding)\n",
    "    metrics=[\"accuracy\"]  # Métrica de acurácia para avaliar o desempenho durante o treinamento\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Je ne supporte pas ce type.', '[start] Eu não suporto esse tipo. [end]')\n",
      "33030 total pairs\n",
      "23122 training pairs\n",
      "4954 validation pairs\n",
      "4954 test pairs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"transformer\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,922,560</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,922,560</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_encode… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">659,456</span> │ positional_embed… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │ not_equal_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_3         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_decode… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,055,360</span> │ positional_embed… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ transformer_enco… │\n",
       "│                     │                   │            │ not_equal_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ not_equal_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,935,000</span> │ transformer_deco… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">15000</span>)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │  \u001b[38;5;34m1,922,560\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mPositionalEmbeddi…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │  \u001b[38;5;34m1,922,560\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mPositionalEmbeddi…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_encode… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │    \u001b[38;5;34m659,456\u001b[0m │ positional_embed… │\n",
       "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │ not_equal_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_3         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_decode… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │  \u001b[38;5;34m1,055,360\u001b[0m │ positional_embed… │\n",
       "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ transformer_enco… │\n",
       "│                     │                   │            │ not_equal_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ not_equal_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │  \u001b[38;5;34m1,935,000\u001b[0m │ transformer_deco… │\n",
       "│                     │ \u001b[38;5;34m15000\u001b[0m)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,494,936</span> (28.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,494,936\u001b[0m (28.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,494,936</span> (28.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,494,936\u001b[0m (28.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 328ms/step - accuracy: 0.0637 - loss: 6.4672 - val_accuracy: 0.1304 - val_loss: 4.2834\n",
      "Epoch 2/30\n",
      "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 341ms/step - accuracy: 0.1479 - loss: 3.7420 - val_accuracy: 0.1775 - val_loss: 3.3135\n",
      "Epoch 3/30\n",
      "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 340ms/step - accuracy: 0.2043 - loss: 2.4399 - val_accuracy: 0.1997 - val_loss: 2.9113\n",
      "Epoch 4/30\n",
      "\u001b[1m129/362\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:14\u001b[0m 319ms/step - accuracy: 0.2455 - loss: 1.5932"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 315\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# ------------------------\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;66;03m# ------------------------\u001b[39;00m\n\u001b[1;32m    314\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m  \u001b[38;5;66;03m# You might consider increasing this further or using early stopping\u001b[39;00m\n\u001b[0;32m--> 315\u001b[0m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/unb/tema/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/unb/tema/.venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:368\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    367\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 368\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/Documents/unb/tema/.venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:216\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    214\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    218\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/unb/tema/.venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/unb/tema/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Documents/unb/tema/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/unb/tema/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/unb/tema/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Documents/unb/tema/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/Documents/unb/tema/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/unb/tema/.venv/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1698\u001b[0m   )\n",
      "File \u001b[0;32m~/Documents/unb/tema/.venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ------------------------\n",
    "# Treinamento do Modelo Transformer\n",
    "# ------------------------\n",
    "\n",
    "# Define o número de épocas para o treinamento do modelo\n",
    "epochs = 30  # Considere aumentar este valor ou usar early stopping para evitar overfitting\n",
    "\n",
    "# Inicia o processo de treinamento do modelo\n",
    "history = transformer.fit(\n",
    "    train_ds,              # Dataset de treinamento\n",
    "    epochs=epochs,         # Número de épocas para o treinamento\n",
    "    validation_data=val_ds  # Dataset de validação para monitorar o desempenho\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
